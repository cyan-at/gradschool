{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "110b1a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow\n"
     ]
    }
   ],
   "source": [
    "# 0 define backend\n",
    "import sys, os, time\n",
    "\n",
    "# %env DDE_BACKEND=tensorflow.compat.v1\n",
    "# %env XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/home/cyan3/miniforge/envs/tf\n",
    "\n",
    "os.environ['DDE_BACKEND'] = \"tensorflow\" # v2\n",
    "os.environ['XLA_FLAGS'] = \"--xla_gpu_cuda_data_dir=/usr/local/home/cyan3/miniforge/envs/tf\"\n",
    "\n",
    "# https://stackoverflow.com/questions/68614547/tensorflow-libdevice-not-found-why-is-it-not-found-in-the-searched-path\n",
    "# this directory has /nvvm/libdevice/libdevice.10.bc\n",
    "\n",
    "print(os.environ['DDE_BACKEND'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "956b850b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-10 09:12:23.679485: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-10 09:12:23.880157: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-09-10 09:12:23.966783: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-10 09:12:24.634194: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/rti.com/rti_connext_dds-5.3.1//lib/x64Linux3gcc5.4.0::/usr/local/lib:/usr/local/include:/usr/lib64/:/home/cyan3/Dev/ames/VerveCollabTest/bundles/com.rti.dds.target/os/linux/x86_64/:/usr/local/irg/lib/:/usr/local/viper/lib/:/usr/local/home/cyan3/miniforge/envs/tf/lib/\n",
      "2022-09-10 09:12:24.634354: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/rti.com/rti_connext_dds-5.3.1//lib/x64Linux3gcc5.4.0::/usr/local/lib:/usr/local/include:/usr/lib64/:/home/cyan3/Dev/ames/VerveCollabTest/bundles/com.rti.dds.target/os/linux/x86_64/:/usr/local/irg/lib/:/usr/local/viper/lib/:/usr/local/home/cyan3/miniforge/envs/tf/lib/\n",
      "2022-09-10 09:12:24.634359: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Using backend: tensorflow\n",
      "\n",
      "2022-09-10 09:12:26.026736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-10 09:12:26.061698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-10 09:12:26.061926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enable just-in-time compilation with XLA.\n",
      "\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "1662826351.6747348\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import deepxde as dde\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "\n",
    "from os.path import dirname, join as pjoin\n",
    "\n",
    "from scipy import stats\n",
    "import scipy.io\n",
    "from scipy.stats import truncnorm, norm\n",
    "from scipy.optimize import linprog\n",
    "from scipy import sparse\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    print(device)\n",
    "    \n",
    "if dde.backend.backend_name == \"pytorch\":\n",
    "    exp = dde.backend.torch.exp\n",
    "else:\n",
    "    from deepxde.backend import tf\n",
    "\n",
    "    exp = tf.exp\n",
    "    \n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.linalg import solve_discrete_are\n",
    "from scipy.linalg import sqrtm\n",
    "from cvxpylayers.tensorflow.cvxpylayer import CvxpyLayer\n",
    "\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29978c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1662826355.7577827\n"
     ]
    }
   ],
   "source": [
    "N = nSample = 100\n",
    "\n",
    "# must be floats\n",
    "state_min = 0.0\n",
    "state_max = 6.0\n",
    "\n",
    "j1, j2, j3 =1,1,2 # axis-symmetric case\n",
    "q_statepenalty_gain = 0 # 0.5\n",
    "\n",
    "T_0=0. #initial time\n",
    "T_t=200. #Terminal time\n",
    "\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29f770b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1662826357.8392096\n"
     ]
    }
   ],
   "source": [
    "x_T = np.transpose(np.linspace(state_min, state_max, N))\n",
    "y_T = np.transpose(np.linspace(state_min, state_max, N))\n",
    "z_T = np.transpose(np.linspace(state_min, state_max, N))\n",
    "x_T=x_T.reshape(len(x_T),1)\n",
    "y_T=y_T.reshape(len(y_T),1)\n",
    "z_T=z_T.reshape(len(z_T),1)\n",
    "\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "689f0e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1662826360.1584666\n"
     ]
    }
   ],
   "source": [
    "def pdf1d(x, mu, sigma):\n",
    "    a, b = (state_min - mu) / sigma, (state_max - mu) / sigma\n",
    "    rho_x=truncnorm.pdf(x, a, b, loc = mu, scale = sigma)\n",
    "\n",
    "    # do NOT use gaussian norm, because it is only area=1\n",
    "    # from -inf, inf, will not be for finite state/grid\n",
    "    # rho_x = norm.pdf(x, mu, sigma)\n",
    "    return rho_x\n",
    "\n",
    "def boundary(_, on_initial):\n",
    "    return on_initial\n",
    "\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7fa9dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1)\n",
      "(200, 10000)\n"
     ]
    }
   ],
   "source": [
    "x_grid = np.transpose(np.linspace(state_min, state_max, nSample))\n",
    "y_grid = np.transpose(np.linspace(state_min, state_max, nSample))\n",
    "[X,Y] = np.meshgrid(x_grid,x_grid)\n",
    "C = (X - Y)**2\n",
    "\n",
    "# cvector = C.flatten('F')\n",
    "cvector = C.reshape(nSample**2,1)\n",
    "\n",
    "A = np.concatenate(\n",
    "    (\n",
    "        np.kron(\n",
    "            np.ones((1,nSample)),\n",
    "            sparse.eye(nSample).toarray()\n",
    "        ),\n",
    "        np.kron(\n",
    "            sparse.eye(nSample).toarray(),\n",
    "            np.ones((1,nSample))\n",
    "        )\n",
    "    ), axis=0)\n",
    "# 2*nSample\n",
    "\n",
    "print(cvector.shape)\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c6660c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1662826374.6869135\n"
     ]
    }
   ],
   "source": [
    "# 1d linprog example\n",
    "\n",
    "rho_0_1d=pdf1d(x_T, 5.0, 1.0).reshape(len(x_T),1)\n",
    "rho_T_1d=pdf1d(x_T, 4.0, 1.0).reshape(len(x_T),1)\n",
    "\n",
    "rho_0_1d = np.where(rho_0_1d < 0, 0, rho_0_1d)\n",
    "rho_0_1d = rho_0_1d / np.sum(np.abs(rho_0_1d))\n",
    "\n",
    "# rho_0_1d_trapz = np.trapz(rho_0_1d, axis=0)[0]\n",
    "# rho_0_1d = rho_0_1d / rho_0_1d_trapz\n",
    "# rho_0_1d_trapz = np.trapz(rho_0_1d, axis=0)\n",
    "# print(\"rho_0_1d_trapz=\",rho_0_1d_trapz)\n",
    "\n",
    "rho_T_1d = np.where(rho_T_1d < 0, 0, rho_T_1d)\n",
    "rho_T_1d = rho_T_1d / np.sum(np.abs(rho_T_1d))\n",
    "\n",
    "# rho_T_1d_trapz = np.trapz(rho_T_1d, axis=0)[0]\n",
    "# rho_T_1d = rho_T_1d / rho_T_1d_trapz\n",
    "# rho_T_1d_trapz = np.trapz(rho_T_1d, axis=0)\n",
    "# print(\"rho_T_1d_trapz=\",rho_T_1d_trapz)\n",
    "\n",
    "rho_0 = rho_0_1d\n",
    "rho_T = rho_T_1d\n",
    "\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d223e944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running HiGHS 1.2.2 [date: 2022-08-26, git hash: n/a]\n",
      "Copyright (c) 2022 ERGO-Code under MIT licence terms\n",
      "Presolving model\n",
      "200 rows, 10000 cols, 20000 nonzeros\n",
      "199 rows, 10000 cols, 19900 nonzeros\n",
      "Presolve : Reductions: rows 199(-1); columns 10000(-0); elements 19900(-100)\n",
      "Solving the presolved LP\n",
      "Using EKK dual simplex solver - serial\n",
      "  Iteration        Objective     Infeasibilities num(sum)\n",
      "          0     0.0000000000e+00 Pr: 199(1.99666) 0s\n",
      "       2699     6.3187344716e-01 Pr: 0(0) 0s\n",
      "Solving the original LP from the solution after postsolve\n",
      "Model   status      : Optimal\n",
      "Simplex   iterations: 2699\n",
      "Objective value     :  6.3187344716e-01\n",
      "HiGHS run time      :          0.11\n",
      "WARNING: Method getModelStatus(const bool scaled_model) is deprecated: alternative method is getModelStatus()\n",
      "0.6318734471629914\n"
     ]
    }
   ],
   "source": [
    "res = linprog(\n",
    "    cvector,\n",
    "    A_eq=A,\n",
    "    b_eq=np.concatenate((rho_0, rho_T), axis=0),\n",
    "    bounds=[(0, np.inf)],\n",
    "    options={\"disp\": True}\n",
    ")\n",
    "print(res.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf66965f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal value is 0.6318734626810212\n"
     ]
    }
   ],
   "source": [
    "# Define and solve the CVXPY problem.\n",
    "x = cp.Variable(\n",
    "    cvector.shape[0],\n",
    "    nonneg=True\n",
    ")\n",
    "prob = cp.Problem(\n",
    "    cp.Minimize(cvector.T @ x),\n",
    "    [\n",
    "        A @ x == np.concatenate((\n",
    "            rho_0,\n",
    "            rho_T\n",
    "        ), axis=0).reshape(-1),\n",
    "        # do NOT specify bounds constraints here\n",
    "    ],\n",
    ")\n",
    "prob.solve(verbose=False)\n",
    "\n",
    "# Print result.\n",
    "print(\"\\nThe optimal value is\", prob.value)\n",
    "\n",
    "# print(\"A dual solution is\")\n",
    "# print(prob.constraints[0].dual_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68a180b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1662826731.8820415\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "import tensorflow as tf\n",
    "from cvxpylayers.tensorflow import CvxpyLayer\n",
    "\n",
    "# Define and solve the CVXPY problem.\n",
    "x = cp.Variable(\n",
    "    cvector.shape[0],\n",
    "    nonneg=True\n",
    ")\n",
    "pred = cp.Parameter((A.shape[0],))\n",
    "problem = cp.Problem(\n",
    "    cp.Minimize(cvector.T @ x),\n",
    "    [\n",
    "        A @ x == pred,\n",
    "    ],\n",
    ")\n",
    "assert problem.is_dpp()\n",
    "cvxpylayer = CvxpyLayer(\n",
    "    problem,\n",
    "    parameters=[pred],\n",
    "    variables=[x])\n",
    "\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f903f7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1662826740.3974142\n"
     ]
    }
   ],
   "source": [
    "rho_0_tf = tf.constant(rho_0, shape=(100,))\n",
    "\n",
    "rho_I=pdf1d(x_T, 4.0, 1.0).reshape(len(x_T),1)\n",
    "rho_I = np.where(rho_I < 0, 0, rho_I)\n",
    "rho_I = rho_I / np.sum(np.abs(rho_I))\n",
    "rho_I = rho_I.reshape((100,))\n",
    "\n",
    "# y_pred = tf.Variable(tf.zeros((100,), tf.double))\n",
    "y_pred = tf.Variable(rho_I, shape=(100,))\n",
    "# this MUST be tf.Variable to get a gradient w.r.t\n",
    "\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9481a7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wass_dist= [0.633]\n",
      "grad_ypred [0.477 0.479 0.482 0.486 0.491 0.499 0.499 0.499 0.499 0.499 0.499 0.499 0.499 0.499 0.499 0.499 0.499 0.499 0.499 0.499 0.499 0.499 0.499 0.499 0.499 0.499 0.499 0.499 0.499 0.499 0.499\n",
      " 0.499 0.499 0.499 0.499 0.499 0.499 0.499 0.499 0.499 0.499 0.498 0.498 0.498 0.498 0.498 0.498 0.498 0.498 0.498 0.498 0.498 0.498 0.498 0.498 0.498 0.498 0.498 0.498 0.498 0.498 0.498\n",
      " 0.498 0.498 0.498 0.498 0.498 0.498 0.498 0.498 0.498 0.498 0.498 0.498 0.497 0.497 0.497 0.497 0.497 0.497 0.497 0.497 0.496 0.496 0.496 0.496 0.496 0.496 0.495 0.495 0.495 0.495 0.495\n",
      " 0.495 0.495 0.495 0.495 0.495 0.495 0.495]\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "  # solve the problem, setting the values of A, b to A_tf, b_tf\n",
    "  param = tf.concat([rho_0_tf, y_pred], 0)\n",
    "  x_sol, = cvxpylayer(param)\n",
    "wass_dist = cvector.T @ x_sol.numpy()\n",
    "print(\"wass_dist=\", wass_dist)\n",
    "\n",
    "# compute the gradient of the summed solution with respect to A, b\n",
    "grad_ypred = tape.gradient(x_sol, [y_pred])\n",
    "print(\"grad_ypred\", grad_ypred[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff01b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b49f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is their example, where you take a gradient w.r.t a Parameter\n",
    "\n",
    "\n",
    "# Generate data\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "n = 2\n",
    "m = 3\n",
    "\n",
    "A = np.eye(n) + 1e-2 * np.random.randn(n, n)\n",
    "B = 1e-2 / 3 * np.random.randn(n, m)\n",
    "Q = np.eye(n)\n",
    "R = np.eye(m)\n",
    "\n",
    "# Compute LQR control policy\n",
    "P_lqr = solve_discrete_are(A, B, Q, R)\n",
    "P = R + B.T@P_lqr@B\n",
    "P_sqrt_lqr = sqrtm(P)\n",
    "\n",
    "# Construct CVXPY problem and layer\n",
    "x_cvxpy = cp.Parameter((n, 1))\n",
    "P_sqrt_cvxpy = cp.Parameter((m, m))\n",
    "P_21_cvxpy = cp.Parameter((n, m))\n",
    "q_cvxpy = cp.Parameter((m, 1))\n",
    "\n",
    "u_cvxpy = cp.Variable((m, 1))\n",
    "y_cvxpy = cp.Variable((n, 1))\n",
    "\n",
    "objective = .5 * cp.sum_squares(P_sqrt_cvxpy @ u_cvxpy) + x_cvxpy.T @ y_cvxpy + q_cvxpy.T @ u_cvxpy\n",
    "problem = cp.Problem(\n",
    "    cp.Minimize(objective),\n",
    "    [\n",
    "        cp.norm(u_cvxpy) <= 1,\n",
    "         y_cvxpy == P_21_cvxpy @ u_cvxpy])\n",
    "assert problem.is_dpp()\n",
    "\n",
    "policy = CvxpyLayer(\n",
    "    problem,\n",
    "    [x_cvxpy, P_sqrt_cvxpy, P_21_cvxpy, q_cvxpy],\n",
    "    [u_cvxpy]\n",
    ")\n",
    "\n",
    "def train(iters):\n",
    "    # Initialize with LQR control lyapunov function\n",
    "    P_sqrt = tf.Variable(P_sqrt_lqr)\n",
    "    P_21 = tf.Variable(A.T @ P_lqr @ B)\n",
    "    q = tf.Variable(tf.zeros((m, 1), dtype=tf.float64))\n",
    "    variables = [P_sqrt, P_21, q]\n",
    "    A_tf, B_tf, Q_tf, R_tf = map(tf.constant, [A, B, Q, R])\n",
    "\n",
    "    def g(x, u):\n",
    "        return tf.squeeze(\n",
    "            tf.transpose(x) @ Q_tf @ x + tf.transpose(u) @ R_tf @ u)\n",
    "\n",
    "    def evaluate(x0, P_sqrt, P_21, q, T):\n",
    "        x = x0\n",
    "        cost = 0.\n",
    "        for _ in range(T):\n",
    "            u, = policy(x, P_sqrt, P_21, q)\n",
    "            cost += g(x, u) / T\n",
    "            x = A_tf @ x + B_tf @ u + .2 * tf.random.normal((n, 1), dtype=tf.float64)\n",
    "        return cost\n",
    "\n",
    "    def eval_loss(N=8, T=25):\n",
    "        return sum(\n",
    "        [\n",
    "            evaluate(\n",
    "                tf.zeros((n, 1), dtype=tf.float64),\n",
    "                P_sqrt,\n",
    "                P_21,\n",
    "                q,\n",
    "                T=T\n",
    "            ) for _ in range(N)\n",
    "        ]) / N\n",
    "\n",
    "    results = []\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.02, momentum=0.9)\n",
    "    for i in range(iters):\n",
    "        tf.random.set_seed(1)\n",
    "        np.random.seed(1)\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = eval_loss()\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "        results.append(loss.numpy())\n",
    "        print(\"(iter %d) loss: %g \" % (i, results[-1]))\n",
    "    return results\n",
    "\n",
    "results = train(iters=100)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(results)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('average cost')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
