{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed94711d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DDE_BACKEND=tensorflow\n"
     ]
    }
   ],
   "source": [
    "# 0 define backend\n",
    "\n",
    "%env DDE_BACKEND=tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7803d4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/lib/cuda\n"
     ]
    }
   ],
   "source": [
    "# 2 define xla\n",
    "\n",
    "%env XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/lib/cuda\n",
    "\n",
    "# below does NOT work, dde won't parse it\n",
    "# %env TF_XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/lib/cuda\n",
    "\n",
    "# using /usr/lib/nvidia-cuda-toolkit does NOT work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5e80d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'--xla_gpu_cuda_data_dir=/usr/lib/cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env XLA_FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9af2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env TF_XLA_FLAGS=\"--tf_xla_auto_jit=1 --tf_xla_cpu_global_jit\"\n",
    "\n",
    "# =1, =2, =-1 both are slow still"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3463c219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-30 09:08:19.056465: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Using backend: tensorflow\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the default backend to \"tensorflow\". You can change it in the ~/.deepxde/config.json file or export the DDE_BACKEND environment variable. Valid options are: tensorflow.compat.v1, tensorflow, pytorch, jax, paddle (all lowercase)\n",
      "Enable just-in-time compilation with XLA.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-30 09:08:20.116079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-30 09:08:20.126848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-30 09:08:20.127260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enable just-in-time compilation with XLA.\n",
      "\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "tensorflow\n"
     ]
    }
   ],
   "source": [
    "# 1 import stuff\n",
    "\n",
    "import os, json\n",
    "\n",
    "# \"tensorflow.compat.v1\", \"tensorflow\", \"pytorch\"\n",
    "def set_default_backend(backend_name):\n",
    "    default_dir = os.path.join(os.path.expanduser(\"~\"), \".deepxde\")\n",
    "    if not os.path.exists(default_dir):\n",
    "        os.makedirs(default_dir)\n",
    "    config_path = os.path.join(default_dir, \"config.json\")\n",
    "    with open(config_path, \"w\") as config_file:\n",
    "        json.dump({\"backend\": backend_name.lower()}, config_file)\n",
    "    print(\n",
    "        'Setting the default backend to \"{}\". You can change it in the '\n",
    "        \"~/.deepxde/config.json file or export the DDE_BACKEND environment variable. \"\n",
    "        \"Valid options are: tensorflow.compat.v1, tensorflow, pytorch, jax, paddle (all lowercase)\".format(\n",
    "            backend_name\n",
    "        )\n",
    "    )\n",
    "    \n",
    "import tensorflow as tf\n",
    "set_default_backend(\"tensorflow\")\n",
    "\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# backend = \"tensorflow_v1\"\n",
    "# set_default_backend(\"tensorflow.compat.v1\")\n",
    "\n",
    "# tf.config.run_functions_eagerly(False)\n",
    "# tf.disable_eager_execution()\n",
    "# tf.enable_eager_execution()\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# eager execution for tensorflow backend works, but is VERY slow\n",
    "# disabling it leads to EagerFunction error\n",
    "\n",
    "# import torch\n",
    "# backend = \"pytorch\"\n",
    "# set_default_backend(\"pytorch\")\n",
    "\n",
    "import deepxde as dde\n",
    "\n",
    "dde.model.backend_name = \"tensorflow\"\n",
    "\n",
    "dde.config.enable_xla_jit(True)\n",
    "# this is key for speed in v2?\n",
    "# happens by default for tensorflow v1?\n",
    "\n",
    "# dde.config.disable_xla_jit()\n",
    "# if you disable, you will run out of memory\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "from numpy import linalg as LA\n",
    "import math\n",
    "import scipy.io\n",
    "from os.path import dirname, join as pjoin\n",
    "from scipy.stats import truncnorm, norm\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "params = {'backend': 'ps',\n",
    "          'xtick.labelsize': 12,\n",
    "          'ytick.labelsize': 12,\n",
    "          'legend.handlelength': 1,\n",
    "          'legend.borderaxespad': 0,\n",
    "          'font.family': 'serif',\n",
    "          'font.serif': ['Computer Modern Roman'],\n",
    "          'ps.usedistiller': 'xpdf',\n",
    "          'text.usetex': True,\n",
    "          # include here any neede package for latex\n",
    "          'text.latex.preamble': [r'\\usepackage{amsmath}'],\n",
    "          }\n",
    "plt.rcParams.update(params)\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "import scipy.integrate as integrate\n",
    "\n",
    "import time\n",
    "\n",
    "import shutil\n",
    "\n",
    "from scipy.interpolate import griddata as gd\n",
    "\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    print(device)\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "# os.environ['XLA_FLAGS'] = \"--xla_gpu_cuda_data_dir=/usr/lib/cuda\"\n",
    "print(dde.model.backend_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c38ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env XLA_FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f22fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1e930b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62ecc0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "run_tensorflow_-2.500_2.500__5.000__2000__0.001__1_1_2__0.000__2.000_1.000__0.000_1.000__12000_1000__20000\n"
     ]
    }
   ],
   "source": [
    "# 3 define training parameters\n",
    "\n",
    "state_min = -2.5\n",
    "state_max = 2.5\n",
    "# shrinking this helps a lot\n",
    "\n",
    "######################################\n",
    "\n",
    "N = 2000\n",
    "\n",
    "T_t = 5.0\n",
    "\n",
    "epsilon=.001\n",
    "\n",
    "# j1, j2, j3=3,2,1\n",
    "j1, j2, j3 =1,1,2 # axis-symmetric case\n",
    "\n",
    "######################################\n",
    "\n",
    "# q=1 # state cost\n",
    "\n",
    "q_statepenalty_gain = 0 # 0.5\n",
    "\n",
    "######################################\n",
    "\n",
    "mu_0 = 2.0\n",
    "sigma_0 = 1.0\n",
    "\n",
    "mu_T = 0.0\n",
    "sigma_T = 1.0\n",
    "\n",
    "######################################\n",
    "\n",
    "samples_between_initial_and_final = 12000 # 10^4 order, 20k = out of memory\n",
    "initial_and_final_samples = 1000 # some 10^3 order\n",
    "\n",
    "######################################\n",
    "\n",
    "num_epochs = 20000\n",
    "\n",
    "id_prefix = \"run_%s_%.3f_%.3f__%.3f__%d__%.3f__%d_%d_%d__%.3f__%.3f_%.3f__%.3f_%.3f__%d_%d__%d\" % (\n",
    "    dde.model.backend_name,\n",
    "    state_min,\n",
    "    state_max,\n",
    "    T_t,\n",
    "    N,\n",
    "    epsilon,\n",
    "    j1, j2, j3,\n",
    "    q_statepenalty_gain,\n",
    "    mu_0, sigma_0,\n",
    "    mu_T, sigma_T,\n",
    "    samples_between_initial_and_final, initial_and_final_samples,\n",
    "    num_epochs\n",
    ")\n",
    "\n",
    "print(T_t)\n",
    "print(id_prefix)\n",
    "\n",
    "# id_prefix is a id for this training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21a1aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 pde\n",
    "\n",
    "def pde(x, y):\n",
    "    \"\"\"Euler system.\n",
    "    dy1_t = g(x)-1/2||Dy1_x||^2-<Dy1_x,f>-epsilon*Dy1_xx\n",
    "    dy2_t = -D.(y2*(f)+Dy1_x)+epsilon*Dy2_xx\n",
    "    All collocation-based residuals are defined here\n",
    "    \"\"\"\n",
    "    y1, y2 = y[:, 0:1], y[:, 1:]\n",
    "    dy1_x = tf.gradients(y1, x)[0]\n",
    "    dy1_x, dy1_y, dy1_z, dy1_t = dy1_x[:,0:1], dy1_x[:,1:2], dy1_x[:,2:3], dy1_x[:,3:]\n",
    "    \n",
    "    dy1_xx = tf.gradients(dy1_x, x)[0][:, 0:1]\n",
    "    dy1_yy = tf.gradients(dy1_y, x)[0][:, 1:2]\n",
    "    dy1_zz = tf.gradients(dy1_z, x)[0][:, 2:3] \n",
    "    \n",
    "    dy2_x = tf.gradients(y2, x)[0]\n",
    "    dy2_x, dy2_y, dy2_z, dy2_t = dy2_x[:,0:1], dy2_x[:,1:2], dy2_x[:,2:3], dy2_x[:,3:]    \n",
    "    \n",
    "    dy2_xx = tf.gradients(dy2_x, x)[0][:, 0:1]\n",
    "    dy2_yy = tf.gradients(dy2_y, x)[0][:, 1:2]\n",
    "    dy2_zz = tf.gradients(dy2_z, x)[0][:, 2:3]     \n",
    "\n",
    "    f1=x[:, 1:2]*x[:, 2:3]*(j2-j3)/j1\n",
    "    f2=x[:, 0:1]*x[:, 2:3]*(j3-j1)/j2\n",
    "    f3=x[:, 0:1]*x[:, 1:2]*(j1-j2)/j3\n",
    "    \n",
    "    d_f1dy1_y2_x=tf.gradients((f1+dy1_x)*y2,x)[0][:, 0:1]\n",
    "    d_f2dy1_y2_y=tf.gradients((f2+dy1_y)*y2,x)[0][:, 1:2]\n",
    "    d_f3dy1_y2_z=tf.gradients((f3+dy1_x)*y2,x)[0][:, 2:3]\n",
    "\n",
    "    # stay close to origin while searching, penalizes large state distance solutions\n",
    "    q = q_statepenalty_gain*(x[:, 0:1] * x[:, 0:1] + x[:, 1:2] * x[:, 1:2] + x[:, 2:3] * x[:, 2:3])\n",
    "    \n",
    "    # also try\n",
    "    # q = 0 # minimum effort control\n",
    "    \n",
    "    # TODO: verify this expression\n",
    "    return [\n",
    "        -dy1_t+q-.5*(dy1_x*dy1_x+dy1_y*dy1_y+dy1_z*dy1_z)-dy1_x*f1-dy1_y*f2-dy1_z*f3-epsilon*(dy1_xx+dy1_yy+dy1_zz),\n",
    "        -dy2_t-(d_f1dy1_y2_x+d_f2dy1_y2_y+d_f3dy1_y2_z)+epsilon*(dy2_xx+dy2_yy+dy2_zz),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3eb598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 more pde, boundary\n",
    "\n",
    "def boundary(_, on_initial):\n",
    "    return on_initial\n",
    "\n",
    "def pdf1d_0(x,y,z):\n",
    "    '''\n",
    "    a, b = (state_min - mu) / sigma, (state_max - mu) / sigma # must match sampling\n",
    "    rho_x=truncnorm.pdf(x, a, b, loc = mu, scale = sigma)\n",
    "    rho_y=truncnorm.pdf(y, a, b, loc = mu, scale = sigma)\n",
    "    rho_z=truncnorm.pdf(z, a, b, loc = mu, scale = sigma) # replace with np.normal? gaussian\n",
    "    '''\n",
    "\n",
    "    rho_x = norm.pdf(x, mu_0, sigma_0)\n",
    "    rho_y = norm.pdf(y, mu_0, sigma_0)\n",
    "    rho_z = norm.pdf(z, mu_0, sigma_0)\n",
    "    \n",
    "#     rho_x = tf.random.normal(\n",
    "#         [1],\n",
    "#         mean=x,\n",
    "#         stddev=mu_0,\n",
    "#         dtype=tf.dtypes.float16,\n",
    "#         seed=None,\n",
    "#         name=None\n",
    "#     )\n",
    "#     rho_y = tf.random.normal(\n",
    "#         [1],\n",
    "#         mean=y,\n",
    "#         stddev=mu_0,\n",
    "#         dtype=tf.dtypes.float16,\n",
    "#         seed=None,\n",
    "#         name=None\n",
    "#     )\n",
    "#     rho_z = tf.random.normal(\n",
    "#         shape,\n",
    "#         mean=z,\n",
    "#         stddev=mu_0,\n",
    "#         dtype=tf.dtypes.float16,\n",
    "#         seed=None,\n",
    "#         name=None\n",
    "#     )\n",
    "\n",
    "    return rho_x*rho_y*rho_z\n",
    "\n",
    "def pdf1d_T(x,y,z):\n",
    "    '''\n",
    "    a, b = (state_min - mu) / sigma, (state_max - mu) / sigma\n",
    "    rho_x=truncnorm.pdf(x, a, b, loc = mu, scale = sigma)\n",
    "    rho_y=truncnorm.pdf(y, a, b, loc = mu, scale = sigma)\n",
    "    rho_z=truncnorm.pdf(z, a, b, loc = mu, scale = sigma)\n",
    "    '''\n",
    "\n",
    "    rho_x = norm.pdf(x, mu_T, sigma_T)\n",
    "    rho_y = norm.pdf(y, mu_T, sigma_T)\n",
    "    rho_z = norm.pdf(z, mu_T, sigma_T)\n",
    "    \n",
    "    return rho_x*rho_y*rho_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ffb8a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-30 09:08:28.307004: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/skopt/sampler/sobol.py:246: UserWarning: The balance properties of Sobol' points require n to be a power of 2. 0 points have been previously generated, then: n=0+12002=12002. \n",
      "  warnings.warn(\"The balance properties of Sobol' points require \"\n",
      "2022-08-30 09:08:28.308267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-30 09:08:28.308616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-30 09:08:28.308856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-30 09:08:28.603718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-30 09:08:28.603910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-30 09:08:28.604052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-30 09:08:28.604197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 852 MB memory:  -> device: 0, name: NVIDIA RTX A2000 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/skopt/sampler/sobol.py:246: UserWarning: The balance properties of Sobol' points require n to be a power of 2. 0 points have been previously generated, then: n=0+1002=1002. \n",
      "  warnings.warn(\"The balance properties of Sobol' points require \"\n"
     ]
    }
   ],
   "source": [
    "# 6 define data and net\n",
    "\n",
    "x_T = np.transpose(np.linspace(state_min, state_max, N))\n",
    "y_T = np.transpose(np.linspace(state_min, state_max, N))\n",
    "z_T = np.transpose(np.linspace(state_min, state_max, N))\n",
    "\n",
    "x_T=x_T.reshape(len(x_T),1)\n",
    "y_T=y_T.reshape(len(y_T),1)\n",
    "z_T=z_T.reshape(len(z_T),1)\n",
    "\n",
    "time=T_t*np.ones((len(x_T), 1))\n",
    "\n",
    "terminal_time=np.hstack((x_T,y_T,z_T,time))\n",
    "\n",
    "rho_T=pdf1d_T(x_T,y_T,z_T).reshape(len(x_T),1)\n",
    "\n",
    "rho_T_BC = dde.icbc.PointSetBC(terminal_time, rho_T, component=1)\n",
    "\n",
    "geom=dde.geometry.geometry_3d.Cuboid(\n",
    "    [state_min, state_min, state_min],\n",
    "    [state_max, state_max, state_max])\n",
    "timedomain = dde.geometry.TimeDomain(0., T_t)\n",
    "geomtime = dde.geometry.GeometryXTime(geom, timedomain)\n",
    "\n",
    "rho_0_BC = dde.icbc.IC(\n",
    "    geomtime,\n",
    "    lambda x: pdf1d_0(x[:,0:1],x[:,1:2],x[:,2:3]),\n",
    "    boundary,\n",
    "    component=1)\n",
    "\n",
    "data = dde.data.TimePDE(\n",
    "    geomtime,\n",
    "    pde, \n",
    "    [rho_0_BC,rho_T_BC],\n",
    "    num_domain=samples_between_initial_and_final,\n",
    "    num_initial=initial_and_final_samples)\n",
    "\n",
    "net = dde.nn.FNN([4] + [70] *3  + [2], \"tanh\", \"Glorot normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "487fd549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<deepxde.model.Model object at 0x7fd16a440670>\n"
     ]
    }
   ],
   "source": [
    "# 7 define model\n",
    "\n",
    "model = dde.Model(data, net)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41aa3274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./run_tensorflow_-2.500_2.500__5.000__2000__0.001__1_1_2__0.000__2.000_1.000__0.000_1.000__12000_1000__20000\n",
      "dir exists\n",
      "checkpoint\n",
      "run_tensorflow_-2.500_2.500__5.000__2000__0.001__1_1_2__0.000__2.000_1.000__0.000_1.000__12000_1000__20000_loss.dat\n",
      "run_tensorflow_-2.500_2.500__5.000__2000__0.001__1_1_2__0.000__2.000_1.000__0.000_1.000__12000_1000__20000_train.dat\n",
      "run_tensorflow_-2.500_2.500__5.000__2000__0.001__1_1_2__0.000__2.000_1.000__0.000_1.000__12000_1000__20000_test.dat\n",
      "run_tensorflow_-2.500_2.500__5.000__2000__0.001__1_1_2__0.000__2.000_1.000__0.000_1.000__12000_1000__20000.ipynb\n",
      "run_tensorflow_-2.500_2.500__5.000__2000__0.001__1_1_2__0.000__2.000_1.000__0.000_1.000__12000_1000__20000-149.ckpt.data-00000-of-00001\n",
      "run_tensorflow_-2.500_2.500__5.000__2000__0.001__1_1_2__0.000__2.000_1.000__0.000_1.000__12000_1000__20000-149.ckpt.index\n",
      "loss.png\n",
      "vopt_xt.dat\n",
      "run_tensorflow_-2.500_2.500__5.000__2000__0.001__1_1_2__0.000__2.000_1.000__0.000_1.000__12000_1000__20000_test.mat\n",
      "run_tensorflow_-2.500_2.500__5.000__2000__0.001__1_1_2__0.000__2.000_1.000__0.000_1.000__12000_1000__20000_post_predict_10_20_v.mat\n",
      "table_vopt_xt.dat\n",
      "run_tensorflow_-2.500_2.500__5.000__2000__0.001__1_1_2__0.000__2.000_1.000__0.000_1.000__12000_1000__20000_post_predict_t0_10_20_v.mat\n",
      "run_tensorflow_-2.500_2.500__5.000__2000__0.001__1_1_2__0.000__2.000_1.000__0.000_1.000__12000_1000__20000_post_predict_mid_10_20_v.mat\n",
      "run_tensorflow_-2.500_2.500__5.000__2000__0.001__1_1_2__0.000__2.000_1.000__0.000_1.000__12000_1000__20000_post_predict_t5_10_20_v.mat\n",
      "run_tensorflow_-2.500_2.500__5.000__2000__0.001__1_1_2__0.000__2.000_1.000__0.000_1.000__12000_1000__20000_post_predict_x1_x2_x3_t.mat\n",
      "run_tensorflow_-2.500_2.500__5.000__2000__0.001__1_1_2__0.000__2.000_1.000__0.000_1.000__12000_1000__20000_post_predict_t0_20_50_v.mat\n",
      "run_tensorflow_-2.500_2.500__5.000__2000__0.001__1_1_2__0.000__2.000_1.000__0.000_1.000__12000_1000__20000_post_predict_mid_20_50_v.mat\n",
      "run_tensorflow_-2.500_2.500__5.000__2000__0.001__1_1_2__0.000__2.000_1.000__0.000_1.000__12000_1000__20000_post_predict_t5_20_50_v.mat\n",
      "notebook_post_predict_t0_100_100_v.mat\n",
      "notebook_post_predict_mid_50_50_v.mat\n"
     ]
    }
   ],
   "source": [
    "# 8 make a directory to save data\n",
    "\n",
    "dirname = './%s' % (id_prefix)\n",
    "print(dirname)\n",
    "\n",
    "if not os.path.exists(dirname):\n",
    "    print(\"making dirname\")\n",
    "    os.mkdir(dirname)\n",
    "else:\n",
    "    print(\"dir exists\")\n",
    "    for file in os.listdir(dirname):\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa4b449d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 9 stop as soon as loss is low enough\n",
    "\n",
    "ck_path = \"%s/%s/model\" % (os.path.abspath(\"./\"), id_prefix)\n",
    "\n",
    "class EarlyStoppingFixed(dde.callbacks.EarlyStopping):\n",
    "    def on_epoch_end(self):\n",
    "        current = self.get_monitor_value()\n",
    "        if self.monitor_op(current - self.min_delta, self.best):\n",
    "            self.best = current\n",
    "            # must meet baseline first\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = self.model.train_state.epoch\n",
    "                self.model.stop_training = True\n",
    "        else:\n",
    "            self.wait = 0\n",
    "                \n",
    "    def on_train_end(self):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print(\"Epoch {}: early stopping\".format(self.stopped_epoch))\n",
    "        \n",
    "        self.model.save(ck_path, verbose=True)\n",
    "\n",
    "earlystop_cb = EarlyStoppingFixed(baseline=1e-3, patience=0)\n",
    "# no patience otherwise keeps going to improve but bounces around\n",
    "\n",
    "# modelcheckpt_cb = dde.callbacks.ModelCheckpoint(ck_path, verbose=True, save_better_only=True, period=1000)\n",
    "\n",
    "# model.compile(\"adam\", lr=1e-3,external_trainable_variables=[])\n",
    "# losshistory, train_state = model.train(epochs=num_epochs, callbacks=[])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89c1071e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "adam\n",
      "['LBFGS_options', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_load_backend', 'backend_name', 'config', 'get', 'importlib', 'is_external_optimizer', 'optimizers', 'set_LBFGS_options', 'sys', 'tensorflow', 'tfp_optimizer']\n",
      "'compile' took 0.000579 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 10 compile\n",
    "\n",
    "model.compile(optimizer=\"adam\", lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9925cce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fd0decfcd30> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x7fd0decfcd30>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary(x[i], on[i]) for i in range(len(x))])\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fd0decfcd30> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x7fd0decfcd30>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary(x[i], on[i]) for i in range(len(x))])\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-30 09:08:46.841066: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x5564935d6ba0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-08-30 09:08:46.841088: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): NVIDIA RTX A2000 Laptop GPU, Compute Capability 8.6\n",
      "2022-08-30 09:08:46.872862: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-08-30 09:08:47.476763: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-08-30 09:08:47.477985: W tensorflow/stream_executor/gpu/asm_compiler.cc:230] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2022-08-30 09:08:47.477998: W tensorflow/stream_executor/gpu/asm_compiler.cc:233] Used ptxas at ptxas\n",
      "2022-08-30 09:08:47.478049: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-08-30 09:08:47.482426: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-08-30 09:08:47.483493: W tensorflow/compiler/xla/service/gpu/buffer_comparator.cc:640] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Setting XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda  or modifying $PATH can be used to set the location of ptxas\n",
      "This message will only be logged once.\n",
      "2022-08-30 09:08:49.479183: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-08-30 09:08:49.481844: I tensorflow/compiler/jit/xla_compilation_cache.cc:478] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step      Train loss                                  Test loss                                   Test metric\n",
      "0         [5.11e-02, 5.89e-02, 8.78e-02, 6.08e-02]    [5.11e-02, 5.89e-02, 8.78e-02, 6.08e-02]    []  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-30 09:08:50.984047: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-08-30 09:09:01.786099: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:61] Constant folding an instrution is taking > 1s:\n",
      "\n",
      "  %dot.51 = f32[128000,70]{1,0} dot(f32[128000,70]{1,0} %constant.263, f32[70,70]{1,0} %constant.395), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2022-08-30 09:09:09.488794: E tensorflow/compiler/xla/service/slow_operation_alarm.cc:61] Constant folding an instrution is taking > 2s:\n",
      "\n",
      "  %dot.12 = f32[128000,70]{1,0} dot(f32[128000,70]{1,0} %constant.363, f32[70,70]{1,0} %constant.321), lhs_contracting_dims={1}, rhs_contracting_dims={1}\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1         [1.90e-02, 1.86e-02, 3.06e-02, 7.21e-03]    [1.90e-02, 1.86e-02, 3.06e-02, 7.21e-03]    []  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-30 09:10:19.722424: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-08-30 09:11:43.776808: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 11 compile and train model\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m losshistory, train_state \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplay_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearlystop_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/deepxde/utils/internal.py:22\u001b[0m, in \u001b[0;36mtiming.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     21\u001b[0m     ts \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n\u001b[0;32m---> 22\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     te \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m took \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m s\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, te \u001b[38;5;241m-\u001b[39m ts))\n",
      "File \u001b[0;32m/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/deepxde/model.py:576\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, iterations, batch_size, display_every, disregard_previous_best, callbacks, model_restore_path, model_save_path, epochs)\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m iterations \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo iterations for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_name))\n\u001b[0;32m--> 576\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_sgd\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_every\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mon_train_end()\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/deepxde/model.py:593\u001b[0m, in \u001b[0;36mModel._train_sgd\u001b[0;34m(self, iterations, display_every)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mon_batch_begin()\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_state\u001b[38;5;241m.\u001b[39mset_data_train(\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mtrain_next_batch(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[1;32m    592\u001b[0m )\n\u001b[0;32m--> 593\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_aux_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_state\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_state\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/deepxde/model.py:494\u001b[0m, in \u001b[0;36mModel._train_step\u001b[0;34m(self, inputs, targets, auxiliary_vars)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msess\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step, feed_dict\u001b[38;5;241m=\u001b[39mfeed_dict)\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauxiliary_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaddle\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;66;03m# TODO: auxiliary_vars\u001b[39;00m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step(inputs, targets)\n",
      "File \u001b[0;32m/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 11 compile and train model\n",
    "\n",
    "losshistory, train_state = model.train(\n",
    "    display_every=1,\n",
    "    iterations=num_epochs,\n",
    "    callbacks=[earlystop_cb])\n",
    "\n",
    "# variable = dde.callbacks.VariableValue([S], period=600, filename=\"variables.dat\")\n",
    "# losshistory, train_state = model.train(epochs=20000, callbacks=[variable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ce059",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 12 save training, test, loss\n",
    "\n",
    "dde.saveplot(losshistory, train_state, issave=True, isplot=False)\n",
    "# test.dat will have 2*initial_and_final_samples + samples_between_initial_and_final + N (terminal_time)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81e0c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f057ad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13 move notebook, dat to folder\n",
    "\n",
    "if os.path.exists('./loss.dat'):\n",
    "    print(\"found\")\n",
    "    os.rename('./loss.dat', '%s/loss.dat' % (dirname))\n",
    "    os.rename('./train.dat', '%s/train.dat' % (dirname))\n",
    "    os.rename('./test.dat', '%s/test.dat' % (dirname))\n",
    "\n",
    "nb_full_path = os.path.join(os.getcwd(), nb_name)\n",
    "shutil.copyfile('./%s' % (nb_name), './%s/notebook.ipynb' % (dirname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b2261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14 remove previous saved model\n",
    "\n",
    "found = False\n",
    "for file in os.listdir(dirname):\n",
    "    if \"ckpt\" in file:\n",
    "        print(\"removing %s\" % (file))\n",
    "        os.remove(\"%s/%s\" % (dirname, file))\n",
    "        found = True\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "if not found:\n",
    "    print(\"noop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874b53d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 save model\n",
    "\n",
    "model_path = model.save(\"%s/%s/model\" % (os.path.abspath(\"./\"), id_prefix))\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4461c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16 plot loss\n",
    "\n",
    "loss_loaded = np.genfromtxt('./%s/loss.dat' % (id_prefix))\n",
    "\n",
    "# import ipdb; ipdb.set_trace();\n",
    "\n",
    "# [0] epoch\n",
    "# [1] y1, psi, hjb\n",
    "# [2] y2, rho, plank pde\n",
    "# [3] rho0, initial\n",
    "# [4] rhoT, terminal\n",
    "\n",
    "epoch = loss_loaded[:, 0]\n",
    "y1_psi_hjb = loss_loaded[:, 1]\n",
    "y2_rho_plankpde = loss_loaded[:, 2]\n",
    "rho0_initial = loss_loaded[:, 3]\n",
    "rhoT_terminal = loss_loaded[:, 4]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_yscale('log')\n",
    "\n",
    "line1, = ax.plot(epoch, y1_psi_hjb, color='orange', lw=1, label='HJB PDE')\n",
    "line2, = ax.plot(epoch, y2_rho_plankpde, color='blue', lw=1, label='Controlled Fokker-Planck PDE')\n",
    "line3, = ax.plot(epoch, rho0_initial, color='red', lw=1, label='p0 boundary condition')\n",
    "line4, = ax.plot(epoch, rhoT_terminal, color='purple', lw=1, label='pT boundary condition')\n",
    "\n",
    "ax.grid()\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set_title('training error/residual plots: mu0=2 -> muT=0')\n",
    "\n",
    "plot_fname = \"%s/%s/loss.png\" % (os.path.abspath(\"./\"), id_prefix)\n",
    "plt.savefig(plot_fname, dpi=300)\n",
    "print(\"saved plot\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5436bb28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 17 restore model to model_restored\n",
    "\n",
    "model_restored = dde.Model(data, net)\n",
    "\n",
    "ckpt_filename = None\n",
    "for file in os.listdir(dirname):\n",
    "    if file.endswith(\"ckpt.index\"):\n",
    "        print(file)        \n",
    "        ckpt_filename = file.replace(\".index\", \"\")\n",
    "print(\"\")\n",
    "print(\"ckpt_filename\")\n",
    "print(ckpt_filename)\n",
    "print(\"\")\n",
    "model_name = \"%s/%s/%s\" % (os.path.abspath(\"./\"), id_prefix, ckpt_filename)\n",
    "print(model_name)\n",
    "\n",
    "print(\"\")\n",
    "print(model_restored)\n",
    "model_restored.restore(model_name)\n",
    "print(model_restored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37d9d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cadfe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8e94fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18 load test data\n",
    "\n",
    "test = np.genfromtxt('./%s/test.dat' % (id_prefix))\n",
    "# test_timesorted = test[test[:, 3].argsort()]\n",
    "# sort AGAIN by output because a lot of samples @ t=0, t=5\n",
    "ind = np.lexsort((test[:,4],test[:,3])) # sorts by [3] (t) then by [4] (psi)\n",
    "test_timesorted = test[ind]\n",
    "source_t = test_timesorted[:, 3]\n",
    "\n",
    "print(test_timesorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c184979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19 save test data to mat for matlab\n",
    "\n",
    "import scipy.io\n",
    "mat = {\n",
    "    \"test_timesorted\" : test_timesorted,\n",
    "}\n",
    "mat_fname = '%s/%s/test.mat' % (os.path.abspath(\"./\"), id_prefix)\n",
    "scipy.io.savemat(mat_fname, mat)\n",
    "print(\"saved mat\", mat_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298e7f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 print loaded test data, try np.gradient\n",
    "\n",
    "print(test_timesorted[:, 4])\n",
    "print(test_timesorted[:, 0])\n",
    "tmp = np.gradient(test_timesorted[:, 4], test_timesorted[:, 0])\n",
    "print(tmp[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e6d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21 make input tensor\n",
    "\n",
    "inp = test_timesorted[:, 0:4] # x1, x2, x3, t\n",
    "inp_tensor = tf.convert_to_tensor(inp, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcda9401",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 22 get tf gradient with model, compare to test output, save\n",
    "\n",
    "print(\"\")\n",
    "print(\"inp\")\n",
    "print(inp, inp.shape)\n",
    "\n",
    "######################################\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(inp_tensor)\n",
    "    # preds = model.net(inp_tensor)\n",
    "\n",
    "    # you can take gradient of BOTH psi / rho w.r.t. input\n",
    "    # but we only care about psi model.net[:, 0]\n",
    "    psi = model.net(inp_tensor)[:, 0]\n",
    "\n",
    "######################################\n",
    "\n",
    "# print(\"\")\n",
    "# print(\"preds\")\n",
    "# print(preds)\n",
    "\n",
    "print(\"\")\n",
    "print(\"psi\")\n",
    "print(psi)\n",
    "\n",
    "######################################\n",
    "\n",
    "print(\"\")\n",
    "print(\"test output\")\n",
    "# print(test_timesorted[:, 4:6])\n",
    "print(test_timesorted[:, 4])\n",
    "\n",
    "######################################\n",
    "\n",
    "# gradient = tape.gradient(preds, inp_tensor)\n",
    "# gradient = gradient.numpy()\n",
    "\n",
    "vopt_xt = tape.gradient(psi, inp_tensor) # nx4\n",
    "vopt_xt = vopt_xt.numpy()\n",
    "\n",
    "######################################\n",
    "\n",
    "# gradient_fname = \"%s/%s/gradient.dat\" % (os.path.abspath(\"./\"), id_prefix)\n",
    "# np.savetxt(gradient_fname, gradient)\n",
    "# print(\"\")\n",
    "# print(\"gradient\")\n",
    "# print(gradient, gradient.shape)\n",
    "# print(\"saved gradient\")\n",
    "\n",
    "vopt_xt_fname = \"%s/%s/vopt_xt.dat\" % (os.path.abspath(\"./\"), id_prefix)\n",
    "np.savetxt(vopt_xt_fname, vopt_xt)\n",
    "print(\"\")\n",
    "print(\"vopt_xt\")\n",
    "print(vopt_xt)\n",
    "print(\"saved vopt_xt\")\n",
    "\n",
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efb5a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23 get tf gradient with model restored from file\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(inp_tensor)\n",
    "\n",
    "    # restored_preds = model_restored.net(inp_tensor)\n",
    "    \n",
    "    # you can take gradient of BOTH psi / rho w.r.t. input\n",
    "    # but we only care about psi model.net[:, 0]\n",
    "    restored_psi = model_restored.net(inp_tensor)[:, 0]\n",
    "\n",
    "######################################\n",
    "  \n",
    "# print(\"\")\n",
    "# print(\"restored_preds\")\n",
    "# print(restored_preds)\n",
    "\n",
    "print(\"\")\n",
    "print(\"restored_psi\")\n",
    "print(restored_psi)\n",
    "\n",
    "######################################\n",
    "\n",
    "print(\"\")\n",
    "print(\"test output\")\n",
    "# print(test_timesorted[:, 4:6])\n",
    "print(test_timesorted[:, 4])\n",
    "\n",
    "######################################\n",
    "\n",
    "# restored_gradient = tape.gradient(restored_preds, inp_tensor)\n",
    "# restored_gradient = restored_gradient.numpy()\n",
    "\n",
    "restored_vopt_xt = tape.gradient(restored_psi, inp_tensor)\n",
    "restored_vopt_xt = restored_vopt_xt.numpy()\n",
    "\n",
    "######################################\n",
    "\n",
    "print(\"\")\n",
    "print(\"restored_vopt_xt\")\n",
    "print(restored_vopt_xt)\n",
    "\n",
    "# restored_gradient_fname = \"%s/%s/restored_gradient.dat\" % (os.path.abspath(\"./\"), id_prefix)\n",
    "# np.savetxt(restored_gradient_fname, restored_gradient)\n",
    "# print(\"\")\n",
    "# print(\"restored_gradient\")\n",
    "# print(restored_gradient, restored_gradient.shape)\n",
    "# print(\"saved restored_gradient\")\n",
    "\n",
    "# restored_vopt_xt_fname = \"%s/%s/restored_vopt_xt.dat\" % (os.path.abspath(\"./\"), id_prefix)\n",
    "# np.savetxt(restored_vopt_xt_fname, restored_vopt_xt)\n",
    "# print(\"saved restored_vopt_xt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a4de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24 load matlab gradient from file\n",
    "\n",
    "matlab_v_name = \"%s/%s\" % (os.path.abspath(\"./\"), 'matlab_vopt_xt.mat')\n",
    "restored_vopt_xt = scipy.io.loadmat(matlab_v_name)[\"vopt_xt\"]\n",
    "restored_vopt_xt = np.nan_to_num(restored_vopt_xt, copy=False)\n",
    "\n",
    "print(restored_vopt_xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4028f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25 shuffle rows, recompute tf gradient, and sort again and compare\n",
    "# shows that gradient does NOT depend on ordering of rows\n",
    "\n",
    "np.random.shuffle(test)\n",
    "inp_shuffled = test[:, 0:4] # x1, x2, x3, t\n",
    "inp_shuffled_tensor = tf.convert_to_tensor(inp_shuffled, dtype=tf.float32)\n",
    "ind = np.lexsort((test[:,4],test[:,3])) # sorts by [3] (t) then by [4] (psi)\n",
    "# sort AGAIN by output because a lot of samples @ t=0, t=5\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(inp_shuffled_tensor)\n",
    "\n",
    "    # shuffled_preds = model_restored.net(inp_shuffled_tensor)\n",
    "\n",
    "    # you can take gradient of BOTH psi / rho w.r.t. input\n",
    "    # but we only care about psi model.net[:, 0]\n",
    "    shuffled_psi = model_restored.net(inp_shuffled_tensor)[:, 0]\n",
    "\n",
    "######################################\n",
    "  \n",
    "# print(\"\")\n",
    "# print(\"shuffled_preds\")\n",
    "# print(shuffled_preds)\n",
    "\n",
    "print(\"\")\n",
    "print(\"shuffled_psi\")\n",
    "print(shuffled_psi)\n",
    "\n",
    "######################################\n",
    "\n",
    "print(\"\")\n",
    "print(\"test output\")\n",
    "# print(test[:, 4:6])\n",
    "print(test[:, 4])\n",
    "\n",
    "######################################\n",
    "\n",
    "# shuffled_gradient = tape.gradient(shuffled_preds, inp_shuffled_tensor)\n",
    "# shuffled_gradient = shuffled_gradient.numpy()\n",
    "\n",
    "shuffled_vopt_xt = tape.gradient(shuffled_psi, inp_shuffled_tensor)\n",
    "shuffled_vopt_xt = shuffled_vopt_xt.numpy()\n",
    "\n",
    "######################################\n",
    "\n",
    "# shuffled_gradient_sorted = shuffled_gradient[ind]\n",
    "shuffled_vopt_xt_sorted = shuffled_vopt_xt[ind]\n",
    "\n",
    "print(\"\")\n",
    "# print(\"shuffled_gradient_sorted\")\n",
    "# print(shuffled_gradient_sorted, shuffled_gradient_sorted.shape)\n",
    "print(\"shuffled_vopt_xt_sorted\")\n",
    "print(shuffled_vopt_xt_sorted, shuffled_vopt_xt_sorted.shape)\n",
    "\n",
    "# if this matches restored_gradient and gradient, that means this gradient is order invariant and is 'real'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53253071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a5707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26 make interp source grids, save\n",
    "\n",
    "vinterp_N = 50\n",
    "vinterp_T = 50\n",
    "\n",
    "x_1_ = np.linspace(state_min, state_max, vinterp_N)\n",
    "x_2_ = np.linspace(state_min, state_max, vinterp_N)\n",
    "x_3_ = np.linspace(state_min, state_max, vinterp_N)\n",
    "t_ = np.linspace(0, T_t, vinterp_T)\n",
    "\n",
    "end_grid_x1, end_grid_x2, end_grid_x3 = np.meshgrid(\n",
    "  x_1_,\n",
    "  x_2_,\n",
    "  x_3_, copy=False)\n",
    "\n",
    "mid_grid_x1, mid_grid_x2, mid_grid_x3, mid_grid_t = np.meshgrid(\n",
    "  x_1_,\n",
    "  x_2_,\n",
    "  x_3_,\n",
    "  t_, copy=False)\n",
    "\n",
    "save = False\n",
    "if save:\n",
    "    x1_x2_x3_t = {\n",
    "        \"x_1_\" : x_1_,\n",
    "        \"x_2_\" : x_2_,\n",
    "        \"x_3_\" : x_3_,\n",
    "        \"t_\" : t_,\n",
    "    }\n",
    "    mat_fname = '%s/%s/post_predict_x1_x2_x3_t.mat' % (\n",
    "        os.path.abspath(\"./\"),\n",
    "        id_prefix)\n",
    "    scipy.io.savemat(mat_fname, x1_x2_x3_t)\n",
    "    print(\"saved mat\", mat_fname)\n",
    "    \n",
    "print(mid_grid_x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8417a869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27 interpolate AFTER predict, t=0\n",
    "\n",
    "test_t0 = test_timesorted[np.where(np.abs(source_t) < 1e-8), :][0] # 2k\n",
    "\n",
    "source_x1 = test_t0[:, 0]\n",
    "source_x2 = test_t0[:, 1]\n",
    "source_x3 = test_t0[:, 2]\n",
    "\n",
    "# print(np.where(np.abs(source_t) < 1e-8))\n",
    "\n",
    "# print(restored_vopt_xt.shape)\n",
    "t0_vopt_xt = vopt_xt[np.where(np.abs(source_t) < 1e-8), :][0] # nx4\n",
    "t0_v1 = t0_vopt_xt[:, 0]\n",
    "t0_v2 = t0_vopt_xt[:, 1]\n",
    "t0_v3 = t0_vopt_xt[:, 2]\n",
    "\n",
    "print(t0_vopt_xt.shape)\n",
    "\n",
    "t0_V1 = gd(\n",
    "  (source_x1, source_x2, source_x3),\n",
    "  t0_v1,\n",
    "  (end_grid_x1, end_grid_x2, end_grid_x3),\n",
    "  method='nearest')\n",
    "\n",
    "t0_V2 = gd(\n",
    "  (source_x1, source_x2, source_x3),\n",
    "  t0_v2,\n",
    "  (end_grid_x1, end_grid_x2, end_grid_x3),\n",
    "  method='nearest')\n",
    "\n",
    "t0_V3 = gd(\n",
    "  (source_x1, source_x2, source_x3),\n",
    "  t0_v3,\n",
    "  (end_grid_x1, end_grid_x2, end_grid_x3),\n",
    "  method='nearest')\n",
    "\n",
    "print(t0_V1.shape)\n",
    "\n",
    "save = True\n",
    "if save:\n",
    "    import scipy.io\n",
    "    v = {\n",
    "        \"t0_V1\" : t0_V1,\n",
    "        \"t0_V2\" : t0_V2,\n",
    "        \"t0_V3\" : t0_V3,\n",
    "    }\n",
    "    mat_fname = '%s/%s/notebook_post_predict_t0_%d_%d_v.mat' % (\n",
    "        os.path.abspath(\"./\"),\n",
    "        id_prefix,\n",
    "        vinterp_N,\n",
    "        vinterp_T)\n",
    "    scipy.io.savemat(mat_fname, v)\n",
    "    print(\"saved mat\", mat_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b38838a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc5c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28 interpolate AFTER predict, middle\n",
    "\n",
    "# middle = test_timesorted[(source_t < 5.0) & (source_t > 0.0), :] # 16k - 4k = 12k\n",
    "\n",
    "middle = test_timesorted\n",
    "\n",
    "source_x1 = middle[:, 0]\n",
    "source_x2 = middle[:, 1]\n",
    "source_x3 = middle[:, 2]\n",
    "source_t_ = middle[:, 3]\n",
    "\n",
    "# middle_vopt_xt = vopt_xt[(source_t < 5.0) & (source_t > 0.0), :]\n",
    "middle_vopt_xt = vopt_xt\n",
    "\n",
    "middle_v1 = middle_vopt_xt[:, 0]\n",
    "middle_v2 = middle_vopt_xt[:, 1]\n",
    "middle_v3 = middle_vopt_xt[:, 2]\n",
    "\n",
    "print(middle_vopt_xt.shape)\n",
    "\n",
    "mid_V1 = gd(\n",
    "  (source_x1, source_x2, source_x3, source_t_),\n",
    "  middle_v1,\n",
    "  (mid_grid_x1, mid_grid_x2, mid_grid_x3, mid_grid_t),\n",
    "  method='nearest')\n",
    "\n",
    "mid_V2 = gd(\n",
    "  (source_x1, source_x2, source_x3, source_t_),\n",
    "  middle_v2,\n",
    "  (mid_grid_x1, mid_grid_x2, mid_grid_x3, mid_grid_t),\n",
    "  method='nearest')\n",
    "\n",
    "mid_V3 = gd(\n",
    "  (source_x1, source_x2, source_x3, source_t_),\n",
    "  middle_v3,\n",
    "  (mid_grid_x1, mid_grid_x2, mid_grid_x3, mid_grid_t),\n",
    "  method='nearest')\n",
    "\n",
    "print(mid_V1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c803d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29 save mid to file\n",
    "\n",
    "import scipy.io\n",
    "v = {\n",
    "    \"mid_V1\" : mid_V1,\n",
    "    \"mid_V2\" : mid_V2,\n",
    "    \"mid_V3\" : mid_V3,\n",
    "}\n",
    "mat_fname = '%s/%s/notebook_post_predict_mid_%d_%d_v.mat' % (\n",
    "    os.path.abspath(\"./\"),\n",
    "    id_prefix,\n",
    "    vinterp_N,\n",
    "    vinterp_T)\n",
    "print(\"abt to save\")\n",
    "scipy.io.savemat(mat_fname, v)\n",
    "print(\"saved mat\", mat_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc85368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(mid_V3), np.min(mid_V3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a57d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 interpolate AFTER predict, t=5\n",
    "\n",
    "target_t = 5.0\n",
    "target_thresh = 1e-8\n",
    "\n",
    "ind = np.where(np.abs(source_t-target_t) < target_thresh)\n",
    "\n",
    "test_t5 = test_timesorted[ind, :][0] # 2k\n",
    "\n",
    "source_x1 = test_t5[:, 0]\n",
    "source_x2 = test_t5[:, 1]\n",
    "source_x3 = test_t5[:, 2]\n",
    "\n",
    "# print(np.where(np.abs(source_t) < 1e-8))\n",
    "\n",
    "# print(restored_vopt_xt.shape)\n",
    "t5_vopt_xt = restored_vopt_xt[ind, :][0]\n",
    "t5_v1 = t5_vopt_xt[:, 0]\n",
    "t5_v2 = t5_vopt_xt[:, 1]\n",
    "t5_v3 = t5_vopt_xt[:, 2]\n",
    "\n",
    "print(t5_vopt_xt.shape)\n",
    "\n",
    "t5_V1 = gd(\n",
    "  (source_x1, source_x2, source_x3),\n",
    "  t5_v1,\n",
    "  (end_grid_x1, end_grid_x2, end_grid_x3),\n",
    "  method='nearest')\n",
    "\n",
    "t5_V2 = gd(\n",
    "  (source_x1, source_x2, source_x3),\n",
    "  t5_v2,\n",
    "  (end_grid_x1, end_grid_x2, end_grid_x3),\n",
    "  method='nearest')\n",
    "\n",
    "t5_V3 = gd(\n",
    "  (source_x1, source_x2, source_x3),\n",
    "  t5_v3,\n",
    "  (end_grid_x1, end_grid_x2, end_grid_x3),\n",
    "  method='nearest')\n",
    "\n",
    "print(t5_V1.shape)\n",
    "\n",
    "save = True\n",
    "if save:\n",
    "    import scipy.io\n",
    "    v = {\n",
    "        \"t5_V1\" : t5_V1,\n",
    "        \"t5_V2\" : t5_V2,\n",
    "        \"t5_V3\" : t5_V3,\n",
    "    }\n",
    "    mat_fname = '%s/%s/post_predict_t5_%d_%d_v.mat' % (\n",
    "        os.path.abspath(\"./\"),\n",
    "        id_prefix,\n",
    "        vinterp_N,\n",
    "        vinterp_T)\n",
    "    scipy.io.savemat(mat_fname, v)\n",
    "    print(\"saved mat\", mat_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb283eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 31 plot V1\n",
    "\n",
    "fig1 = plt.figure()\n",
    "ax1=fig1.gca(projection='3d')\n",
    "sc1=ax1.scatter(source_x1, source_x2, source_x3, c=t5_v2, cmap=plt.hot())\n",
    "plt.colorbar(sc1)\n",
    "ax1.set_xlabel('x1')\n",
    "ax1.set_ylabel('x2')\n",
    "ax1.set_zlabel('x3')\n",
    "ax1.set_title('source data t=%.3f' % (target_t))\n",
    "\n",
    "#Plot interpolated values\n",
    "fig2 = plt.figure()\n",
    "ax2=fig2.gca(projection='3d')\n",
    "sc2=ax2.scatter(end_grid_x1, end_grid_x2, end_grid_x3, c=t5_V2, cmap=plt.hot())\n",
    "plt.colorbar(sc2)\n",
    "ax2.set_xlabel('x1')\n",
    "ax2.set_ylabel('x2')\n",
    "ax2.set_zlabel('x3')\n",
    "ax2.set_title('grid data t=%.3f' % (target_t))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da6e831",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(t0_V1)*j1)\n",
    "print(np.max(t0_V2)*j2)\n",
    "print(np.max(t0_V3)*j3)\n",
    "\n",
    "print(\"#####\")\n",
    "\n",
    "print(np.min(t0_V1)*j1)\n",
    "print(np.min(t0_V2)*j2)\n",
    "print(np.min(t0_V3)*j3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9163c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32 sampling t0 vs\n",
    "\n",
    "sampl = np.random.uniform(low=state_min, high=state_max, size=(1,3))\n",
    "\n",
    "print(sampl)\n",
    "\n",
    "closest_1 = [(np.abs(x_1_ - sampl[i, 0])).argmin() for i in range(sampl.shape[0])]\n",
    "closest_2 = [(np.abs(x_2_ - sampl[i, 1])).argmin() for i in range(sampl.shape[0])]\n",
    "closest_3 = [(np.abs(x_3_ - sampl[i, 2])).argmin() for i in range(sampl.shape[0])]\n",
    "\n",
    "print(sampl[:, 0])\n",
    "print(x_1_[closest_1])\n",
    "print(closest_1)\n",
    "\n",
    "v1s = t0_V1[closest_1, closest_2, closest_3]\n",
    "v2s = t0_V2[closest_1, closest_2, closest_3]\n",
    "v3s = t0_V3[closest_1, closest_2, closest_3]\n",
    "\n",
    "print(v1s)\n",
    "\n",
    "sampl = sampl[0, :]\n",
    "print(sampl)\n",
    "\n",
    "closest_1 = (np.abs(x_1_ - sampl[0])).argmin()\n",
    "closest_2 = (np.abs(x_2_ - sampl[1])).argmin()\n",
    "closest_3 = (np.abs(x_3_ - sampl[2])).argmin()\n",
    "\n",
    "v1s = t0_V1[closest_1, closest_2, closest_3]\n",
    "v2s = t0_V2[closest_1, closest_2, closest_3]\n",
    "v3s = t0_V3[closest_1, closest_2, closest_3]\n",
    "\n",
    "print(v1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fc2d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 33 sampling middle vs\n",
    "\n",
    "sampl = np.random.uniform(low=state_min, high=state_max, size=(1,4))\n",
    "sampl[0,3] = np.random.uniform(low=0.1, high=4.9)\n",
    "\n",
    "closest_1 = [(np.abs(x_1_ - sampl[i, 0])).argmin() for i in range(sampl.shape[0])]\n",
    "closest_2 = [(np.abs(x_2_ - sampl[i, 1])).argmin() for i in range(sampl.shape[0])]\n",
    "closest_3 = [(np.abs(x_3_ - sampl[i, 2])).argmin() for i in range(sampl.shape[0])]\n",
    "closest_t = [(np.abs(t_ - sampl[i, 3])).argmin() for i in range(sampl.shape[0])]\n",
    "\n",
    "print(sampl[:, 0])\n",
    "print(x_1_[closest_1])\n",
    "print(closest_1)\n",
    "\n",
    "print(sampl[:, 3])\n",
    "print(t_[closest_t])\n",
    "print(closest_t)\n",
    "\n",
    "v1s = mid_V1[closest_1, closest_2, closest_3, closest_t]\n",
    "v2s = mid_V2[closest_1, closest_2, closest_3, closest_t]\n",
    "v3s = mid_V3[closest_1, closest_2, closest_3, closest_t]\n",
    "\n",
    "print(v1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e213014",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(t0_V1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce53f1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 34 interpolate BEFORE predict\n",
    "\n",
    "# turn grid to table\n",
    "table = np.vstack([grid_x1.reshape(-1), grid_x2.reshape(-1), grid_x3.reshape(-1), grid_t.reshape(-1)]).T\n",
    "table = table[np.lexsort((table[:, 3], table[:,2], table[:,1], table[:,0]))]\n",
    "print(table, table.shape)\n",
    "\n",
    "table_tensor = tf.convert_to_tensor(table, dtype=tf.float32)\n",
    "ind = np.lexsort((test[:,4],test[:,3])) # sorts by [3] (t) then by [4] (psi)\n",
    "# sort AGAIN by output because a lot of samples @ t=0, t=5\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(table_tensor)\n",
    "\n",
    "    # table_preds = model_restored.net(table_tensor)\n",
    "\n",
    "    # you can take gradient of BOTH psi / rho w.r.t. input\n",
    "    # but we only care about psi model.net[:, 0]\n",
    "    table_psi = model_restored.net(table_tensor)[:, 0]\n",
    "\n",
    "table_vopt_xt = tape.gradient(table_psi, table_tensor)\n",
    "table_vopt_xt = table_vopt_xt.numpy()\n",
    "\n",
    "print(\"\")\n",
    "print(\"table_vopt_xt\")\n",
    "print(table_vopt_xt)\n",
    "\n",
    "table_vopt_xt_fname = \"%s/%s/table_vopt_xt.dat\" % (\n",
    "    os.path.abspath(\"./\"),\n",
    "    id_prefix)\n",
    "np.savetxt(table_vopt_xt_fname, table_vopt_xt)\n",
    "print(\"saved table_vopt_xt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877944e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d15ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35 plot rho at t=5, t=0\n",
    "\n",
    "target_t = 5.0\n",
    "\n",
    "N = 50\n",
    "\n",
    "test_timesorted = test[test[:, 3].argsort()]\n",
    "timesorted = test_timesorted[:, 3]\n",
    "test_ti = test_timesorted[np.where(np.abs(timesorted - target_t) < 1e-8), :][0] # 2k\n",
    "\n",
    "ti_rho_opt = test_ti[:, 5]\n",
    "ti_x1_x2_x3 = test_ti[:, 0:3]\n",
    "\n",
    "####################################################################\n",
    "\n",
    "d = 0.0\n",
    "x1 = np.linspace(state_min - d, state_max + d, N)\n",
    "x2 = np.linspace(state_min - d, state_max + d, N)\n",
    "x3 = np.linspace(state_min - d, state_max + d, N)\n",
    "X1, X2, X3 = np.meshgrid(x1,x2,x3,copy=False) # each is NxNxN\n",
    "\n",
    "rho_opt = np.zeros((N,N,N))\n",
    "\n",
    "closest_1 = [(np.abs(x1 - ti_x1_x2_x3[i, 0])).argmin() for i in range(ti_x1_x2_x3.shape[0])]\n",
    "closest_2 = [(np.abs(x2 - ti_x1_x2_x3[i, 1])).argmin() for i in range(ti_x1_x2_x3.shape[0])]\n",
    "closest_3 = [(np.abs(x3 - ti_x1_x2_x3[i, 2])).argmin() for i in range(ti_x1_x2_x3.shape[0])]\n",
    "\n",
    "# some transposing going on in some reshape\n",
    "# swapping closest_1/2 works well\n",
    "rho_opt[closest_2, closest_1, closest_3] = ti_rho_opt\n",
    "\n",
    "####################################################################\n",
    "\n",
    "# RHO_OPT = gd(\n",
    "#   (ti_x1_x2_x3[:, 0], ti_x1_x2_x3[:, 1], ti_x1_x2_x3[:, 2]),\n",
    "#   ti_rho_opt,\n",
    "#   (X1, X2, X3),\n",
    "#   method='linear')\n",
    "\n",
    "####################################################################\n",
    "\n",
    "x1_marginal = np.array([\n",
    "    np.trapz(\n",
    "        np.array([\n",
    "            np.trapz(rho_opt[j, i, :], x=x3) # x3 slices for one x2 => R\n",
    "            for i in range(len(x2))]) # x3 slices across all x2 => Rn\n",
    "        , x=x2) # x2 slice for one x1 => R\n",
    "for j in range(len(x1))])\n",
    "\n",
    "x2_marginal = np.array([\n",
    "    np.trapz(\n",
    "        np.array([\n",
    "            np.trapz(rho_opt[i, j, :], x=x3) # x3 slices for one x1 => R\n",
    "            for i in range(len(x1))]) # x3 slices across all x1 => Rn\n",
    "        , x=x1) # x1 slice for one x2 => R\n",
    "for j in range(len(x2))])\n",
    "\n",
    "x3_marginal = np.array([\n",
    "    np.trapz(\n",
    "        np.array([\n",
    "            np.trapz(rho_opt[i, :, j], x=x2) # x2 slices for one x1 => R\n",
    "            for i in range(len(x1))]) # x2 slices across all x1 => Rn\n",
    "        , x=x1) # x1 slice for one x3 => R\n",
    "for j in range(len(x3))])\n",
    "\n",
    "####################################################################\n",
    "\n",
    "# normalize all the pdfs so area under curve ~= 1.0\n",
    "x1_pdf_area = np.trapz(x1_marginal, x=x1)\n",
    "x2_pdf_area = np.trapz(x2_marginal, x=x2)\n",
    "x3_pdf_area = np.trapz(x3_marginal, x=x3)\n",
    "print(\"prior to normalization: %.2f, %.2f, %.2f\" % (\n",
    "    x1_pdf_area,\n",
    "    x2_pdf_area,\n",
    "    x3_pdf_area))\n",
    "\n",
    "x1_marginal /= x1_pdf_area\n",
    "x2_marginal /= x2_pdf_area\n",
    "x3_marginal /= x3_pdf_area\n",
    "\n",
    "x1_pdf_area = np.trapz(x1_marginal, x=x1)\n",
    "x2_pdf_area = np.trapz(x2_marginal, x=x2)\n",
    "x3_pdf_area = np.trapz(x3_marginal, x=x3)\n",
    "print(\"after to normalization: %.2f, %.2f, %.2f\" % (\n",
    "    x1_pdf_area,\n",
    "    x2_pdf_area,\n",
    "    x3_pdf_area))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20059796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35 plot rho at t=5, t=0\n",
    "\n",
    "fig = plt.figure(1)\n",
    "ax1 = plt.subplot(131, frameon=False)\n",
    "# ax1.set_aspect('equal')\n",
    "ax1.grid()\n",
    "ax1.set_title('x1 marginal')\n",
    "\n",
    "ax2 = plt.subplot(132, frameon=False)\n",
    "# ax2.set_aspect('equal')\n",
    "ax2.grid()\n",
    "ax2.set_title('x2 marginal')\n",
    "\n",
    "# ax3 = plt.subplot(133, frameon=False)\n",
    "\n",
    "ax3 = plt.subplot(133, frameon=False)\n",
    "# ax3.set_aspect('equal')\n",
    "ax3.grid()\n",
    "ax3.set_title('x3 marginal')\n",
    "\n",
    "colors=\"rgbymkc\"\n",
    "\n",
    "i = 0\n",
    "t_e = 0\n",
    "ax1.plot(x1,\n",
    "    x1_marginal,\n",
    "    colors[i % len(colors)],\n",
    "    linewidth=1,\n",
    "    label=t_e)\n",
    "ax1.legend(loc='lower right')\n",
    "\n",
    "ax2.plot(x2,\n",
    "    x2_marginal,\n",
    "    colors[i % len(colors)],\n",
    "    linewidth=1,\n",
    "    label=t_e)\n",
    "ax2.legend(loc='lower right')\n",
    "\n",
    "ax3.plot(x3,\n",
    "    x3_marginal,\n",
    "    colors[i % len(colors)],\n",
    "    linewidth=1,\n",
    "    label=t_e)\n",
    "ax3.legend(loc='lower right')\n",
    "\n",
    "fig.suptitle('t=%.2f' % (target_t), fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba699bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9c6889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e873187a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741dbdd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e26b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5699f4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deba1752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8703b35b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb09cbd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6f55d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78feaa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aab644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dadcec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6deec07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f53d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd037056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e158f7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d694147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd940673",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
