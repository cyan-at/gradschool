{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1. [60 points] Making Sandcastle\n",
    "\n",
    "Grad student Alice is at Cancun to spend her end-of-the-year vacation. Relaxing at the beautiful white sand beach, she contemplates making a sandcastle while minimizing her effort to construct it. \n",
    "\n",
    "Alice approximates the sandy beach as part of a 2D plane. She decides to move the sand mass from $m$ known source locations $x_{i}^{\\text{source}}\\in\\mathbb{R}^{2}$, $i=1,...,m$, to $n$ known destination locations $x_{j}^{\\text{sandcastle}}\\in\\mathbb{R}^{2}$ , $j=1,...,n$. \n",
    "\n",
    "Sand particles in the beach have nonuniform mass. In particular, the $i$th source location has a known mass $\\alpha_i>0$, $i=1,...,m$. Alice's sandcastle design requires the $j$th destination location to have a known mass $\\beta_j>0$, $j=1,...,n$. Conservation of mass requires $\\sum_{i}\\alpha_i = \\sum_{j}\\beta_{j}$. Without loss of generality, Alice normalizes the mass, i.e., sets $\\sum_{i}\\alpha_i = \\sum_{j}\\beta_{j}=1$. In other words, known $\\alpha_i$ denotes the fraction of total mass at the $i$th source location. Similar interpretation holds for $\\beta_{j}$.\n",
    "\n",
    "Alice models the cost $C_{ij}$ of moving **unit amout of sand** from the source location $x_{i}^{\\text{source}}$ to the destination location $x_{j}^{\\text{sandcastle}}$ as squared Euclidean distance, i.e., $C_{ij} = \\|x_{i}^{\\text{source}} - x_{j}^{\\text{sandcastle}}\\|_{2}^{2}$. This defines a matrix $C\\equiv [C_{ij}]\\in\\mathbb{R}^{m\\times n}$. \n",
    "\n",
    "## (a) [5 + 10 + (5 + 5) + 10 = 35 points] Formulation\n",
    "\n",
    "(i) **Explain why** Alice's model for $C_{ij}$ is reasonable. \n",
    "\n",
    "(ii) If Alice decides to move $M_{ij}$ amount of mass from $x_{i}^{\\text{source}}$ to $x_{j}^{\\text{sandcastle}}$, then she incurs a cost $C_{ij}M_{ij}$ for that particular route. Taking the matrix $M\\equiv [M_{ij}]\\in\\mathbb{R}^{m\\times n}$ as the decision variable, **clearly write down the optimization problem** Alice needs to solve for making her sandcastle. The input parameters for the problem should be the matrix $C\\in\\mathbb{R}^{m\\times n}$, the vector $\\alpha\\in\\mathbb{R}^{m}_{++}$, and the vector $\\beta\\in\\mathbb{R}^{n}_{++}$. Assume that the problem data already guarantees $\\langle\\boldsymbol{1}_{m},\\alpha\\rangle = \\langle\\boldsymbol{1}_{n},\\beta\\rangle = 1$ where $\\boldsymbol{1}_{m},\\boldsymbol{1}_{n}$ denote the vector of all ones of size $m\\times 1$ and $n\\times 1$, respectively.\n",
    "\n",
    "(iii) **Mathematically explain why** this is a convex optimization problem. **Mathematically argue what type** of convex optimization problem is this.\n",
    "\n",
    "Side remark: Unlike the exercises in HW5 Problem 2, this problem has no analytical solution in terms of the problem data.\n",
    "\n",
    "(iv) **Carefully argue the size of the optimization problem**, i.e., how many variables are to be solved for and how many constraints are there.\n",
    "\n",
    "## (b) [25 points] Numerical solution\n",
    "\n",
    "Fix $m=150$, $n=225$. Write a code in MATLAB/Python/Julia to load the input from CANVAS Files section: HW problems and solutions: alpha.txt, beta.txt, x_source.txt, x_sandcastle.txt, and use cvx/cvxpy/Convex.jl in the same code to solve the optimization problem in part (a). Report the **numerically computed optimal value (minimized cost) and submit your code**. **Also report the computational time needed to solve the problem by cvx/cvxpy/Convex.jl** (only the computational time for solving, not for setting up the problem data).\n",
    "\n",
    "Side remark: It is recommended (but not required) that in your code, you also check if your optimal solution obtained from using cvx/cvxpy/Convex.jl matches with linprog in MATLAB, or with scipy.optimize.linprog in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.\n",
    "1. We can see that $C_{ij} = \\|x_{i}^{\\text{source}} - x_{j}^{\\text{sandcastle}}\\|_{2}^{2} = $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2. [15 + 15 + 10 = 40 points] Lagrange Dual Problem\n",
    "\n",
    "Consider the primal convex optimization problem\n",
    "\\begin{align}\n",
    "p^{*} = &\\underset{x\\in\\mathbb{R}^{n}}{\\min}\\quad\\frac{1}{2}x^{\\top}P_{0}x + \\langle q_0, x\\rangle + r_0\\\\\n",
    "&\\text{subject to} \\quad \\frac{1}{2}x^{\\top}P_{i}x + \\langle q_i, x\\rangle + r_i \\leq 0, \\quad\\forall\\,i=1,...,m,\n",
    "\\end{align}\n",
    "where $P_0\\in\\mathbb{S}^{n}_{+}$, $P_{i}\\in\\mathbb{S}^{n}_{++}$ for all $i=1,...,m$, $q_i\\in\\mathbb{R}^{n}$ for all $i=0,1,...,m$, and $r_i\\in\\mathbb{R}$ for all $i=0,1,...,m$.\n",
    "\n",
    "(a) Denote the Lagrange multiplier associated with the primal inequality constraints as $\\lambda\\in\\mathbb{R}^{m}_{\\geq 0}$. Let\n",
    "\\begin{align}\n",
    "P(\\lambda) := P_{0} + \\sum_{i=1}^{m}\\lambda_i P_i \\succ 0,\\quad q(\\lambda) &:= q_0 + \\sum_{i=1}^{m}\\lambda_i q_i,\\quad r(\\lambda) := r_0 + \\sum_{i=1}^{m}\\lambda_i r_i.\n",
    "\\end{align}\n",
    "**Prove that** the Lagrange dual problem associated with the primal problem is \n",
    "$$d^{*} = \\underset{\\lambda\\in\\mathbb{R}^{m}_{\\geq 0}}{\\min}\\:\\frac{1}{2}\\left(q(\\lambda)\\right)^{\\top}\\left(P(\\lambda)\\right)^{-1}q(\\lambda) - r(\\lambda).$$\n",
    "\n",
    "(b) Rewrite the Lagrange dual problem derived in part (a) in one of the standard forms: LP, QP, QCQP, SOCP, SDP. **Show all your calculations**.\n",
    "\n",
    "(c) Specialize Slater's condition for this primal problem to **state a sufficient condition for strong duality** ($p^{*}=d^{*}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a\n",
    "1.\n",
    "\\begin{align}\n",
    "\\mathcal{L}(\\underline{x}, \\underline{\\lambda}) & = \\frac{1}{2}x^{\\top}P_{0}x + \\langle q_0, x\\rangle + r_0 + \\langle \\lambda, \\frac{1}{2}x^{\\top}P_{i}x + \\langle q_i, x\\rangle + r_i \\rangle \\\\\n",
    "& = \\frac{1}{2}x^{\\top}P_{0}x + \\langle q_0, x\\rangle + r_0 + \\sum_{i=1}^{m}\\lambda_i \\frac{1}{2}x^{\\top}P_{i}x + \\sum_{i=1}^{m}\\lambda_i \\langle q_i, x\\rangle + \\sum_{i=1}^{m}\\lambda_i r_i \\\\\n",
    "& = \\frac{1}{2}x^{\\top}P_{0} x + \\frac{1}{2} \\sum_{i=1}^{m} x^{\\top}\\lambda_i P_{i} x + \\langle q_0, x\\rangle + \\sum_{i=1}^{m}\\lambda_i \\langle q_i, x\\rangle + r_0 + \\sum_{i=1}^{m}\\lambda_i r_i \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
