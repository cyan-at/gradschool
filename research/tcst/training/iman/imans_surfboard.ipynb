{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64431653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA RTX A2000 Laptop GPU\n",
      "11.6\n",
      "0\n",
      "pytorch\n",
      "trying\n",
      "no SDE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/deepxde/backend/pytorch/tensor.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(initial_value, dtype=dtype, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "'''\n",
    "run ./train.py --sdept ../../trained_sde_model/4fold_3_2_layer_model.pt\n",
    "'''\n",
    "\n",
    "# 0 define backend\n",
    "import sys, os, time\n",
    "import argparse\n",
    "import glob\n",
    "\n",
    "# %env DDE_BACKEND=tensorflow.compat.v1\n",
    "# %env XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/home/cyan3/miniforge/envs/tf\n",
    "\n",
    "os.environ['DDE_BACKEND'] = \"pytorch\" # v2\n",
    "os.environ['XLA_FLAGS'] = \"--xla_gpu_cuda_data_dir=/usr/local/home/cyan3/miniforge/envs/tf\"\n",
    "\n",
    "# https://stackoverflow.com/questions/68614547/tensorflow-libdevice-not-found-why-is-it-not-found-in-the-searched-path\n",
    "# this directory has /nvvm/libdevice/libdevice.10.bc\n",
    "\n",
    "print(os.environ['DDE_BACKEND'])\n",
    "\n",
    "import torch\n",
    "torch.set_printoptions(precision=3)\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.current_device())\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html\n",
    "try:\n",
    "    torch.jit.enable_onednn_fusion(True)\n",
    "except:\n",
    "    print(\"no onednn\")\n",
    "\n",
    "cuda0 = torch.device('cuda:0')\n",
    "cpu = torch.device('cpu')\n",
    "device = cuda0\n",
    "\n",
    "import deepxde as dde\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "from os.path import dirname, join as pjoin\n",
    "from scipy import stats\n",
    "import scipy.io\n",
    "from scipy.stats import truncnorm, norm\n",
    "from scipy.optimize import linprog\n",
    "from scipy import sparse\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.spatial.distance import cdist\n",
    "if dde.backend.backend_name == \"pytorch\":\n",
    "    exp = dde.backend.torch.exp\n",
    "else:\n",
    "    from deepxde.backend import tf\n",
    "    exp = tf.exp\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "from scipy.linalg import solve_discrete_are\n",
    "from scipy.linalg import sqrtm as sqrtm2\n",
    "\n",
    "######################################\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "\n",
    "sys.path.insert(0,'..')\n",
    "from layers import *\n",
    "\n",
    "sde_path = '../../sde/T_t200_2D/'\n",
    "sys.path.insert(0,sde_path)\n",
    "from trained_sde_model import *\n",
    "\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "616dda21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tcst1(x, y, network_f, network_g, args):\n",
    "    psi, rho, u1, u2 = y[:, 0:1], y[:, 1:2], y[:, 2:3], y[:, 3:4]\n",
    "\n",
    "    # x = c10, c12, t\n",
    "\n",
    "    # psi eq (4a), rho eq (4b), u1 eq (6), u2 eq (6)\n",
    "    dpsi_c10 = dde.grad.jacobian(psi, x, j=0)\n",
    "    dpsi_c12 = dde.grad.jacobian(psi, x, j=1)\n",
    "    dpsi_t = dde.grad.jacobian(psi, x, j=2)\n",
    "\n",
    "    hpsi_c10 = dde.grad.hessian(psi, x, i=0, j=0)\n",
    "    hpsi_c12 = dde.grad.hessian(psi, x, i=1, j=1)\n",
    "\n",
    "    drho_t = dde.grad.jacobian(rho, x, j=2)\n",
    "\n",
    "    drho_c10 = dde.grad.hessian(rho, x, i=0, j=0)\n",
    "    drho_c12 = dde.grad.hessian(rho, x, i=1, j=1)\n",
    "\n",
    "    # d1\n",
    "    leaf_x = x[:, 0:2].detach()\n",
    "    leaf_u1_u2 = y[:, 2:4].detach()\n",
    "    leaf_t = x[:, 2].detach().unsqueeze(1)\n",
    "\n",
    "    ###########################################\n",
    "\n",
    "    leaf_vec = torch.cat(\n",
    "        (\n",
    "            x[:, 0:2], # leaf_x,\n",
    "            # i think this makes sense since we\n",
    "            # take jacobian of it w.r.t x for divergence\n",
    "            y[:, 2:4],\n",
    "            x[:, 2].unsqueeze(1),\n",
    "        ),\n",
    "        dim=1)\n",
    "    leaf_vec = leaf_vec.requires_grad_(True)\n",
    "\n",
    "    d1 = network_f.forward(leaf_vec)\n",
    "    d2 = network_g.forward(leaf_vec)**2 / 2 # elementwise\n",
    "    # divergence terms\n",
    "    d_rhod1_c10 = dde.grad.jacobian(rho*d1[:, 0], x, j=0)\n",
    "    d_rhod1_c12 = dde.grad.jacobian(rho*d1[:, 1], x, j=1)\n",
    "\n",
    "    ###########################################\n",
    "\n",
    "    # divergence = trace of jacobian\n",
    "    # divergence is a scalar\n",
    "\n",
    "    u_term = torch.mul(dpsi_c10.squeeze(), d1[:, 0])\\\n",
    "    + torch.mul(dpsi_c12.squeeze(), d1[:, 1])\\\n",
    "    + torch.mul(d2[:, 0], hpsi_c10.squeeze())\\\n",
    "    + torch.mul(d2[:, 1], hpsi_c12.squeeze())\n",
    "\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "\n",
    "    d_uterm_du1_du2 = torch.autograd.grad(\n",
    "        outputs=u_term,\n",
    "        inputs=leaf_vec,\n",
    "        grad_outputs=torch.ones_like(u_term),\n",
    "        retain_graph=True)[0]\n",
    "\n",
    "    l_u1 = u1 - d_uterm_du1_du2[:, 2]\n",
    "    l_u2 = u2 - d_uterm_du1_du2[:, 3]\n",
    "    if args.bound_u > 0:\n",
    "        # print(\"bounding u\")\n",
    "        l_u1_bound = -torch.sum(u1[u1 < -0.005]) +\\\n",
    "            torch.sum(u1[u1 > 0.005]) \n",
    "        l_u2_bound = -torch.sum(u2[u2 < -0.005]) +\\\n",
    "            torch.sum(u2[u2 > 0.005])\n",
    "\n",
    "        l_u1 += args.bound_u * l_u1_bound\n",
    "        l_u2 += args.bound_u * l_u2_bound\n",
    "\n",
    "    return [\n",
    "        -dpsi_t + 0.5 * (u1**2 + u2**2)\\\n",
    "        - (dpsi_c10 * d1[:, 0] + dpsi_c12 * d1[:, 1])\\\n",
    "        - (d2[:, 0] * hpsi_c10 + d2[:, 1] * hpsi_c12),\n",
    "\n",
    "        -drho_t - (d_rhod1_c10 + d_rhod1_c12)\\\n",
    "        + (d2[:, 0] * drho_c10 + d2[:, 1] * drho_c12),\n",
    "\n",
    "        l_u1,\n",
    "        l_u2\n",
    "    ]\n",
    "\n",
    "def get_model(\n",
    "    d,\n",
    "    N,\n",
    "    batchsize,\n",
    "    model_type,\n",
    "    activations, # sigmoid, tanh\n",
    "    mu_0,\n",
    "    sigma_0,\n",
    "    mu_T,\n",
    "    sigma_T,\n",
    "    T_t,\n",
    "    args,\n",
    "    network_f,\n",
    "    network_g,\n",
    "    optimizer=\"adam\",\n",
    "    init=\"Glorot normal\",\n",
    "    train_distribution=\"Hammersley\",\n",
    "    timemode=0,\n",
    "    ni=0,\n",
    "    epsilon=1e-3\n",
    "    ):\n",
    "    M = N**d\n",
    "\n",
    "    linspaces = []\n",
    "    for i in range(d):\n",
    "        linspaces.append(np.transpose(\n",
    "            np.linspace(args.state_bound_min, args.state_bound_max, N))\n",
    "        )\n",
    "\n",
    "    linspace_tensors = []\n",
    "    for i in range(d):\n",
    "        t = torch.from_numpy(\n",
    "            linspaces[i]).requires_grad_(False)\n",
    "        t = t.to(device)\n",
    "        linspace_tensors.append(t)\n",
    "\n",
    "    meshes = np.meshgrid(*linspaces)\n",
    "    mesh_vectors = []\n",
    "    for i in range(d):\n",
    "        mesh_vectors.append(meshes[i].reshape(M,1))\n",
    "    state = np.hstack(tuple(mesh_vectors))\n",
    "\n",
    "    ######################################\n",
    "\n",
    "    rv0 = multivariate_normal(mu_0, sigma_0 * np.eye(d))\n",
    "    rvT = multivariate_normal(mu_T, sigma_T * np.eye(d))\n",
    "\n",
    "    rho0=rv0.pdf(state)\n",
    "    rho0 = np.float32(rho0)\n",
    "\n",
    "    rhoT= rvT.pdf(state)\n",
    "    rhoT = np.float32(rhoT)\n",
    "\n",
    "    ######################################\n",
    "\n",
    "    time_0=np.hstack((\n",
    "        state,\n",
    "        T_0*np.ones((len(mesh_vectors[0]), 1))\n",
    "    ))\n",
    "    \n",
    "    if batchsize is not None:\n",
    "        rho_0_BC = dde.icbc.PointSetBC(\n",
    "            time_0,\n",
    "            rho0[..., np.newaxis],\n",
    "            component=1,\n",
    "            batch_size=batchsize,\n",
    "            shuffle=True\n",
    "        )\n",
    "    else:\n",
    "        rho_0_BC = dde.icbc.PointSetBC(\n",
    "            time_0,\n",
    "            rho0[..., np.newaxis],\n",
    "            component=1,\n",
    "        )\n",
    "\n",
    "    ######################################\n",
    "\n",
    "    time_t=np.hstack((\n",
    "        state,\n",
    "        T_t*np.ones((len(mesh_vectors[0]), 1))\n",
    "    ))\n",
    "    \n",
    "    if batchsize is not None:\n",
    "        rho_T_BC = dde.icbc.PointSetBC(\n",
    "            time_t,\n",
    "            rhoT[..., np.newaxis],\n",
    "            component=1,\n",
    "            batch_size=batchsize,\n",
    "            shuffle=True\n",
    "        )\n",
    "    else:\n",
    "        rho_T_BC = dde.icbc.PointSetBC(\n",
    "            time_t,\n",
    "            rhoT[..., np.newaxis],\n",
    "            component=1,\n",
    "        )\n",
    "\n",
    "    ######################################\n",
    "\n",
    "    geom=dde.geometry.geometry_3d.Cuboid(\n",
    "        [args.state_bound_min]*d,\n",
    "        [args.state_bound_max]*d)\n",
    "    timedomain = dde.geometry.TimeDomain(0., T_t)\n",
    "\n",
    "    geomtime = dde.geometry.GeometryXTime(geom, timedomain)\n",
    "\n",
    "    bif = samples_between_initial_and_final\n",
    "    if args.bif > 0:\n",
    "        bif = args.bif\n",
    "\n",
    "    batchsize2 = None\n",
    "    if len(args.batchsize2) > 0:\n",
    "        batchsize2 = int(args.batchsize2)\n",
    "\n",
    "    # dde.data.TimePDE\n",
    "    data = WASSPDE(\n",
    "        geomtime,\n",
    "        lambda x, y: tcst1(\n",
    "            x,  y, network_f, network_g, args),\n",
    "        [rho_0_BC,rho_T_BC],\n",
    "        num_domain=bif,\n",
    "        num_initial=ni, # initial_samples,\n",
    "        train_distribution=train_distribution,\n",
    "        domain_batch_size=batchsize2\n",
    "    )\n",
    "\n",
    "    # d+1 inputs: <state> + t\n",
    "    # 5 outputs: 2 eq\n",
    "    net = dde.nn.FNN(\n",
    "        [d+1] + [70] *4  + [4],\n",
    "        # \"sigmoid\",\n",
    "        activations,\n",
    "        init\n",
    "        # \"zeros\",\n",
    "    )\n",
    "    model = model_types[model_type](data, net)\n",
    "\n",
    "    ######################################\n",
    "\n",
    "    losses=[\n",
    "        \"MSE\",\"MSE\", \"MSE\", \"MSE\",\n",
    "        \"MSE\",\n",
    "        \"MSE\",\n",
    "    ]\n",
    "    # loss functions are based on PDE + BC: eq outputs, BCs\n",
    "\n",
    "    model.compile(\"adam\", lr=1e-3,loss=losses)\n",
    "\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "\n",
    "    return model, meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37837d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello?\n",
      "hello?\n",
      "hello?\n",
      "hello?\n",
      "hello?\n",
      "hello?\n",
      "using model:  ../../sde/T_t200_2D/15fold_3_2_layer_model.pt\n",
      "Using GPU.\n"
     ]
    }
   ],
   "source": [
    "sde = SDE()\n",
    "# state path to model information file\n",
    "# load model parameters\n",
    "\n",
    "files = glob.glob(\n",
    "    sde_path + \"/*.pt\", \n",
    "    recursive = False)\n",
    "assert(len(files) == 1)\n",
    "print(\"using model: \", files[0])\n",
    "sde.load_state_dict(torch.load(files[0]))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPU.\")\n",
    "    sde = sde.to(cuda0)\n",
    "# set model to evaluation mode\n",
    "sde.eval()\n",
    "\n",
    "sde.r = torch.tensor(np.array([0.0]*2), dtype=torch.float32)\n",
    "sde.r = sde.r.reshape([-1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce7369c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2\n",
    "N = 15\n",
    "batchsize = None\n",
    "\n",
    "mu_0 = [0.35, 0.35]\n",
    "\n",
    "sigma = 0.1\n",
    "T_t = 200.0\n",
    "bcc = np.array([0.41235, 0.37605])\n",
    "\n",
    "class Container(object):\n",
    "    state_bound_min = 0.1\n",
    "    state_bound_max = 0.6\n",
    "    bound_u = 0\n",
    "    \n",
    "    bif = 100000\n",
    "    batchsize2 = \"5000\"\n",
    "    batch2_period = 5000\n",
    "args = Container()\n",
    "\n",
    "num_epochs = 15000\n",
    "de = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1515530a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abhishek\n",
      "abhishek\n",
      "abhishek\n",
      "abhi\n",
      "sampling domain by  5000\n",
      "num_test NONE\n",
      "hello?\n",
      "hello?\n",
      "hello?\n",
      "hello?\n",
      "hello?\n",
      "Compiling model...\n",
      "'compile' took 0.000084 s\n",
      "\n",
      "<deepxde.model.Model object at 0x7f8cc46a9310>\n"
     ]
    }
   ],
   "source": [
    "model, meshes = get_model(\n",
    "    d,\n",
    "    N,\n",
    "    batchsize,\n",
    "    0,\n",
    "    \"tanh\",\n",
    "\n",
    "    mu_0,\n",
    "    sigma,\n",
    "\n",
    "    bcc,\n",
    "    sigma,\n",
    "\n",
    "    T_t,\n",
    "    args,\n",
    "    sde.network_f,\n",
    "    sde.network_g,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "069d455e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "\n",
      "Step      Train loss                                                      Test loss                                                       Test metric\n",
      "0         [3.44e-03, 7.86e-04, 2.27e-02, 8.08e-02, 1.52e+00, 1.04e+00]    [3.44e-03, 7.86e-04, 2.27e-02, 8.08e-02, 1.52e+00, 1.04e+00]    []  \n",
      "using _train_sgd\n",
      "1000      [6.39e-06, 6.41e-04, 2.87e-04, 5.52e-04, 1.46e-02, 3.16e-02]    [6.39e-06, 6.41e-04, 2.87e-04, 5.52e-04, 1.46e-02, 3.16e-02]    []  \n",
      "2000      [1.20e-05, 1.73e-04, 5.96e-04, 1.79e-04, 2.36e-04, 2.88e-02]    [1.20e-05, 1.73e-04, 5.96e-04, 1.79e-04, 2.36e-04, 2.88e-02]    []  \n",
      "3000      [2.37e-06, 2.96e-04, 2.24e-04, 1.27e-04, 1.46e-04, 4.22e-02]    [2.37e-06, 2.96e-04, 2.24e-04, 1.27e-04, 1.46e-04, 4.22e-02]    []  \n",
      "4000      [9.75e-07, 8.70e-05, 1.61e-04, 5.22e-05, 7.99e-05, 2.80e-02]    [9.75e-07, 8.70e-05, 1.61e-04, 5.22e-05, 7.99e-05, 2.80e-02]    []  \n",
      "5000      [5.41e-07, 1.45e-04, 2.25e-04, 7.30e-05, 7.91e-05, 1.82e-02]    [5.41e-07, 1.45e-04, 2.25e-04, 7.30e-05, 7.91e-05, 1.82e-02]    []  \n",
      "abhishek\n",
      "abhishek\n",
      "abhishek\n",
      "abhi\n",
      "sampling domain by  5000\n",
      "6000      [2.48e-06, 1.13e-04, 1.87e-04, 1.78e-04, 5.59e-05, 1.70e-02]    [2.76e-06, 1.31e-04, 2.11e-04, 1.81e-04, 5.59e-05, 1.70e-02]    []  \n",
      "7000      [8.38e-07, 1.25e-04, 8.98e-05, 3.62e-05, 4.56e-05, 1.78e-02]    [1.09e-06, 1.46e-04, 1.22e-04, 4.16e-05, 4.56e-05, 1.78e-02]    []  \n",
      "8000      [2.81e-07, 8.83e-05, 2.94e-05, 9.45e-06, 1.37e-05, 1.59e-02]    [4.86e-07, 1.20e-04, 5.96e-05, 1.14e-05, 1.37e-05, 1.59e-02]    []  \n",
      "9000      [5.06e-07, 7.34e-05, 4.29e-05, 3.16e-05, 3.15e-05, 3.09e-02]    [1.23e-06, 1.87e-04, 8.39e-05, 4.16e-05, 3.15e-05, 3.09e-02]    []  \n",
      "10000     [1.45e-07, 9.05e-05, 7.47e-05, 2.22e-05, 1.95e-05, 1.68e-02]    [6.02e-07, 1.49e-04, 1.06e-04, 2.36e-05, 1.95e-05, 1.68e-02]    []  \n",
      "abhishek\n",
      "abhishek\n",
      "abhishek\n",
      "abhi\n",
      "sampling domain by  5000\n",
      "11000     [1.16e-07, 8.36e-05, 2.69e-05, 2.63e-05, 5.13e-05, 1.50e-02]    [1.51e-07, 1.09e-04, 3.56e-05, 2.65e-05, 5.13e-05, 1.50e-02]    []  \n",
      "12000     [6.58e-08, 1.14e-04, 1.99e-05, 2.73e-05, 2.74e-05, 1.73e-04]    [2.17e-07, 1.33e-04, 2.84e-05, 3.23e-05, 2.74e-05, 1.73e-04]    []  \n",
      "13000     [3.86e-08, 1.04e-04, 1.08e-05, 1.54e-05, 3.24e-05, 5.30e-04]    [8.78e-08, 1.20e-04, 2.04e-05, 2.04e-05, 3.24e-05, 5.30e-04]    []  \n",
      "14000     [1.72e-08, 9.26e-05, 1.94e-05, 9.36e-06, 4.80e-06, 5.34e-04]    [3.77e-08, 1.17e-04, 2.74e-05, 1.45e-05, 4.80e-06, 5.34e-04]    []  \n",
      "15000     [2.60e-08, 8.70e-05, 1.65e-05, 9.48e-06, 5.36e-06, 4.31e-04]    [4.61e-08, 1.33e-04, 2.41e-05, 1.57e-05, 5.36e-06, 4.31e-04]    []  \n",
      "abhishek\n",
      "abhishek\n",
      "abhishek\n",
      "abhi\n",
      "sampling domain by  5000\n",
      "\n",
      "Best model at step 12000:\n",
      "  train loss: 3.62e-04\n",
      "  test loss: 3.94e-04\n",
      "  test metric: []\n",
      "\n",
      "Epoch 15000: saving model to ./tt200_2dr0_mse-15000.pt ...\n",
      "\n",
      "'train' took 2229.335874 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resampler_cb = PDEPointResampler2(\n",
    "    pde_points=True,\n",
    "    bc_points=False,\n",
    "    period=args.batch2_period)\n",
    "ck_path = \"./tt200_2dr0_mse\"\n",
    "\n",
    "start = time.time()\n",
    "losshistory, train_state = model.train(\n",
    "    iterations=num_epochs,\n",
    "    display_every=de,\n",
    "    callbacks=[resampler_cb],\n",
    "    model_save_path=ck_path)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae9530ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving loss history to /usr/local/home/cyan3/Dev/jim/gradschool/research/tcst/training/iman/loss.dat ...\n",
      "Saving training data to /usr/local/home/cyan3/Dev/jim/gradschool/research/tcst/training/iman/train.dat ...\n",
      "Saving test data to /usr/local/home/cyan3/Dev/jim/gradschool/research/tcst/training/iman/test.dat ...\n",
      "./tt200_2dr0_mse-15000.pt\n"
     ]
    }
   ],
   "source": [
    "dde.saveplot(losshistory, train_state, issave=True, isplot=False)\n",
    "model_path = model.save(ck_path)\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05867be",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
