{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64431653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA RTX A2000 Laptop GPU\n",
      "11.6\n",
      "0\n",
      "pytorch\n",
      "no SDE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/deepxde/backend/pytorch/tensor.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(initial_value, dtype=dtype, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "'''\n",
    "run ./train.py --sdept ../../trained_sde_model/4fold_3_2_layer_model.pt\n",
    "'''\n",
    "\n",
    "# 0 define backend\n",
    "import sys, os, time\n",
    "import argparse\n",
    "import glob\n",
    "\n",
    "# %env DDE_BACKEND=tensorflow.compat.v1\n",
    "# %env XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/home/cyan3/miniforge/envs/tf\n",
    "\n",
    "os.environ['DDE_BACKEND'] = \"pytorch\" # v2\n",
    "os.environ['XLA_FLAGS'] = \"--xla_gpu_cuda_data_dir=/usr/local/home/cyan3/miniforge/envs/tf\"\n",
    "\n",
    "# https://stackoverflow.com/questions/68614547/tensorflow-libdevice-not-found-why-is-it-not-found-in-the-searched-path\n",
    "# this directory has /nvvm/libdevice/libdevice.10.bc\n",
    "\n",
    "print(os.environ['DDE_BACKEND'])\n",
    "\n",
    "import torch\n",
    "torch.set_printoptions(precision=3)\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.current_device())\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html\n",
    "try:\n",
    "    torch.jit.enable_onednn_fusion(True)\n",
    "except:\n",
    "    print(\"no onednn\")\n",
    "\n",
    "cuda0 = torch.device('cuda:0')\n",
    "cpu = torch.device('cpu')\n",
    "device = cuda0\n",
    "\n",
    "import deepxde as dde\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "from os.path import dirname, join as pjoin\n",
    "from scipy import stats\n",
    "import scipy.io\n",
    "from scipy.stats import truncnorm, norm\n",
    "from scipy.optimize import linprog\n",
    "from scipy import sparse\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.spatial.distance import cdist\n",
    "if dde.backend.backend_name == \"pytorch\":\n",
    "    exp = dde.backend.torch.exp\n",
    "else:\n",
    "    from deepxde.backend import tf\n",
    "    exp = tf.exp\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "from scipy.linalg import solve_discrete_are\n",
    "from scipy.linalg import sqrtm as sqrtm2\n",
    "\n",
    "######################################\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "\n",
    "sys.path.insert(0,'..')\n",
    "from layers import *\n",
    "\n",
    "sde_path = './sde/T_t200_2D/'\n",
    "sys.path.insert(0,sde_path)\n",
    "from trained_sde_model import *\n",
    "\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "616dda21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tcst1(x, y, network_f, network_g, args):\n",
    "    psi, rho, u1, u2 = y[:, 0:1], y[:, 1:2], y[:, 2:3], y[:, 3:4]\n",
    "\n",
    "    # x = c10, c12, t\n",
    "\n",
    "    # psi eq (4a), rho eq (4b), u1 eq (6), u2 eq (6)\n",
    "    dpsi_c10 = dde.grad.jacobian(psi, x, j=0)\n",
    "    dpsi_c12 = dde.grad.jacobian(psi, x, j=1)\n",
    "    dpsi_t = dde.grad.jacobian(psi, x, j=2)\n",
    "\n",
    "    hpsi_c10 = dde.grad.hessian(psi, x, i=0, j=0)\n",
    "    hpsi_c12 = dde.grad.hessian(psi, x, i=1, j=1)\n",
    "\n",
    "    drho_t = dde.grad.jacobian(rho, x, j=2)\n",
    "\n",
    "    drho_c10 = dde.grad.hessian(rho, x, i=0, j=0)\n",
    "    drho_c12 = dde.grad.hessian(rho, x, i=1, j=1)\n",
    "\n",
    "    # d1\n",
    "    leaf_x = x[:, 0:2].detach()\n",
    "    leaf_u1_u2 = y[:, 2:4].detach()\n",
    "    leaf_t = x[:, 2].detach().unsqueeze(1)\n",
    "\n",
    "    ###########################################\n",
    "\n",
    "    leaf_vec = torch.cat(\n",
    "        (\n",
    "            x[:, 0:2], # leaf_x,\n",
    "            # i think this makes sense since we\n",
    "            # take jacobian of it w.r.t x for divergence\n",
    "            y[:, 2:4],\n",
    "            x[:, 2].unsqueeze(1),\n",
    "        ),\n",
    "        dim=1)\n",
    "    leaf_vec = leaf_vec.requires_grad_(True)\n",
    "\n",
    "    d1 = network_f.forward(leaf_vec)\n",
    "    d2 = network_g.forward(leaf_vec)**2 / 2 # elementwise\n",
    "    # divergence terms\n",
    "    d_rhod1_c10 = dde.grad.jacobian(rho*d1[:, 0], x, j=0)\n",
    "    d_rhod1_c12 = dde.grad.jacobian(rho*d1[:, 1], x, j=1)\n",
    "\n",
    "    ###########################################\n",
    "\n",
    "    # divergence = trace of jacobian\n",
    "    # divergence is a scalar\n",
    "\n",
    "    u_term = torch.mul(dpsi_c10.squeeze(), d1[:, 0])\\\n",
    "    + torch.mul(dpsi_c12.squeeze(), d1[:, 1])\\\n",
    "    + torch.mul(d2[:, 0], hpsi_c10.squeeze())\\\n",
    "    + torch.mul(d2[:, 1], hpsi_c12.squeeze()).unsqueeze(dim=0)\n",
    "\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "\n",
    "    d_uterm_du1_du2 = torch.autograd.grad(\n",
    "        outputs=u_term,\n",
    "        inputs=leaf_vec,\n",
    "        grad_outputs=torch.ones_like(u_term),\n",
    "        retain_graph=True)[0]\n",
    "\n",
    "    l_u1 = u1 - d_uterm_du1_du2[:, 2]\n",
    "    l_u2 = u2 - d_uterm_du1_du2[:, 3]\n",
    "    if args.bound_u > 0:\n",
    "        # print(\"bounding u\")\n",
    "        l_u1_bound = -torch.sum(u1[u1 < -0.005]) +\\\n",
    "            torch.sum(u1[u1 > 0.005]) \n",
    "        l_u2_bound = -torch.sum(u2[u2 < -0.005]) +\\\n",
    "            torch.sum(u2[u2 > 0.005])\n",
    "\n",
    "        l_u1 += args.bound_u * l_u1_bound\n",
    "        l_u2 += args.bound_u * l_u2_bound\n",
    "\n",
    "    return [\n",
    "        -dpsi_t + 0.5 * (u1**2 + u2**2)\\\n",
    "        - (dpsi_c10 * d1[:, 0] + dpsi_c12 * d1[:, 1])\\\n",
    "        - (d2[:, 0] * hpsi_c10 + d2[:, 1] * hpsi_c12),\n",
    "\n",
    "        -drho_t - (d_rhod1_c10 + d_rhod1_c12)\\\n",
    "        + (d2[:, 0] * drho_c10 + d2[:, 1] * drho_c12),\n",
    "\n",
    "        l_u1,\n",
    "        l_u2\n",
    "    ]\n",
    "\n",
    "def get_model(\n",
    "    d,\n",
    "    N,\n",
    "    batchsize,\n",
    "    model_type,\n",
    "    activations, # sigmoid, tanh\n",
    "    mu_0,\n",
    "    sigma_0,\n",
    "    mu_T,\n",
    "    sigma_T,\n",
    "    T_t,\n",
    "    args,\n",
    "    network_f,\n",
    "    network_g,\n",
    "    optimizer=\"adam\",\n",
    "    init=\"Glorot normal\",\n",
    "    train_distribution=\"Hammersley\",\n",
    "    timemode=0,\n",
    "    ni=0,\n",
    "    epsilon=1e-3\n",
    "    ):\n",
    "    M = N**d\n",
    "\n",
    "    linspaces = []\n",
    "    for i in range(d):\n",
    "        linspaces.append(np.transpose(\n",
    "            np.linspace(args.state_bound_min, args.state_bound_max, N))\n",
    "        )\n",
    "\n",
    "    linspace_tensors = []\n",
    "    for i in range(d):\n",
    "        t = torch.from_numpy(\n",
    "            linspaces[i]).requires_grad_(False)\n",
    "        t = t.to(device)\n",
    "        linspace_tensors.append(t)\n",
    "\n",
    "    meshes = np.meshgrid(*linspaces)\n",
    "    mesh_vectors = []\n",
    "    for i in range(d):\n",
    "        mesh_vectors.append(meshes[i].reshape(M,1))\n",
    "    state = np.hstack(tuple(mesh_vectors))\n",
    "\n",
    "    ######################################\n",
    "\n",
    "    rv0 = multivariate_normal(mu_0, sigma_0 * np.eye(d))\n",
    "    rvT = multivariate_normal(mu_T, sigma_T * np.eye(d))\n",
    "\n",
    "    rho0=rv0.pdf(state)\n",
    "    rho0 = np.float32(rho0)\n",
    "\n",
    "    rhoT= rvT.pdf(state)\n",
    "    rhoT = np.float32(rhoT)\n",
    "\n",
    "    ######################################\n",
    "\n",
    "    time_0=np.hstack((\n",
    "        state,\n",
    "        T_0*np.ones((len(mesh_vectors[0]), 1))\n",
    "    ))\n",
    "    \n",
    "    if batchsize is not None:\n",
    "        rho_0_BC = dde.icbc.PointSetBC(\n",
    "            time_0,\n",
    "            rho0[..., np.newaxis],\n",
    "            component=1,\n",
    "            batch_size=batchsize,\n",
    "            shuffle=True\n",
    "        )\n",
    "    else:\n",
    "        rho_0_BC = dde.icbc.PointSetBC(\n",
    "            time_0,\n",
    "            rho0[..., np.newaxis],\n",
    "            component=1,\n",
    "        )\n",
    "\n",
    "    ######################################\n",
    "\n",
    "    time_t=np.hstack((\n",
    "        state,\n",
    "        T_t*np.ones((len(mesh_vectors[0]), 1))\n",
    "    ))\n",
    "    \n",
    "    if batchsize is not None:\n",
    "        rho_T_BC = dde.icbc.PointSetBC(\n",
    "            time_t,\n",
    "            rhoT[..., np.newaxis],\n",
    "            component=1,\n",
    "            batch_size=batchsize,\n",
    "            shuffle=True\n",
    "        )\n",
    "    else:\n",
    "        rho_T_BC = dde.icbc.PointSetBC(\n",
    "            time_t,\n",
    "            rhoT[..., np.newaxis],\n",
    "            component=1,\n",
    "        )\n",
    "\n",
    "    ######################################\n",
    "\n",
    "    geom=dde.geometry.geometry_3d.Cuboid(\n",
    "        [args.state_bound_min]*d,\n",
    "        [args.state_bound_max]*d)\n",
    "    timedomain = dde.geometry.TimeDomain(0., T_t)\n",
    "\n",
    "    geomtime = dde.geometry.GeometryXTime(geom, timedomain)\n",
    "\n",
    "    bif = samples_between_initial_and_final\n",
    "    if args.bif > 0:\n",
    "        bif = args.bif\n",
    "\n",
    "    batchsize2 = None\n",
    "    if len(args.batchsize2) > 0:\n",
    "        batchsize2 = int(args.batchsize2)\n",
    "\n",
    "    # dde.data.TimePDE\n",
    "    data = WASSPDE(\n",
    "        geomtime,\n",
    "        lambda x, y: tcst1(\n",
    "            x,  y, network_f, network_g, args),\n",
    "        [rho_0_BC,rho_T_BC],\n",
    "        num_domain=bif,\n",
    "        num_initial=ni, # initial_samples,\n",
    "        train_distribution=train_distribution,\n",
    "        domain_batch_size=batchsize2\n",
    "    )\n",
    "\n",
    "    # d+1 inputs: <state> + t\n",
    "    # 5 outputs: 2 eq\n",
    "    net = dde.nn.FNN(\n",
    "        [d+1] + [70] *4  + [4],\n",
    "        # \"sigmoid\",\n",
    "        activations,\n",
    "        init\n",
    "        # \"zeros\",\n",
    "    )\n",
    "    model = model_types[model_type](data, net)\n",
    "\n",
    "    ######################################\n",
    "\n",
    "    losses=[\n",
    "        \"MSE\",\"MSE\", \"MSE\", \"MSE\",\n",
    "        \"MSE\",\n",
    "        \"MSE\",\n",
    "    ]\n",
    "    # loss functions are based on PDE + BC: eq outputs, BCs\n",
    "\n",
    "    model.compile(\"adam\", lr=1e-3,loss=losses)\n",
    "\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "\n",
    "    return model, meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37837d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello?\n",
      "hello?\n",
      "hello?\n",
      "hello?\n",
      "hello?\n",
      "hello?\n",
      "using model:  ./sde/T_t200_2D/15fold_3_2_layer_model.pt\n",
      "Using GPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SDE(\n",
       "  (network_f): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=200, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=200, out_features=2, bias=True)\n",
       "  )\n",
       "  (network_g): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=200, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=200, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sde = SDE()\n",
    "# state path to model information file\n",
    "# load model parameters\n",
    "\n",
    "files = glob.glob(\n",
    "    sde_path + \"/*.pt\", \n",
    "    recursive = False)\n",
    "assert(len(files) == 1)\n",
    "print(\"using model: \", files[0])\n",
    "sde.load_state_dict(torch.load(files[0]))\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPU.\")\n",
    "    sde = sde.to(cuda0)\n",
    "# set model to evaluation mode\n",
    "sde.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce7369c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2\n",
    "N = 15\n",
    "batchsize = None\n",
    "\n",
    "mu_0 = [0.35, 0.35]\n",
    "\n",
    "sigma = 0.1\n",
    "T_t = 200.0\n",
    "bcc = np.array([0.41235, 0.37605])\n",
    "\n",
    "class Container(object):\n",
    "    state_bound_min = 0.1\n",
    "    state_bound_max = 0.6\n",
    "    bound_u = 0\n",
    "    \n",
    "    bif = 100000\n",
    "    batchsize2 = \"5000\"\n",
    "    batch2_period = 5000\n",
    "args = Container()\n",
    "\n",
    "num_epochs = 15000\n",
    "de = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1515530a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abhishek\n",
      "abhishek\n",
      "abhishek\n",
      "abhi\n",
      "sampling domain by  5000\n",
      "num_test NONE\n",
      "hello?\n",
      "hello?\n",
      "hello?\n",
      "hello?\n",
      "hello?\n",
      "Compiling model...\n",
      "'compile' took 0.000093 s\n",
      "\n",
      "<deepxde.model.Model object at 0x7fed9c5e8df0>\n"
     ]
    }
   ],
   "source": [
    "model, meshes = get_model(\n",
    "    d,\n",
    "    N,\n",
    "    batchsize,\n",
    "    0,\n",
    "    \"tanh\",\n",
    "\n",
    "    mu_0,\n",
    "    sigma,\n",
    "\n",
    "    bcc,\n",
    "    sigma,\n",
    "\n",
    "    T_t,\n",
    "    args,\n",
    "    sde.network_f,\n",
    "    sde.network_g,\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "069d455e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "\n",
      "Step      Train loss                                                      Test loss                                                       Test metric\n",
      "0         [2.23e-02, 1.35e-04, 5.42e-02, 2.41e-01, 1.62e+00, 1.10e+00]    [2.23e-02, 1.35e-04, 5.42e-02, 2.41e-01, 1.62e+00, 1.10e+00]    []  \n",
      "using _train_sgd\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m ck_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./tt200_2d_mse\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 8\u001b[0m losshistory, train_state \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplay_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mresampler_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mck_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/deepxde/utils/internal.py:22\u001b[0m, in \u001b[0;36mtiming.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     21\u001b[0m     ts \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n\u001b[0;32m---> 22\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     te \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m took \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m s\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, te \u001b[38;5;241m-\u001b[39m ts))\n",
      "File \u001b[0;32m/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/deepxde/model.py:596\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, iterations, batch_size, display_every, disregard_previous_best, callbacks, model_restore_path, model_save_path, epochs)\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo iterations for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_name))\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing _train_sgd\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 596\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_sgd\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_every\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mon_train_end()\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/deepxde/model.py:613\u001b[0m, in \u001b[0;36mModel._train_sgd\u001b[0;34m(self, iterations, display_every)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mon_batch_begin()\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_state\u001b[38;5;241m.\u001b[39mset_data_train(\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mtrain_next_batch(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[1;32m    612\u001b[0m )\n\u001b[0;32m--> 613\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_aux_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# import ipdb; ipdb.set_trace();\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_state\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/deepxde/model.py:515\u001b[0m, in \u001b[0;36mModel._train_step\u001b[0;34m(self, inputs, targets, auxiliary_vars)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step(inputs, targets, auxiliary_vars)\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaddle\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;66;03m# TODO: auxiliary_vars\u001b[39;00m\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjax\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;66;03m# TODO: auxiliary_vars\u001b[39;00m\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step(\n\u001b[1;32m    519\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_state, inputs, targets\n\u001b[1;32m    520\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/deepxde/model.py:337\u001b[0m, in \u001b[0;36mModel._compile_pytorch.<locals>.train_step\u001b[0;34m(inputs, targets)\u001b[0m\n\u001b[1;32m    334\u001b[0m     total_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m total_loss\n\u001b[0;32m--> 337\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/torch/optim/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/torch/optim/adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    155\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 157\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/torch/optim/adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 213\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/torch/optim/adam.py:290\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    288\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 290\u001b[0m     step \u001b[38;5;241m=\u001b[39m \u001b[43mstep_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     bias_correction1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m step\n\u001b[1;32m    293\u001b[0m     bias_correction2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m step\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "resampler_cb = PDEPointResampler2(\n",
    "    pde_points=True,\n",
    "    bc_points=False,\n",
    "    period=args.batch2_period)\n",
    "ck_path = \"./tt200_2d_mse\"\n",
    "\n",
    "start = time.time()\n",
    "losshistory, train_state = model.train(\n",
    "    iterations=num_epochs,\n",
    "    display_every=de,\n",
    "    callbacks=[resampler_cb],\n",
    "    model_save_path=ck_path)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fae703",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
