{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed94711d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DDE_BACKEND=tensorflow\n",
      "env: XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/home/cyan3/miniforge/envs/tf\n"
     ]
    }
   ],
   "source": [
    "# 0 define backend\n",
    "\n",
    "%env DDE_BACKEND=tensorflow\n",
    "\n",
    "%env XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/home/cyan3/miniforge/envs/tf\n",
    "# https://stackoverflow.com/questions/68614547/tensorflow-libdevice-not-found-why-is-it-not-found-in-the-searched-path\n",
    "# this directory has /nvvm/libdevice/libdevice.10.bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e80d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env XLA_FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ffb61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env TF_XLA_FLAGS=\"--tf_xla_auto_jit=1 --tf_xla_cpu_global_jit\"\n",
    "\n",
    "# =1, =2, =-1 both are slow still"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3463c219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: tensorflow\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the default backend to \"tensorflow\". You can change it in the ~/.deepxde/config.json file or export the DDE_BACKEND environment variable. Valid options are: tensorflow.compat.v1, tensorflow, pytorch, jax, paddle (all lowercase)\n",
      "Enable just-in-time compilation with XLA.\n",
      "\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "tensorflow\n"
     ]
    }
   ],
   "source": [
    "# 1 import stuff\n",
    "\n",
    "import os, json\n",
    "\n",
    "# \"tensorflow.compat.v1\", \"tensorflow\", \"pytorch\"\n",
    "def set_default_backend(backend_name):\n",
    "    default_dir = os.path.join(os.path.expanduser(\"~\"), \".deepxde\")\n",
    "    if not os.path.exists(default_dir):\n",
    "        os.makedirs(default_dir)\n",
    "    config_path = os.path.join(default_dir, \"config.json\")\n",
    "    with open(config_path, \"w\") as config_file:\n",
    "        json.dump({\"backend\": backend_name.lower()}, config_file)\n",
    "    print(\n",
    "        'Setting the default backend to \"{}\". You can change it in the '\n",
    "        \"~/.deepxde/config.json file or export the DDE_BACKEND environment variable. \"\n",
    "        \"Valid options are: tensorflow.compat.v1, tensorflow, pytorch, jax, paddle (all lowercase)\".format(\n",
    "            backend_name\n",
    "        )\n",
    "    )\n",
    "    \n",
    "import tensorflow as tf\n",
    "set_default_backend(\"tensorflow\")\n",
    "\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# backend = \"tensorflow_v1\"\n",
    "# set_default_backend(\"tensorflow.compat.v1\")\n",
    "\n",
    "# tf.config.run_functions_eagerly(False)\n",
    "# tf.disable_eager_execution()\n",
    "# tf.enable_eager_execution()\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# eager execution for tensorflow backend works, but is VERY slow\n",
    "# disabling it leads to EagerFunction error\n",
    "\n",
    "# import torch\n",
    "# backend = \"pytorch\"\n",
    "# set_default_backend(\"pytorch\")\n",
    "\n",
    "import deepxde as dde\n",
    "\n",
    "dde.model.backend_name = \"tensorflow\"\n",
    "\n",
    "# dde.config.enable_xla_jit(True)\n",
    "# this is key for speed in v2?\n",
    "# happens by default for tensorflow v1?\n",
    "\n",
    "# dde.config.disable_xla_jit()\n",
    "# if you disable, you will run out of memory\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "from numpy import linalg as LA\n",
    "import math\n",
    "import scipy.io\n",
    "from os.path import dirname, join as pjoin\n",
    "from scipy.stats import truncnorm, norm\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "params = {'backend': 'ps',\n",
    "          'xtick.labelsize': 12,\n",
    "          'ytick.labelsize': 12,\n",
    "          'legend.handlelength': 1,\n",
    "          'legend.borderaxespad': 0,\n",
    "          'font.family': 'serif',\n",
    "          'font.serif': ['Computer Modern Roman'],\n",
    "          'ps.usedistiller': 'xpdf',\n",
    "          'text.usetex': True,\n",
    "          # include here any neede package for latex\n",
    "          'text.latex.preamble': [r'\\usepackage{amsmath}'],\n",
    "          }\n",
    "plt.rcParams.update(params)\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "import scipy.integrate as integrate\n",
    "\n",
    "import time\n",
    "\n",
    "import shutil\n",
    "\n",
    "from scipy.interpolate import griddata as gd\n",
    "\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    print(device)\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "# os.environ['XLA_FLAGS'] = \"--xla_gpu_cuda_data_dir=/usr/lib/cuda\"\n",
    "print(dde.model.backend_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c38ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env XLA_FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f22fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1e930b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62ecc0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "run_tensorflow_-2.500_2.500__5.000__2000__0.001__1_1_2__0.000__2.000_1.000__0.000_1.000__12000_1000__20000\n"
     ]
    }
   ],
   "source": [
    "# 3 define training parameters\n",
    "\n",
    "state_min = -2.5\n",
    "state_max = 2.5\n",
    "# shrinking this helps a lot\n",
    "\n",
    "######################################\n",
    "\n",
    "N = 2000\n",
    "\n",
    "T_t = 5.0\n",
    "\n",
    "epsilon=.001\n",
    "\n",
    "# j1, j2, j3=3,2,1\n",
    "j1, j2, j3 =1,1,2 # axis-symmetric case\n",
    "\n",
    "######################################\n",
    "\n",
    "# q=1 # state cost\n",
    "\n",
    "q_statepenalty_gain = 0 # 0.5\n",
    "\n",
    "######################################\n",
    "\n",
    "mu_0 = 2.0\n",
    "sigma_0 = 1.0\n",
    "\n",
    "mu_T = 0.0\n",
    "sigma_T = 1.0\n",
    "\n",
    "######################################\n",
    "\n",
    "samples_between_initial_and_final = 12000 # 10^4 order, 20k = out of memory\n",
    "initial_and_final_samples = 1000 # some 10^3 order\n",
    "\n",
    "######################################\n",
    "\n",
    "num_epochs = 20000\n",
    "\n",
    "id_prefix = \"run_%s_%.3f_%.3f__%.3f__%d__%.3f__%d_%d_%d__%.3f__%.3f_%.3f__%.3f_%.3f__%d_%d__%d\" % (\n",
    "    dde.model.backend_name,\n",
    "    state_min,\n",
    "    state_max,\n",
    "    T_t,\n",
    "    N,\n",
    "    epsilon,\n",
    "    j1, j2, j3,\n",
    "    q_statepenalty_gain,\n",
    "    mu_0, sigma_0,\n",
    "    mu_T, sigma_T,\n",
    "    samples_between_initial_and_final, initial_and_final_samples,\n",
    "    num_epochs\n",
    ")\n",
    "\n",
    "print(T_t)\n",
    "print(id_prefix)\n",
    "\n",
    "# id_prefix is a id for this training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21a1aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 pde\n",
    "\n",
    "def pde(x, y):\n",
    "    \"\"\"Euler system.\n",
    "    dy1_t = g(x)-1/2||Dy1_x||^2-<Dy1_x,f>-epsilon*Dy1_xx\n",
    "    dy2_t = -D.(y2*(f)+Dy1_x)+epsilon*Dy2_xx\n",
    "    All collocation-based residuals are defined here\n",
    "    \"\"\"\n",
    "    y1, y2 = y[:, 0:1], y[:, 1:] # y1 = psi, y2 = rho_opt\n",
    "    \n",
    "    # alpha (*) f(x)\n",
    "    f1=x[:, 1:2]*x[:, 2:3]*(j2-j3)/j1\n",
    "    f2=x[:, 0:1]*x[:, 2:3]*(j3-j1)/j2\n",
    "    f3=x[:, 0:1]*x[:, 1:2]*(j1-j2)/j3\n",
    "    \n",
    "    # jacobians\n",
    "    dy1_x1 = dde.grad.jacobian(y, x, i=0, j=0) # y[0] = output, x[0] = x1\n",
    "    dy1_x2 = dde.grad.jacobian(y, x, i=0, j=1) # y[0] = output, x[0] = x2\n",
    "    dy1_x3 = dde.grad.jacobian(y, x, i=0, j=2) # y[0] = output, x[0] = x3\n",
    "    dy1_t  = dde.grad.jacobian(y, x, i=0, j=3) # y[0] = output, x[0] = t\n",
    "    \n",
    "    dy2_x1 = dde.grad.jacobian(y, x, i=1, j=0) # y[0] = output, x[0] = x1\n",
    "    dy2_x2 = dde.grad.jacobian(y, x, i=1, j=1) # y[0] = output, x[0] = x2\n",
    "    dy2_x3 = dde.grad.jacobian(y, x, i=1, j=2) # y[0] = output, x[0] = x3\n",
    "    dy2_t  = dde.grad.jacobian(y, x, i=1, j=3) # y[0] = output, x[0] = t\n",
    "    \n",
    "    # hessians / laplacians\n",
    "    dy1_xx = dde.grad.hessian(y, x, component=0, i=0, j=0) # hessian y[component] of dx[i] dx[j]\n",
    "    dy1_yy = dde.grad.hessian(y, x, component=0, i=1, j=1)\n",
    "    dy1_zz = dde.grad.hessian(y, x, component=0, i=2, j=2)\n",
    "    \n",
    "    dy2_xx = dde.grad.hessian(y, x, component=1, i=0, j=0) # hessian y[component] of dx[i] dx[j]\n",
    "    dy2_yy = dde.grad.hessian(y, x, component=1, i=1, j=1)\n",
    "    dy2_zz = dde.grad.hessian(y, x, component=1, i=2, j=2)\n",
    "    \n",
    "    # \n",
    "    l1 = (f1 + dy1_x1)*y2\n",
    "    l2 = (f2 + dy1_x2)*y2\n",
    "    l3 = (f3 + dy1_x3)*y2\n",
    "    \n",
    "    dl1_x1 = dde.grad.jacobian(l1, x, i=0, j=0)\n",
    "    dl2_x2 = dde.grad.jacobian(l2, x, i=0, j=1)\n",
    "    dl3_x3 = dde.grad.jacobian(l3, x, i=0, j=2)\n",
    "\n",
    "    # q(x)\n",
    "    q = q_statepenalty_gain*(x[:, 0:1] * x[:, 0:1] + x[:, 1:2] * x[:, 1:2] + x[:, 2:3] * x[:, 2:3])\n",
    "    \n",
    "    # gradient in eq. 7 does not include t, t is on lhs\n",
    "    return [\n",
    "        -dy1_t + q -.5*(dy1_x1*dy1_x1+dy1_x2*dy1_x2+dy1_x3*dy1_x3) - (dy1_x1*f1+dy1_x2*f2+dy1_x3*f3) - epsilon*(dy1_xx+dy1_yy+dy1_zz),\n",
    "        -dy2_t - (dl1_x1+dl2_x2+dl3_x3) + epsilon*(dy2_xx+dy2_yy+dy2_zz),\n",
    "    ]\n",
    "\n",
    "\n",
    "def prior_pde(x, y):\n",
    "    \"\"\"Euler system.\n",
    "    dy1_t = g(x)-1/2||Dy1_x||^2-<Dy1_x,f>-epsilon*Dy1_xx\n",
    "    dy2_t = -D.(y2*(f)+Dy1_x)+epsilon*Dy2_xx\n",
    "    All collocation-based residuals are defined here\n",
    "    \"\"\"\n",
    "    y1, y2 = y[:, 0:1], y[:, 1:] # y1 = psi, y2 = rho_opt\n",
    "    \n",
    "    # prior code\n",
    "    dy1_x = tf.gradients(y1, x)[0]\n",
    "    dy1_x, dy1_y, dy1_z, dy1_t = dy1_x[:,0:1], dy1_x[:,1:2], dy1_x[:,2:3], dy1_x[:,3:]\n",
    "    \n",
    "    dy1_xx = tf.gradients(dy1_x, x)[0][:, 0:1]\n",
    "    dy1_yy = tf.gradients(dy1_y, x)[0][:, 1:2]\n",
    "    dy1_zz = tf.gradients(dy1_z, x)[0][:, 2:3] \n",
    "    \n",
    "    dy2_x = tf.gradients(y2, x)[0]\n",
    "    dy2_x, dy2_y, dy2_z, dy2_t = dy2_x[:,0:1], dy2_x[:,1:2], dy2_x[:,2:3], dy2_x[:,3:]    \n",
    "    \n",
    "    dy2_xx = tf.gradients(dy2_x, x)[0][:, 0:1]\n",
    "    dy2_yy = tf.gradients(dy2_y, x)[0][:, 1:2]\n",
    "    dy2_zz = tf.gradients(dy2_z, x)[0][:, 2:3]     \n",
    "\n",
    "    f1=x[:, 1:2]*x[:, 2:3]*(j2-j3)/j1\n",
    "    f2=x[:, 0:1]*x[:, 2:3]*(j3-j1)/j2\n",
    "    f3=x[:, 0:1]*x[:, 1:2]*(j1-j2)/j3\n",
    "    \n",
    "    d_f1dy1_y2_x=tf.gradients((f1+dy1_x)*y2,x)[0][:, 0:1]\n",
    "    d_f2dy1_y2_y=tf.gradients((f2+dy1_y)*y2,x)[0][:, 1:2]\n",
    "    d_f3dy1_y2_z=tf.gradients((f3+dy1_z)*y2,x)[0][:, 2:3]\n",
    "\n",
    "    # stay close to origin while searching, penalizes large state distance solutions\n",
    "    q = q_statepenalty_gain*(x[:, 0:1] * x[:, 0:1] + x[:, 1:2] * x[:, 1:2] + x[:, 2:3] * x[:, 2:3])\n",
    "    \n",
    "    # also try\n",
    "    # q = 0 # minimum effort control\n",
    "    \n",
    "    # TODO: verify this expression\n",
    "    return [\n",
    "        -dy1_t+q-.5*(dy1_x*dy1_x+dy1_y*dy1_y+dy1_z*dy1_z)-dy1_x*f1-dy1_y*f2-dy1_z*f3-epsilon*(dy1_xx+dy1_yy+dy1_zz),\n",
    "        -dy2_t-(d_f1dy1_y2_x+d_f2dy1_y2_y+d_f3dy1_y2_z)+epsilon*(dy2_xx+dy2_yy+dy2_zz),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3eb598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 more pde, boundary\n",
    "\n",
    "def boundary(_, on_initial):\n",
    "    return on_initial\n",
    "\n",
    "def pdf1d_0(x,y,z):\n",
    "    '''\n",
    "    a, b = (state_min - mu) / sigma, (state_max - mu) / sigma # must match sampling\n",
    "    rho_x=truncnorm.pdf(x, a, b, loc = mu, scale = sigma)\n",
    "    rho_y=truncnorm.pdf(y, a, b, loc = mu, scale = sigma)\n",
    "    rho_z=truncnorm.pdf(z, a, b, loc = mu, scale = sigma) # replace with np.normal? gaussian\n",
    "    '''\n",
    "\n",
    "    rho_x = norm.pdf(x, mu_0, sigma_0)\n",
    "    rho_y = norm.pdf(y, mu_0, sigma_0)\n",
    "    rho_z = norm.pdf(z, mu_0, sigma_0)\n",
    "\n",
    "    return rho_x*rho_y*rho_z\n",
    "\n",
    "def pdf1d_T(x,y,z):\n",
    "    '''\n",
    "    a, b = (state_min - mu) / sigma, (state_max - mu) / sigma\n",
    "    rho_x=truncnorm.pdf(x, a, b, loc = mu, scale = sigma)\n",
    "    rho_y=truncnorm.pdf(y, a, b, loc = mu, scale = sigma)\n",
    "    rho_z=truncnorm.pdf(z, a, b, loc = mu, scale = sigma)\n",
    "    '''\n",
    "\n",
    "    rho_x = norm.pdf(x, mu_T, sigma_T)\n",
    "    rho_y = norm.pdf(y, mu_T, sigma_T)\n",
    "    rho_z = norm.pdf(z, mu_T, sigma_T)\n",
    "    \n",
    "    return rho_x*rho_y*rho_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ffb8a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 14:05:34.956757: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-02 14:05:35.550436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2945 MB memory:  -> device: 0, name: Quadro RTX 4000, pci bus id: 0000:91:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# 6 define data and net\n",
    "\n",
    "x_T = np.transpose(np.linspace(state_min, state_max, N))\n",
    "y_T = np.transpose(np.linspace(state_min, state_max, N))\n",
    "z_T = np.transpose(np.linspace(state_min, state_max, N))\n",
    "\n",
    "x_T=x_T.reshape(len(x_T),1)\n",
    "y_T=y_T.reshape(len(y_T),1)\n",
    "z_T=z_T.reshape(len(z_T),1)\n",
    "\n",
    "input_timet=np.hstack((\n",
    "    x_T,\n",
    "    y_T,\n",
    "    z_T,\n",
    "    T_t*np.ones((len(x_T), 1))\n",
    "))\n",
    "\n",
    "rho_T=pdf1d_T(x_T,y_T,z_T).reshape(len(x_T),1)\n",
    "\n",
    "rho_T_BC = dde.icbc.PointSetBC(input_timet, rho_T, component=1)\n",
    "# output[component](input_timet) = rho_T\n",
    "\n",
    "geom=dde.geometry.geometry_3d.Cuboid(\n",
    "    [state_min, state_min, state_min],\n",
    "    [state_max, state_max, state_max])\n",
    "timedomain = dde.geometry.TimeDomain(0., T_t)\n",
    "geomtime = dde.geometry.GeometryXTime(geom, timedomain)\n",
    "\n",
    "# rho_0_BC = dde.icbc.IC(\n",
    "#     geomtime,\n",
    "#     lambda x: pdf1d_0(x[:,0:1],x[:,1:2],x[:,2:3]),\n",
    "#     lambda _, on_initial: on_initial,\n",
    "#     component=1)\n",
    "\n",
    "input_time0=np.hstack((\n",
    "    x_T,\n",
    "    y_T,\n",
    "    z_T,\n",
    "    np.zeros((len(x_T), 1))\n",
    "))\n",
    "rho_0=pdf1d_0(x_T,y_T,z_T).reshape(len(x_T),1)\n",
    "rho_0_BC = dde.icbc.PointSetBC(input_time0, rho_0, component=1)\n",
    "\n",
    "data = dde.data.TimePDE(\n",
    "    geomtime,\n",
    "    pde, \n",
    "    [rho_0_BC,rho_T_BC],\n",
    "    num_domain=samples_between_initial_and_final,\n",
    "    num_initial=initial_and_final_samples)\n",
    "\n",
    "net = dde.nn.FNN([4] + [70] *3  + [2], \"tanh\", \"Glorot normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "487fd549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<deepxde.model.Model object at 0x7f10a3960a00>\n"
     ]
    }
   ],
   "source": [
    "# 7 define model\n",
    "\n",
    "model = dde.Model(data, net)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41aa3274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./run_tensorflow_-2.500_2.500__5.000__2000__0.001__1_1_2__0.000__2.000_1.000__0.000_1.000__12000_1000__20000\n",
      "dir exists\n"
     ]
    }
   ],
   "source": [
    "# 8 make a directory to save data\n",
    "\n",
    "dirname = './%s' % (id_prefix)\n",
    "print(dirname)\n",
    "\n",
    "if not os.path.exists(dirname):\n",
    "    print(\"making dirname\")\n",
    "    os.mkdir(dirname)\n",
    "else:\n",
    "    print(\"dir exists\")\n",
    "    for file in os.listdir(dirname):\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4b449d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 9 stop as soon as loss is low enough\n",
    "\n",
    "ck_path = \"%s/%s/model\" % (os.path.abspath(\"./\"), id_prefix)\n",
    "\n",
    "class EarlyStoppingFixed(dde.callbacks.EarlyStopping):\n",
    "    def on_epoch_end(self):\n",
    "        current = self.get_monitor_value()\n",
    "        if self.monitor_op(current - self.min_delta, self.best):\n",
    "            self.best = current\n",
    "            # must meet baseline first\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = self.model.train_state.epoch\n",
    "                self.model.stop_training = True\n",
    "        else:\n",
    "            self.wait = 0\n",
    "                \n",
    "    def on_train_end(self):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print(\"Epoch {}: early stopping\".format(self.stopped_epoch))\n",
    "        \n",
    "        self.model.save(ck_path, verbose=True)\n",
    "        \n",
    "    def get_monitor_value(self):\n",
    "        if self.monitor == \"loss_train\":\n",
    "            result = max(self.model.train_state.loss_train)\n",
    "        elif self.monitor == \"loss_test\":\n",
    "            result = max(self.model.train_state.loss_test)\n",
    "        else:\n",
    "            raise ValueError(\"The specified monitor function is incorrect.\")\n",
    "\n",
    "        return result\n",
    "\n",
    "earlystop_cb = EarlyStoppingFixed(baseline=1e-4, patience=0)\n",
    "# no patience otherwise keeps going to improve but bounces around\n",
    "\n",
    "# modelcheckpt_cb = dde.callbacks.ModelCheckpoint(ck_path, verbose=True, save_better_only=True, period=1000)\n",
    "\n",
    "# model.compile(\"adam\", lr=1e-3,external_trainable_variables=[])\n",
    "# losshistory, train_state = model.train(epochs=num_epochs, callbacks=[])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c1071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 compile\n",
    "\n",
    "model.compile(optimizer=\"adam\", lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9925cce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 11 compile and train model\n",
    "\n",
    "losshistory, train_state = model.train(\n",
    "    display_every=1,\n",
    "    iterations=num_epochs,\n",
    "    callbacks=[earlystop_cb])\n",
    "\n",
    "# variable = dde.callbacks.VariableValue([S], period=600, filename=\"variables.dat\")\n",
    "# losshistory, train_state = model.train(epochs=20000, callbacks=[variable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ce059",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 12 save training, test, loss\n",
    "\n",
    "dde.saveplot(losshistory, train_state, issave=True, isplot=False)\n",
    "# test.dat will have 2*initial_and_final_samples + samples_between_initial_and_final + N (terminal_time)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81e0c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f057ad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13 move notebook, dat to folder\n",
    "\n",
    "if os.path.exists('./loss.dat'):\n",
    "    print(\"found\")\n",
    "    os.rename('./loss.dat', '%s/loss.dat' % (dirname))\n",
    "    os.rename('./train.dat', '%s/train.dat' % (dirname))\n",
    "    os.rename('./test.dat', '%s/test.dat' % (dirname))\n",
    "\n",
    "nb_full_path = os.path.join(os.getcwd(), nb_name)\n",
    "shutil.copyfile('./%s' % (nb_name), './%s/notebook.ipynb' % (dirname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b2261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14 remove previous saved model\n",
    "\n",
    "found = False\n",
    "for file in os.listdir(dirname):\n",
    "    if \"ckpt\" in file:\n",
    "        print(\"removing %s\" % (file))\n",
    "        os.remove(\"%s/%s\" % (dirname, file))\n",
    "        found = True\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "if not found:\n",
    "    print(\"noop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874b53d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 save model\n",
    "\n",
    "model_path = model.save(\"%s/%s/model\" % (os.path.abspath(\"./\"), id_prefix))\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4461c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16 plot loss\n",
    "\n",
    "loss_loaded = np.genfromtxt('./%s/loss.dat' % (id_prefix))\n",
    "\n",
    "# import ipdb; ipdb.set_trace();\n",
    "\n",
    "# [0] epoch\n",
    "# [1] y1, psi, hjb\n",
    "# [2] y2, rho, plank pde\n",
    "# [3] rho0, initial\n",
    "# [4] rhoT, terminal\n",
    "\n",
    "epoch = loss_loaded[:, 0]\n",
    "y1_psi_hjb = loss_loaded[:, 1]\n",
    "y2_rho_plankpde = loss_loaded[:, 2]\n",
    "rho0_initial = loss_loaded[:, 3]\n",
    "rhoT_terminal = loss_loaded[:, 4]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_yscale('log')\n",
    "\n",
    "line1, = ax.plot(epoch, y1_psi_hjb, color='orange', lw=1, label='HJB PDE')\n",
    "line2, = ax.plot(epoch, y2_rho_plankpde, color='blue', lw=1, label='Controlled Fokker-Planck PDE')\n",
    "line3, = ax.plot(epoch, rho0_initial, color='red', lw=1, label='p0 boundary condition')\n",
    "line4, = ax.plot(epoch, rhoT_terminal, color='purple', lw=1, label='pT boundary condition')\n",
    "\n",
    "ax.grid()\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set_title('training error/residual plots: mu0=2 -> muT=0')\n",
    "\n",
    "plot_fname = \"%s/%s/loss.png\" % (os.path.abspath(\"./\"), id_prefix)\n",
    "plt.savefig(plot_fname, dpi=300)\n",
    "print(\"saved plot\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5436bb28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 17 restore model to model_restored\n",
    "\n",
    "model_restored = dde.Model(data, net)\n",
    "\n",
    "ckpt_filename = None\n",
    "for file in os.listdir(dirname):\n",
    "    if file.endswith(\"ckpt.index\"):\n",
    "        print(file)        \n",
    "        ckpt_filename = file.replace(\".index\", \"\")\n",
    "print(\"\")\n",
    "print(\"ckpt_filename\")\n",
    "print(ckpt_filename)\n",
    "print(\"\")\n",
    "model_name = \"%s/%s/%s\" % (os.path.abspath(\"./\"), id_prefix, ckpt_filename)\n",
    "print(model_name)\n",
    "\n",
    "print(\"\")\n",
    "print(model_restored)\n",
    "model_restored.restore(model_name)\n",
    "print(model_restored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37d9d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cadfe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8e94fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18 load test data\n",
    "\n",
    "test = np.genfromtxt('./%s/test.dat' % (id_prefix))\n",
    "# test_timesorted = test[test[:, 3].argsort()]\n",
    "# sort AGAIN by output because a lot of samples @ t=0, t=5\n",
    "ind = np.lexsort((test[:,4],test[:,3])) # sorts by [3] (t) then by [4] (psi)\n",
    "test_timesorted = test[ind]\n",
    "source_t = test_timesorted[:, 3]\n",
    "\n",
    "print(test_timesorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c184979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19 save test data to mat for matlab\n",
    "\n",
    "import scipy.io\n",
    "mat = {\n",
    "    \"test_timesorted\" : test_timesorted,\n",
    "}\n",
    "mat_fname = '%s/%s/test.mat' % (os.path.abspath(\"./\"), id_prefix)\n",
    "scipy.io.savemat(mat_fname, mat)\n",
    "print(\"saved mat\", mat_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298e7f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 print loaded test data, try np.gradient\n",
    "\n",
    "print(test_timesorted[:, 4])\n",
    "print(test_timesorted[:, 0])\n",
    "tmp = np.gradient(test_timesorted[:, 4], test_timesorted[:, 0])\n",
    "print(tmp[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e6d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21 make input tensor\n",
    "\n",
    "inp = test_timesorted[:, 0:4] # x1, x2, x3, t\n",
    "inp_tensor = tf.convert_to_tensor(inp, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcda9401",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 22 get tf gradient with model, compare to test output, save\n",
    "\n",
    "print(\"\")\n",
    "print(\"inp\")\n",
    "print(inp, inp.shape)\n",
    "\n",
    "######################################\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(inp_tensor)\n",
    "    # preds = model.net(inp_tensor)\n",
    "\n",
    "    # you can take gradient of BOTH psi / rho w.r.t. input\n",
    "    # but we only care about psi model.net[:, 0]\n",
    "    psi = model.net(inp_tensor)[:, 0]\n",
    "\n",
    "######################################\n",
    "\n",
    "# print(\"\")\n",
    "# print(\"preds\")\n",
    "# print(preds)\n",
    "\n",
    "print(\"\")\n",
    "print(\"psi\")\n",
    "print(psi)\n",
    "\n",
    "######################################\n",
    "\n",
    "print(\"\")\n",
    "print(\"test output\")\n",
    "# print(test_timesorted[:, 4:6])\n",
    "print(test_timesorted[:, 4])\n",
    "\n",
    "######################################\n",
    "\n",
    "# gradient = tape.gradient(preds, inp_tensor)\n",
    "# gradient = gradient.numpy()\n",
    "\n",
    "vopt_xt = tape.gradient(psi, inp_tensor) # nx4\n",
    "vopt_xt = vopt_xt.numpy()\n",
    "\n",
    "######################################\n",
    "\n",
    "# gradient_fname = \"%s/%s/gradient.dat\" % (os.path.abspath(\"./\"), id_prefix)\n",
    "# np.savetxt(gradient_fname, gradient)\n",
    "# print(\"\")\n",
    "# print(\"gradient\")\n",
    "# print(gradient, gradient.shape)\n",
    "# print(\"saved gradient\")\n",
    "\n",
    "vopt_xt_fname = \"%s/%s/vopt_xt.dat\" % (os.path.abspath(\"./\"), id_prefix)\n",
    "np.savetxt(vopt_xt_fname, vopt_xt)\n",
    "print(\"\")\n",
    "print(\"vopt_xt\")\n",
    "print(vopt_xt)\n",
    "print(\"saved vopt_xt\")\n",
    "\n",
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efb5a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23 get tf gradient with model restored from file\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(inp_tensor)\n",
    "\n",
    "    # restored_preds = model_restored.net(inp_tensor)\n",
    "    \n",
    "    # you can take gradient of BOTH psi / rho w.r.t. input\n",
    "    # but we only care about psi model.net[:, 0]\n",
    "    restored_psi = model_restored.net(inp_tensor)[:, 0]\n",
    "\n",
    "######################################\n",
    "  \n",
    "# print(\"\")\n",
    "# print(\"restored_preds\")\n",
    "# print(restored_preds)\n",
    "\n",
    "print(\"\")\n",
    "print(\"restored_psi\")\n",
    "print(restored_psi)\n",
    "\n",
    "######################################\n",
    "\n",
    "print(\"\")\n",
    "print(\"test output\")\n",
    "# print(test_timesorted[:, 4:6])\n",
    "print(test_timesorted[:, 4])\n",
    "\n",
    "######################################\n",
    "\n",
    "# restored_gradient = tape.gradient(restored_preds, inp_tensor)\n",
    "# restored_gradient = restored_gradient.numpy()\n",
    "\n",
    "restored_vopt_xt = tape.gradient(restored_psi, inp_tensor)\n",
    "restored_vopt_xt = restored_vopt_xt.numpy()\n",
    "\n",
    "######################################\n",
    "\n",
    "print(\"\")\n",
    "print(\"restored_vopt_xt\")\n",
    "print(restored_vopt_xt)\n",
    "\n",
    "# restored_gradient_fname = \"%s/%s/restored_gradient.dat\" % (os.path.abspath(\"./\"), id_prefix)\n",
    "# np.savetxt(restored_gradient_fname, restored_gradient)\n",
    "# print(\"\")\n",
    "# print(\"restored_gradient\")\n",
    "# print(restored_gradient, restored_gradient.shape)\n",
    "# print(\"saved restored_gradient\")\n",
    "\n",
    "# restored_vopt_xt_fname = \"%s/%s/restored_vopt_xt.dat\" % (os.path.abspath(\"./\"), id_prefix)\n",
    "# np.savetxt(restored_vopt_xt_fname, restored_vopt_xt)\n",
    "# print(\"saved restored_vopt_xt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a4de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24 load matlab gradient from file\n",
    "\n",
    "matlab_v_name = \"%s/%s\" % (os.path.abspath(\"./\"), 'matlab_vopt_xt.mat')\n",
    "restored_vopt_xt = scipy.io.loadmat(matlab_v_name)[\"vopt_xt\"]\n",
    "restored_vopt_xt = np.nan_to_num(restored_vopt_xt, copy=False)\n",
    "\n",
    "print(restored_vopt_xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4028f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25 shuffle rows, recompute tf gradient, and sort again and compare\n",
    "# shows that gradient does NOT depend on ordering of rows\n",
    "\n",
    "np.random.shuffle(test)\n",
    "inp_shuffled = test[:, 0:4] # x1, x2, x3, t\n",
    "inp_shuffled_tensor = tf.convert_to_tensor(inp_shuffled, dtype=tf.float32)\n",
    "ind = np.lexsort((test[:,4],test[:,3])) # sorts by [3] (t) then by [4] (psi)\n",
    "# sort AGAIN by output because a lot of samples @ t=0, t=5\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(inp_shuffled_tensor)\n",
    "\n",
    "    # shuffled_preds = model_restored.net(inp_shuffled_tensor)\n",
    "\n",
    "    # you can take gradient of BOTH psi / rho w.r.t. input\n",
    "    # but we only care about psi model.net[:, 0]\n",
    "    shuffled_psi = model_restored.net(inp_shuffled_tensor)[:, 0]\n",
    "\n",
    "######################################\n",
    "  \n",
    "# print(\"\")\n",
    "# print(\"shuffled_preds\")\n",
    "# print(shuffled_preds)\n",
    "\n",
    "print(\"\")\n",
    "print(\"shuffled_psi\")\n",
    "print(shuffled_psi)\n",
    "\n",
    "######################################\n",
    "\n",
    "print(\"\")\n",
    "print(\"test output\")\n",
    "# print(test[:, 4:6])\n",
    "print(test[:, 4])\n",
    "\n",
    "######################################\n",
    "\n",
    "# shuffled_gradient = tape.gradient(shuffled_preds, inp_shuffled_tensor)\n",
    "# shuffled_gradient = shuffled_gradient.numpy()\n",
    "\n",
    "shuffled_vopt_xt = tape.gradient(shuffled_psi, inp_shuffled_tensor)\n",
    "shuffled_vopt_xt = shuffled_vopt_xt.numpy()\n",
    "\n",
    "######################################\n",
    "\n",
    "# shuffled_gradient_sorted = shuffled_gradient[ind]\n",
    "shuffled_vopt_xt_sorted = shuffled_vopt_xt[ind]\n",
    "\n",
    "print(\"\")\n",
    "# print(\"shuffled_gradient_sorted\")\n",
    "# print(shuffled_gradient_sorted, shuffled_gradient_sorted.shape)\n",
    "print(\"shuffled_vopt_xt_sorted\")\n",
    "print(shuffled_vopt_xt_sorted, shuffled_vopt_xt_sorted.shape)\n",
    "\n",
    "# if this matches restored_gradient and gradient, that means this gradient is order invariant and is 'real'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53253071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a5707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26 make interp source grids, save\n",
    "\n",
    "vinterp_N = 50\n",
    "vinterp_T = 50\n",
    "\n",
    "x_1_ = np.linspace(state_min, state_max, vinterp_N)\n",
    "x_2_ = np.linspace(state_min, state_max, vinterp_N)\n",
    "x_3_ = np.linspace(state_min, state_max, vinterp_N)\n",
    "t_ = np.linspace(0, T_t, vinterp_T)\n",
    "\n",
    "end_grid_x1, end_grid_x2, end_grid_x3 = np.meshgrid(\n",
    "  x_1_,\n",
    "  x_2_,\n",
    "  x_3_, copy=False)\n",
    "\n",
    "mid_grid_x1, mid_grid_x2, mid_grid_x3, mid_grid_t = np.meshgrid(\n",
    "  x_1_,\n",
    "  x_2_,\n",
    "  x_3_,\n",
    "  t_, copy=False)\n",
    "\n",
    "save = False\n",
    "if save:\n",
    "    x1_x2_x3_t = {\n",
    "        \"x_1_\" : x_1_,\n",
    "        \"x_2_\" : x_2_,\n",
    "        \"x_3_\" : x_3_,\n",
    "        \"t_\" : t_,\n",
    "    }\n",
    "    mat_fname = '%s/%s/post_predict_x1_x2_x3_t.mat' % (\n",
    "        os.path.abspath(\"./\"),\n",
    "        id_prefix)\n",
    "    scipy.io.savemat(mat_fname, x1_x2_x3_t)\n",
    "    print(\"saved mat\", mat_fname)\n",
    "    \n",
    "print(mid_grid_x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8417a869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27 interpolate AFTER predict, t=0\n",
    "\n",
    "test_t0 = test_timesorted[np.where(np.abs(source_t) < 1e-8), :][0] # 2k\n",
    "\n",
    "source_x1 = test_t0[:, 0]\n",
    "source_x2 = test_t0[:, 1]\n",
    "source_x3 = test_t0[:, 2]\n",
    "\n",
    "# print(np.where(np.abs(source_t) < 1e-8))\n",
    "\n",
    "# print(restored_vopt_xt.shape)\n",
    "t0_vopt_xt = vopt_xt[np.where(np.abs(source_t) < 1e-8), :][0] # nx4\n",
    "t0_v1 = t0_vopt_xt[:, 0]\n",
    "t0_v2 = t0_vopt_xt[:, 1]\n",
    "t0_v3 = t0_vopt_xt[:, 2]\n",
    "\n",
    "print(t0_vopt_xt.shape)\n",
    "\n",
    "t0_V1 = gd(\n",
    "  (source_x1, source_x2, source_x3),\n",
    "  t0_v1,\n",
    "  (end_grid_x1, end_grid_x2, end_grid_x3),\n",
    "  method='nearest')\n",
    "\n",
    "t0_V2 = gd(\n",
    "  (source_x1, source_x2, source_x3),\n",
    "  t0_v2,\n",
    "  (end_grid_x1, end_grid_x2, end_grid_x3),\n",
    "  method='nearest')\n",
    "\n",
    "t0_V3 = gd(\n",
    "  (source_x1, source_x2, source_x3),\n",
    "  t0_v3,\n",
    "  (end_grid_x1, end_grid_x2, end_grid_x3),\n",
    "  method='nearest')\n",
    "\n",
    "print(t0_V1.shape)\n",
    "\n",
    "save = True\n",
    "if save:\n",
    "    import scipy.io\n",
    "    v = {\n",
    "        \"t0_V1\" : t0_V1,\n",
    "        \"t0_V2\" : t0_V2,\n",
    "        \"t0_V3\" : t0_V3,\n",
    "    }\n",
    "    mat_fname = '%s/%s/notebook_post_predict_t0_%d_%d_v.mat' % (\n",
    "        os.path.abspath(\"./\"),\n",
    "        id_prefix,\n",
    "        vinterp_N,\n",
    "        vinterp_T)\n",
    "    scipy.io.savemat(mat_fname, v)\n",
    "    print(\"saved mat\", mat_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b38838a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc5c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28 interpolate AFTER predict, middle\n",
    "\n",
    "# middle = test_timesorted[(source_t < 5.0) & (source_t > 0.0), :] # 16k - 4k = 12k\n",
    "\n",
    "middle = test_timesorted\n",
    "\n",
    "source_x1 = middle[:, 0]\n",
    "source_x2 = middle[:, 1]\n",
    "source_x3 = middle[:, 2]\n",
    "source_t_ = middle[:, 3]\n",
    "\n",
    "# middle_vopt_xt = vopt_xt[(source_t < 5.0) & (source_t > 0.0), :]\n",
    "middle_vopt_xt = vopt_xt\n",
    "\n",
    "middle_v1 = middle_vopt_xt[:, 0]\n",
    "middle_v2 = middle_vopt_xt[:, 1]\n",
    "middle_v3 = middle_vopt_xt[:, 2]\n",
    "\n",
    "print(middle_vopt_xt.shape)\n",
    "\n",
    "mid_V1 = gd(\n",
    "  (source_x1, source_x2, source_x3, source_t_),\n",
    "  middle_v1,\n",
    "  (mid_grid_x1, mid_grid_x2, mid_grid_x3, mid_grid_t),\n",
    "  method='nearest')\n",
    "\n",
    "mid_V2 = gd(\n",
    "  (source_x1, source_x2, source_x3, source_t_),\n",
    "  middle_v2,\n",
    "  (mid_grid_x1, mid_grid_x2, mid_grid_x3, mid_grid_t),\n",
    "  method='nearest')\n",
    "\n",
    "mid_V3 = gd(\n",
    "  (source_x1, source_x2, source_x3, source_t_),\n",
    "  middle_v3,\n",
    "  (mid_grid_x1, mid_grid_x2, mid_grid_x3, mid_grid_t),\n",
    "  method='nearest')\n",
    "\n",
    "print(mid_V1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c803d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29 save mid to file\n",
    "\n",
    "import scipy.io\n",
    "v = {\n",
    "    \"mid_V1\" : mid_V1,\n",
    "    \"mid_V2\" : mid_V2,\n",
    "    \"mid_V3\" : mid_V3,\n",
    "}\n",
    "mat_fname = '%s/%s/notebook_post_predict_mid_%d_%d_v.mat' % (\n",
    "    os.path.abspath(\"./\"),\n",
    "    id_prefix,\n",
    "    vinterp_N,\n",
    "    vinterp_T)\n",
    "print(\"abt to save\")\n",
    "scipy.io.savemat(mat_fname, v)\n",
    "print(\"saved mat\", mat_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc85368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(mid_V3), np.min(mid_V3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a57d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 interpolate AFTER predict, t=5\n",
    "\n",
    "target_t = 5.0\n",
    "target_thresh = 1e-8\n",
    "\n",
    "ind = np.where(np.abs(source_t-target_t) < target_thresh)\n",
    "\n",
    "test_t5 = test_timesorted[ind, :][0] # 2k\n",
    "\n",
    "source_x1 = test_t5[:, 0]\n",
    "source_x2 = test_t5[:, 1]\n",
    "source_x3 = test_t5[:, 2]\n",
    "\n",
    "# print(np.where(np.abs(source_t) < 1e-8))\n",
    "\n",
    "# print(restored_vopt_xt.shape)\n",
    "t5_vopt_xt = restored_vopt_xt[ind, :][0]\n",
    "t5_v1 = t5_vopt_xt[:, 0]\n",
    "t5_v2 = t5_vopt_xt[:, 1]\n",
    "t5_v3 = t5_vopt_xt[:, 2]\n",
    "\n",
    "print(t5_vopt_xt.shape)\n",
    "\n",
    "t5_V1 = gd(\n",
    "  (source_x1, source_x2, source_x3),\n",
    "  t5_v1,\n",
    "  (end_grid_x1, end_grid_x2, end_grid_x3),\n",
    "  method='nearest')\n",
    "\n",
    "t5_V2 = gd(\n",
    "  (source_x1, source_x2, source_x3),\n",
    "  t5_v2,\n",
    "  (end_grid_x1, end_grid_x2, end_grid_x3),\n",
    "  method='nearest')\n",
    "\n",
    "t5_V3 = gd(\n",
    "  (source_x1, source_x2, source_x3),\n",
    "  t5_v3,\n",
    "  (end_grid_x1, end_grid_x2, end_grid_x3),\n",
    "  method='nearest')\n",
    "\n",
    "print(t5_V1.shape)\n",
    "\n",
    "save = True\n",
    "if save:\n",
    "    import scipy.io\n",
    "    v = {\n",
    "        \"t5_V1\" : t5_V1,\n",
    "        \"t5_V2\" : t5_V2,\n",
    "        \"t5_V3\" : t5_V3,\n",
    "    }\n",
    "    mat_fname = '%s/%s/post_predict_t5_%d_%d_v.mat' % (\n",
    "        os.path.abspath(\"./\"),\n",
    "        id_prefix,\n",
    "        vinterp_N,\n",
    "        vinterp_T)\n",
    "    scipy.io.savemat(mat_fname, v)\n",
    "    print(\"saved mat\", mat_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb283eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 31 plot V1\n",
    "\n",
    "fig1 = plt.figure()\n",
    "ax1=fig1.gca(projection='3d')\n",
    "sc1=ax1.scatter(source_x1, source_x2, source_x3, c=t5_v2, cmap=plt.hot())\n",
    "plt.colorbar(sc1)\n",
    "ax1.set_xlabel('x1')\n",
    "ax1.set_ylabel('x2')\n",
    "ax1.set_zlabel('x3')\n",
    "ax1.set_title('source data t=%.3f' % (target_t))\n",
    "\n",
    "#Plot interpolated values\n",
    "fig2 = plt.figure()\n",
    "ax2=fig2.gca(projection='3d')\n",
    "sc2=ax2.scatter(end_grid_x1, end_grid_x2, end_grid_x3, c=t5_V2, cmap=plt.hot())\n",
    "plt.colorbar(sc2)\n",
    "ax2.set_xlabel('x1')\n",
    "ax2.set_ylabel('x2')\n",
    "ax2.set_zlabel('x3')\n",
    "ax2.set_title('grid data t=%.3f' % (target_t))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da6e831",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(t0_V1)*j1)\n",
    "print(np.max(t0_V2)*j2)\n",
    "print(np.max(t0_V3)*j3)\n",
    "\n",
    "print(\"#####\")\n",
    "\n",
    "print(np.min(t0_V1)*j1)\n",
    "print(np.min(t0_V2)*j2)\n",
    "print(np.min(t0_V3)*j3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9163c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32 sampling t0 vs\n",
    "\n",
    "sampl = np.random.uniform(low=state_min, high=state_max, size=(1,3))\n",
    "\n",
    "print(sampl)\n",
    "\n",
    "closest_1 = [(np.abs(x_1_ - sampl[i, 0])).argmin() for i in range(sampl.shape[0])]\n",
    "closest_2 = [(np.abs(x_2_ - sampl[i, 1])).argmin() for i in range(sampl.shape[0])]\n",
    "closest_3 = [(np.abs(x_3_ - sampl[i, 2])).argmin() for i in range(sampl.shape[0])]\n",
    "\n",
    "print(sampl[:, 0])\n",
    "print(x_1_[closest_1])\n",
    "print(closest_1)\n",
    "\n",
    "v1s = t0_V1[closest_1, closest_2, closest_3]\n",
    "v2s = t0_V2[closest_1, closest_2, closest_3]\n",
    "v3s = t0_V3[closest_1, closest_2, closest_3]\n",
    "\n",
    "print(v1s)\n",
    "\n",
    "sampl = sampl[0, :]\n",
    "print(sampl)\n",
    "\n",
    "closest_1 = (np.abs(x_1_ - sampl[0])).argmin()\n",
    "closest_2 = (np.abs(x_2_ - sampl[1])).argmin()\n",
    "closest_3 = (np.abs(x_3_ - sampl[2])).argmin()\n",
    "\n",
    "v1s = t0_V1[closest_1, closest_2, closest_3]\n",
    "v2s = t0_V2[closest_1, closest_2, closest_3]\n",
    "v3s = t0_V3[closest_1, closest_2, closest_3]\n",
    "\n",
    "print(v1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fc2d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 33 sampling middle vs\n",
    "\n",
    "sampl = np.random.uniform(low=state_min, high=state_max, size=(1,4))\n",
    "sampl[0,3] = np.random.uniform(low=0.1, high=4.9)\n",
    "\n",
    "closest_1 = [(np.abs(x_1_ - sampl[i, 0])).argmin() for i in range(sampl.shape[0])]\n",
    "closest_2 = [(np.abs(x_2_ - sampl[i, 1])).argmin() for i in range(sampl.shape[0])]\n",
    "closest_3 = [(np.abs(x_3_ - sampl[i, 2])).argmin() for i in range(sampl.shape[0])]\n",
    "closest_t = [(np.abs(t_ - sampl[i, 3])).argmin() for i in range(sampl.shape[0])]\n",
    "\n",
    "print(sampl[:, 0])\n",
    "print(x_1_[closest_1])\n",
    "print(closest_1)\n",
    "\n",
    "print(sampl[:, 3])\n",
    "print(t_[closest_t])\n",
    "print(closest_t)\n",
    "\n",
    "v1s = mid_V1[closest_1, closest_2, closest_3, closest_t]\n",
    "v2s = mid_V2[closest_1, closest_2, closest_3, closest_t]\n",
    "v3s = mid_V3[closest_1, closest_2, closest_3, closest_t]\n",
    "\n",
    "print(v1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e213014",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(t0_V1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce53f1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 34 interpolate BEFORE predict\n",
    "\n",
    "# turn grid to table\n",
    "table = np.vstack([grid_x1.reshape(-1), grid_x2.reshape(-1), grid_x3.reshape(-1), grid_t.reshape(-1)]).T\n",
    "table = table[np.lexsort((table[:, 3], table[:,2], table[:,1], table[:,0]))]\n",
    "print(table, table.shape)\n",
    "\n",
    "table_tensor = tf.convert_to_tensor(table, dtype=tf.float32)\n",
    "ind = np.lexsort((test[:,4],test[:,3])) # sorts by [3] (t) then by [4] (psi)\n",
    "# sort AGAIN by output because a lot of samples @ t=0, t=5\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(table_tensor)\n",
    "\n",
    "    # table_preds = model_restored.net(table_tensor)\n",
    "\n",
    "    # you can take gradient of BOTH psi / rho w.r.t. input\n",
    "    # but we only care about psi model.net[:, 0]\n",
    "    table_psi = model_restored.net(table_tensor)[:, 0]\n",
    "\n",
    "table_vopt_xt = tape.gradient(table_psi, table_tensor)\n",
    "table_vopt_xt = table_vopt_xt.numpy()\n",
    "\n",
    "print(\"\")\n",
    "print(\"table_vopt_xt\")\n",
    "print(table_vopt_xt)\n",
    "\n",
    "table_vopt_xt_fname = \"%s/%s/table_vopt_xt.dat\" % (\n",
    "    os.path.abspath(\"./\"),\n",
    "    id_prefix)\n",
    "np.savetxt(table_vopt_xt_fname, table_vopt_xt)\n",
    "print(\"saved table_vopt_xt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877944e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d15ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35 plot rho at t=5, t=0\n",
    "\n",
    "target_t = 5.0\n",
    "\n",
    "N = 50\n",
    "\n",
    "test_timesorted = test[test[:, 3].argsort()]\n",
    "timesorted = test_timesorted[:, 3]\n",
    "test_ti = test_timesorted[np.where(np.abs(timesorted - target_t) < 1e-8), :][0] # 2k\n",
    "\n",
    "ti_rho_opt = test_ti[:, 5]\n",
    "ti_x1_x2_x3 = test_ti[:, 0:3]\n",
    "\n",
    "####################################################################\n",
    "\n",
    "d = 0.0\n",
    "x1 = np.linspace(state_min - d, state_max + d, N)\n",
    "x2 = np.linspace(state_min - d, state_max + d, N)\n",
    "x3 = np.linspace(state_min - d, state_max + d, N)\n",
    "X1, X2, X3 = np.meshgrid(x1,x2,x3,copy=False) # each is NxNxN\n",
    "\n",
    "rho_opt = np.zeros((N,N,N))\n",
    "\n",
    "closest_1 = [(np.abs(x1 - ti_x1_x2_x3[i, 0])).argmin() for i in range(ti_x1_x2_x3.shape[0])]\n",
    "closest_2 = [(np.abs(x2 - ti_x1_x2_x3[i, 1])).argmin() for i in range(ti_x1_x2_x3.shape[0])]\n",
    "closest_3 = [(np.abs(x3 - ti_x1_x2_x3[i, 2])).argmin() for i in range(ti_x1_x2_x3.shape[0])]\n",
    "\n",
    "# some transposing going on in some reshape\n",
    "# swapping closest_1/2 works well\n",
    "rho_opt[closest_2, closest_1, closest_3] = ti_rho_opt\n",
    "\n",
    "####################################################################\n",
    "\n",
    "# RHO_OPT = gd(\n",
    "#   (ti_x1_x2_x3[:, 0], ti_x1_x2_x3[:, 1], ti_x1_x2_x3[:, 2]),\n",
    "#   ti_rho_opt,\n",
    "#   (X1, X2, X3),\n",
    "#   method='linear')\n",
    "\n",
    "####################################################################\n",
    "\n",
    "x1_marginal = np.array([\n",
    "    np.trapz(\n",
    "        np.array([\n",
    "            np.trapz(rho_opt[j, i, :], x=x3) # x3 slices for one x2 => R\n",
    "            for i in range(len(x2))]) # x3 slices across all x2 => Rn\n",
    "        , x=x2) # x2 slice for one x1 => R\n",
    "for j in range(len(x1))])\n",
    "\n",
    "x2_marginal = np.array([\n",
    "    np.trapz(\n",
    "        np.array([\n",
    "            np.trapz(rho_opt[i, j, :], x=x3) # x3 slices for one x1 => R\n",
    "            for i in range(len(x1))]) # x3 slices across all x1 => Rn\n",
    "        , x=x1) # x1 slice for one x2 => R\n",
    "for j in range(len(x2))])\n",
    "\n",
    "x3_marginal = np.array([\n",
    "    np.trapz(\n",
    "        np.array([\n",
    "            np.trapz(rho_opt[i, :, j], x=x2) # x2 slices for one x1 => R\n",
    "            for i in range(len(x1))]) # x2 slices across all x1 => Rn\n",
    "        , x=x1) # x1 slice for one x3 => R\n",
    "for j in range(len(x3))])\n",
    "\n",
    "####################################################################\n",
    "\n",
    "# normalize all the pdfs so area under curve ~= 1.0\n",
    "x1_pdf_area = np.trapz(x1_marginal, x=x1)\n",
    "x2_pdf_area = np.trapz(x2_marginal, x=x2)\n",
    "x3_pdf_area = np.trapz(x3_marginal, x=x3)\n",
    "print(\"prior to normalization: %.2f, %.2f, %.2f\" % (\n",
    "    x1_pdf_area,\n",
    "    x2_pdf_area,\n",
    "    x3_pdf_area))\n",
    "\n",
    "x1_marginal /= x1_pdf_area\n",
    "x2_marginal /= x2_pdf_area\n",
    "x3_marginal /= x3_pdf_area\n",
    "\n",
    "x1_pdf_area = np.trapz(x1_marginal, x=x1)\n",
    "x2_pdf_area = np.trapz(x2_marginal, x=x2)\n",
    "x3_pdf_area = np.trapz(x3_marginal, x=x3)\n",
    "print(\"after to normalization: %.2f, %.2f, %.2f\" % (\n",
    "    x1_pdf_area,\n",
    "    x2_pdf_area,\n",
    "    x3_pdf_area))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20059796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35 plot rho at t=5, t=0\n",
    "\n",
    "fig = plt.figure(1)\n",
    "ax1 = plt.subplot(131, frameon=False)\n",
    "# ax1.set_aspect('equal')\n",
    "ax1.grid()\n",
    "ax1.set_title('x1 marginal')\n",
    "\n",
    "ax2 = plt.subplot(132, frameon=False)\n",
    "# ax2.set_aspect('equal')\n",
    "ax2.grid()\n",
    "ax2.set_title('x2 marginal')\n",
    "\n",
    "# ax3 = plt.subplot(133, frameon=False)\n",
    "\n",
    "ax3 = plt.subplot(133, frameon=False)\n",
    "# ax3.set_aspect('equal')\n",
    "ax3.grid()\n",
    "ax3.set_title('x3 marginal')\n",
    "\n",
    "colors=\"rgbymkc\"\n",
    "\n",
    "i = 0\n",
    "t_e = 0\n",
    "ax1.plot(x1,\n",
    "    x1_marginal,\n",
    "    colors[i % len(colors)],\n",
    "    linewidth=1,\n",
    "    label=t_e)\n",
    "ax1.legend(loc='lower right')\n",
    "\n",
    "ax2.plot(x2,\n",
    "    x2_marginal,\n",
    "    colors[i % len(colors)],\n",
    "    linewidth=1,\n",
    "    label=t_e)\n",
    "ax2.legend(loc='lower right')\n",
    "\n",
    "ax3.plot(x3,\n",
    "    x3_marginal,\n",
    "    colors[i % len(colors)],\n",
    "    linewidth=1,\n",
    "    label=t_e)\n",
    "ax3.legend(loc='lower right')\n",
    "\n",
    "fig.suptitle('t=%.2f' % (target_t), fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba699bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9c6889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e873187a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741dbdd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e26b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5699f4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deba1752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8703b35b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb09cbd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6f55d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78feaa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aab644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dadcec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6deec07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f53d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd037056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e158f7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d694147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd940673",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
