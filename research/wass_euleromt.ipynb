{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d782664a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DDE_BACKEND=tensorflow.compat.v1\n",
      "env: XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/home/cyan3/miniforge/envs/tf\n"
     ]
    }
   ],
   "source": [
    "# 0 define backend\n",
    "\n",
    "%env DDE_BACKEND=tensorflow.compat.v1\n",
    "\n",
    "%env XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/local/home/cyan3/miniforge/envs/tf\n",
    "# https://stackoverflow.com/questions/68614547/tensorflow-libdevice-not-found-why-is-it-not-found-in-the-searched-path\n",
    "# this directory has /nvvm/libdevice/libdevice.10.bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3463c219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: tensorflow.compat.v1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:32:36.740954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-07 00:32:36.744923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-07 00:32:36.745143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enable just-in-time compilation with XLA.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/deepxde/nn/initializers.py:118: The name tf.keras.initializers.he_normal is deprecated. Please use tf.compat.v1.keras.initializers.he_normal instead.\n",
      "\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "import sys, os, time\n",
    "import deepxde as dde\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "from numpy import linalg as LA\n",
    "import math\n",
    "import scipy.io\n",
    "from os.path import dirname, join as pjoin\n",
    "from scipy.stats import truncnorm\n",
    "# import tensorflow as tf\n",
    "from scipy.optimize import linprog\n",
    "from scipy import sparse\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9afdc78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dde.backend.backend_name == \"pytorch\":\n",
    "    exp = dde.backend.torch.exp\n",
    "else:\n",
    "    from deepxde.backend import tf\n",
    "    exp = tf.exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc691efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1662536009.3315578\n"
     ]
    }
   ],
   "source": [
    "N = nSample = 200\n",
    "\n",
    "state_min = 0\n",
    "state_max = 6\n",
    "T_t = 5\n",
    "\n",
    "mu_0 = 4.0\n",
    "sigma_0 = 0.5\n",
    "\n",
    "mu_T = 0.0\n",
    "sigma_T = 0.3\n",
    "\n",
    "j1, j2, j3 =1,1,2 # axis-symmetric case\n",
    "q_statepenalty_gain = 0 # 0.5\n",
    "epsilon=.001\n",
    "\n",
    "T_0=0. #initial time\n",
    "T_t=200. #Terminal time\n",
    "\n",
    "x_grid = np.transpose(np.linspace(state_min, state_max, nSample))\n",
    "y_grid = np.transpose(np.linspace(state_min, state_max, nSample))\n",
    "[X,Y] = np.meshgrid(x_grid,x_grid)\n",
    "C = (X - Y)**2\n",
    "\n",
    "# cvector = C.flatten('F')\n",
    "cvector = C.reshape(nSample**2,1)\n",
    "\n",
    "A = np.concatenate(\n",
    "    (\n",
    "        np.kron(\n",
    "            np.ones((1,nSample)),\n",
    "            sparse.eye(nSample).toarray()\n",
    "        ),\n",
    "        np.kron(\n",
    "            sparse.eye(nSample).toarray(),\n",
    "            np.ones((1,nSample))\n",
    "        )\n",
    "    ), axis=0)\n",
    "# 2*nSample\n",
    "\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "241315fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rv0 = multivariate_normal([mu_0, mu_0, mu_0], sigma_0 * np.eye(3))\n",
    "rvT = multivariate_normal([mu_T, mu_T, mu_T], sigma_T * np.eye(3))\n",
    "\n",
    "def pdf3d_0(x,y,z):\n",
    "    return rv0.pdf(np.hstack((x, y, z)))\n",
    "\n",
    "def pdf3d_T(x,y,z):\n",
    "    return rvT.pdf(np.hstack((x, y, z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5b6d196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "(200, 1)\n",
      "Running HiGHS 1.2.2 [date: 2022-08-30, git hash: n/a]\n",
      "Copyright (c) 2022 ERGO-Code under MIT licence terms\n",
      "Presolving model\n",
      "110 rows, 3025 cols, 6050 nonzeros\n",
      "109 rows, 3025 cols, 5995 nonzeros\n",
      "Presolve : Reductions: rows 109(-291); columns 3025(-36975); elements 5995(-74005)\n",
      "Solving the presolved LP\n",
      "Using EKK dual simplex solver - serial\n",
      "  Iteration        Objective     Infeasibilities num(sum)\n",
      "          0     0.0000000000e+00 Pr: 109(2) 0s\n",
      "         55     0.0000000000e+00 Pr: 0(0) 0s\n",
      "Solving the original LP from the solution after postsolve\n",
      "Model   status      : Optimal\n",
      "Simplex   iterations: 55\n",
      "Objective value     :  0.0000000000e+00\n",
      "HiGHS run time      :          0.02\n",
      "WARNING: Method getModelStatus(const bool scaled_model) is deprecated: alternative method is getModelStatus()\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "test_x_T = np.transpose(np.linspace(state_min, state_max, N))\n",
    "test_y_T = np.transpose(np.linspace(state_min, state_max, N))\n",
    "test_z_T = np.transpose(np.linspace(state_min, state_max, N))\n",
    "\n",
    "print(test_x_T.shape)\n",
    "test_x_T=test_x_T.reshape(len(test_x_T),1)\n",
    "test_y_T=test_y_T.reshape(len(test_y_T),1)\n",
    "test_z_T=test_z_T.reshape(len(test_z_T),1)\n",
    "\n",
    "print(test_x_T.shape)\n",
    "\n",
    "test_rho_0=pdf3d_0(test_x_T,test_y_T,test_z_T).reshape(len(test_x_T),1)\n",
    "test_rho_T=pdf3d_T(test_x_T,test_y_T,test_z_T).reshape(len(test_x_T),1)\n",
    "\n",
    "# very important to make it solvable\n",
    "test_rho_0 = np.where(test_rho_0 < 0, 0, test_rho_0)\n",
    "test_rho_0 = test_rho_0 / np.sum(test_rho_0)\n",
    "\n",
    "test_rho_T = np.where(test_rho_T < 0, 0, test_rho_T)\n",
    "test_rho_T = test_rho_T / np.sum(test_rho_T)\n",
    "\n",
    "res = linprog(\n",
    "    cvector,\n",
    "    A_eq=A,\n",
    "    b_eq=np.concatenate((test_rho_T, test_rho_T), axis=0),\n",
    "    options={\"disp\": True})\n",
    "print(res.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774ca4af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8e80ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bffc7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eb598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary(_, on_initial):\n",
    "    return on_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a1d1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "S3 = dde.Variable(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ffb8a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1662536018.3093913\n"
     ]
    }
   ],
   "source": [
    "x_T = np.transpose(np.linspace(state_min, state_max, N))\n",
    "y_T = np.transpose(np.linspace(state_min, state_max, N))\n",
    "z_T = np.transpose(np.linspace(state_min, state_max, N))\n",
    "\n",
    "x_T=x_T.reshape(len(x_T),1)\n",
    "y_T=y_T.reshape(len(y_T),1)\n",
    "z_T=z_T.reshape(len(z_T),1)\n",
    "\n",
    "terminal_time=np.hstack((x_T,y_T,z_T,T_t*np.ones((len(x_T), 1))))\n",
    "rho_T=pdf3d_T(x_T,y_T,z_T).reshape(len(x_T),1)\n",
    "rho_T_BC = dde.icbc.PointSetBC(terminal_time, rho_T, component=1)\n",
    "\n",
    "time_0=np.hstack((x_T,y_T,z_T,T_0*np.ones((len(x_T), 1))))\n",
    "rho_0=pdf3d_0(x_T,y_T,z_T).reshape(len(x_T),1)\n",
    "rho_0_BC = dde.icbc.PointSetBC(time_0, rho_0, component=1)\n",
    "\n",
    "geom=dde.geometry.geometry_3d.Cuboid(\n",
    "    [state_min, state_min, state_min],\n",
    "    [state_max, state_max, state_max])\n",
    "timedomain = dde.geometry.TimeDomain(T_0, T_t)\n",
    "geomtime = dde.geometry.GeometryXTime(geom, timedomain)\n",
    "\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cb37ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1662536048.1683652\n"
     ]
    }
   ],
   "source": [
    "def WASS(y_true, y_pred):\n",
    "    xpdf = y_pred.numpy()\n",
    "\n",
    "    xpdf = np.where(xpdf < 0, 0, xpdf)    \n",
    "#     print(np.sum(xpdf))\n",
    "    if np.sum(xpdf) > 1e-8:\n",
    "        xpdf = xpdf / np.sum(xpdf)\n",
    "        \n",
    "    ypdf = y_true.numpy()\n",
    "\n",
    "    #     ypdf = np.where(ypdf < 0, 0, ypdf)    \n",
    "    # #     print(np.sum(ypdf))\n",
    "    #     if np.sum(ypdf) > 1e-8:\n",
    "    #         ypdf = ypdf / np.sum(ypdf)\n",
    "    # if you use y_true, then it will solve but will always return c = 0\n",
    "\n",
    "    C = (X - Y)**2\n",
    "    cvector = C.reshape(nSample**2,1)\n",
    "\n",
    "    res = linprog(\n",
    "        cvector,\n",
    "        A_eq=A,\n",
    "        b_eq=np.concatenate((rho_0, xpdf), axis=0),\n",
    "        options={\"disp\": False})\n",
    "    \n",
    "    # we are cheating here, we are using tf.reduce_sum\n",
    "    # so that tf system will like our output 'type'\n",
    "    # but we are 0'ing the sum and adding our scalar cost\n",
    "    cand = tf.reduce_sum(y_pred) * 0.0\n",
    "    \n",
    "    if res.fun is None:\n",
    "        return np.inf + cand\n",
    "    else:\n",
    "        print(\"found!\", res.fun)\n",
    "        return res.fun + cand\n",
    "\n",
    "def WASS2(y_true, y_pred):\n",
    "    loss = tf.py_function(\n",
    "        func=WASS,\n",
    "        inp=[y_true, y_pred],\n",
    "        Tout=tf.float32\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21a1aecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1662536049.8522787\n"
     ]
    }
   ],
   "source": [
    "def pde(x, y):\n",
    "    \"\"\"Euler system.\n",
    "    dy1_t = g(x)-1/2||Dy1_x||^2-<Dy1_x,f>-epsilon*Dy1_xx\n",
    "    dy2_t = -D.(y2*(f)+Dy1_x)+epsilon*Dy2_xx\n",
    "    All collocation-based residuals are defined here\n",
    "    \"\"\"\n",
    "    y1, y2 = y[:, 0:1], y[:, 1:]\n",
    "    dy1_x = tf.gradients(y1, x)[0]\n",
    "    dy1_x, dy1_y, dy1_z, dy1_t = dy1_x[:,0:1], dy1_x[:,1:2], dy1_x[:,2:3], dy1_x[:,3:]\n",
    "    \n",
    "    dy1_xx = tf.gradients(dy1_x, x)[0][:, 0:1]\n",
    "    dy1_yy = tf.gradients(dy1_y, x)[0][:, 1:2]\n",
    "    dy1_zz = tf.gradients(dy1_z, x)[0][:, 2:3] \n",
    "    \n",
    "    dy2_x = tf.gradients(y2, x)[0]\n",
    "    dy2_x, dy2_y, dy2_z, dy2_t = dy2_x[:,0:1], dy2_x[:,1:2], dy2_x[:,2:3], dy2_x[:,3:]    \n",
    "    \n",
    "    dy2_xx = tf.gradients(dy2_x, x)[0][:, 0:1]\n",
    "    dy2_yy = tf.gradients(dy2_y, x)[0][:, 1:2]\n",
    "    dy2_zz = tf.gradients(dy2_z, x)[0][:, 2:3]     \n",
    "\n",
    "    f1=x[:, 1:2]*x[:, 2:3]*(j2-j3)/j1\n",
    "    f2=x[:, 0:1]*x[:, 2:3]*(j3-j1)/j2\n",
    "    f3=x[:, 0:1]*x[:, 1:2]*(j1-j2)/j3\n",
    "    \n",
    "    d_f1dy1_y2_x=tf.gradients((f1+dy1_x)*y2,x)[0][:, 0:1]\n",
    "    d_f2dy1_y2_y=tf.gradients((f2+dy1_y)*y2,x)[0][:, 1:2]\n",
    "    d_f3dy1_y2_z=tf.gradients((f3+dy1_z)*y2,x)[0][:, 2:3]\n",
    "\n",
    "    # stay close to origin while searching, penalizes large state distance solutions\n",
    "    q = q_statepenalty_gain*(x[:, 0:1] * x[:, 0:1] + x[:, 1:2] * x[:, 1:2] + x[:, 2:3] * x[:, 2:3])\n",
    "    \n",
    "    # also try\n",
    "    # q = 0 # minimum effort control\n",
    "    \n",
    "    # TODO: verify this expression\n",
    "    return [\n",
    "        -dy1_t+q-.5*(dy1_x*dy1_x+dy1_y*dy1_y+dy1_z*dy1_z)-dy1_x*f1-dy1_y*f2-dy1_z*f3-epsilon*(dy1_xx+dy1_yy+dy1_zz),\n",
    "        -dy2_t-(d_f1dy1_y2_x+d_f2dy1_y2_y+d_f3dy1_y2_z)+epsilon*(dy2_xx+dy2_yy+dy2_zz),\n",
    "    ]\n",
    "\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bef81d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1662536051.5961869\n"
     ]
    }
   ],
   "source": [
    "ck_path = \"%s/model\" % (os.path.abspath(\"./\"))\n",
    "\n",
    "class EarlyStoppingFixed(dde.callbacks.EarlyStopping):\n",
    "    def on_epoch_end(self):\n",
    "        current = self.get_monitor_value()\n",
    "        if self.monitor_op(current - self.min_delta, self.best):\n",
    "            self.best = current\n",
    "            # must meet baseline first\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = self.model.train_state.epoch\n",
    "                self.model.stop_training = True\n",
    "        else:\n",
    "            self.wait = 0\n",
    "                \n",
    "    def on_train_end(self):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print(\"Epoch {}: early stopping\".format(self.stopped_epoch))\n",
    "        \n",
    "        self.model.save(ck_path, verbose=True)\n",
    "\n",
    "    def get_monitor_value(self):\n",
    "        if self.monitor == \"loss_train\":\n",
    "            result = max(self.model.train_state.loss_train)\n",
    "        elif self.monitor == \"loss_test\":\n",
    "            result = max(self.model.train_state.loss_test)\n",
    "        else:\n",
    "            raise ValueError(\"The specified monitor function is incorrect.\")\n",
    "\n",
    "        return result\n",
    "        \n",
    "earlystop_cb = EarlyStoppingFixed(baseline=1e-4, patience=0)\n",
    "\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "487fd549",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dde.data.TimePDE(\n",
    "    geomtime, pde, \n",
    "    [rho_0_BC,rho_T_BC],\n",
    "    num_domain=5000,\n",
    "    num_initial=500)\n",
    "net = dde.nn.FNN([4] + [70] *3  + [2], \"tanh\", \"Glorot normal\")\n",
    "# net.apply_output_transform(modify_output)\n",
    "# net.apply_output_transform(modify_output)\n",
    "model = dde.Model(data, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4b449d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "Building feed-forward neural network...\n",
      "'build' took 0.023988 s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/deepxde/nn/tensorflow_compat_v1/fnn.py:103: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  return tf.layers.dense(\n",
      "/usr/local/home/cyan3/miniforge/envs/tf/lib/python3.9/site-packages/keras/legacy_tf_layers/core.py:255: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "2022-09-07 00:34:14.224593: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-07 00:34:14.225629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-07 00:34:14.225914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-07 00:34:14.226112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-07 00:34:14.530871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-07 00:34:14.531136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-07 00:34:14.531326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-07 00:34:14.531489: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-09-07 00:34:14.531516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1401 MB memory:  -> device: 0, name: NVIDIA RTX A2000 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Sum:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Sum_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Sum_2:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Sum_3:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Sum_4:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Sum_5:0\", shape=(), dtype=float32)\n",
      "'compile' took 1.240362 s\n",
      "\n",
      "Warning: epochs is deprecated and will be removed in a future version. Use iterations instead.\n",
      "Initializing variables...\n",
      "Training model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:34:15.588031: W tensorflow/compiler/jit/kernels/xla_ops.cc:436] Compilation failed:UNIMPLEMENTED: Could not find compiler for platform CUDA: NOT_FOUND: could not find registered compiler for platform CUDA -- check target linkage (hint: try adding tensorflow/compiler/jit:xla_gpu_jit as a dependency).  Falling back to TF function call.\n",
      "2022-09-07 00:34:16.031483: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-09-07 00:34:16.032834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-07 00:34:16.033070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-07 00:34:16.033242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-07 00:34:16.033436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-07 00:34:16.033605: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-07 00:34:16.033758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1401 MB memory:  -> device: 0, name: NVIDIA RTX A2000 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-09-07 00:34:16.598214: W tensorflow/compiler/jit/kernels/xla_ops.cc:436] Compilation failed:UNIMPLEMENTED: Could not find compiler for platform CUDA: NOT_FOUND: could not find registered compiler for platform CUDA -- check target linkage (hint: try adding tensorflow/compiler/jit:xla_gpu_jit as a dependency).  Falling back to TF function call.\n",
      "2022-09-07 00:34:16.749827: W tensorflow/compiler/jit/kernels/xla_ops.cc:436] Compilation failed:UNIMPLEMENTED: Could not find compiler for platform CUDA: NOT_FOUND: could not find registered compiler for platform CUDA -- check target linkage (hint: try adding tensorflow/compiler/jit:xla_gpu_jit as a dependency).  Falling back to TF function call.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step      Train loss                                  Test loss                                   Test metric\n",
      "0         [4.45e-01, 4.62e-01, inf, 2.53e-02]         [4.45e-01, 4.62e-01, inf, 2.53e-02]         []  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 00:34:17.315776: W tensorflow/compiler/jit/kernels/xla_ops.cc:436] Compilation failed:UNIMPLEMENTED: Could not find compiler for platform CUDA: NOT_FOUND: could not find registered compiler for platform CUDA -- check target linkage (hint: try adding tensorflow/compiler/jit:xla_gpu_jit as a dependency).  Falling back to TF function call.\n",
      "2022-09-07 00:34:17.799493: W tensorflow/compiler/jit/kernels/xla_ops.cc:436] Compilation failed:UNIMPLEMENTED: Could not find compiler for platform CUDA: NOT_FOUND: could not find registered compiler for platform CUDA -- check target linkage (hint: try adding tensorflow/compiler/jit:xla_gpu_jit as a dependency).  Falling back to TF function call.\n",
      "2022-09-07 00:34:18.361362: W tensorflow/compiler/jit/kernels/xla_ops.cc:436] Compilation failed:UNIMPLEMENTED: Could not find compiler for platform CUDA: NOT_FOUND: could not find registered compiler for platform CUDA -- check target linkage (hint: try adding tensorflow/compiler/jit:xla_gpu_jit as a dependency).  Falling back to TF function call.\n"
     ]
    }
   ],
   "source": [
    "loss_func=[\"MSE\",\"MSE\",WASS2,\"MSE\"]\n",
    "model.compile(\"adam\", lr=1e-3,loss=loss_func)\n",
    "losshistory, train_state = model.train(\n",
    "    epochs=15000,\n",
    "    display_every=500,\n",
    "    callbacks=[earlystop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ce059",
   "metadata": {},
   "outputs": [],
   "source": [
    "dde.saveplot(losshistory, train_state, issave=True, isplot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1e930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'backend': 'ps',\n",
    "          'xtick.labelsize': 12,\n",
    "          'ytick.labelsize': 12,\n",
    "          'legend.handlelength': 1,\n",
    "          'legend.borderaxespad': 0,\n",
    "          'font.family': 'serif',\n",
    "          'font.serif': ['Computer Modern Roman'],\n",
    "          'ps.usedistiller': 'xpdf',\n",
    "          'text.usetex': True,\n",
    "          # include here any neede package for latex\n",
    "          'text.latex.preamble': [r'\\usepackage{amsmath}'],\n",
    "          }\n",
    "plt.rcParams.update(params)\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ddc203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16 plot loss\n",
    "\n",
    "loss_loaded = np.genfromtxt('./loss.dat')\n",
    "\n",
    "print(\"loss_loaded\", loss_loaded)\n",
    "\n",
    "# import ipdb; ipdb.set_trace();\n",
    "\n",
    "# [0] epoch\n",
    "# [1] y1, psi, hjb\n",
    "# [2] y2, rho, plank pde\n",
    "# [3] rho0, initial\n",
    "# [4] rhoT, terminal\n",
    "\n",
    "epoch = loss_loaded[:, 0]\n",
    "y1_psi_hjb = loss_loaded[:, 1]\n",
    "y2_rho_plankpde = loss_loaded[:, 2]\n",
    "rho0_initial = loss_loaded[:, 3]\n",
    "rhoT_terminal = loss_loaded[:, 4]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "\n",
    "line1, = ax.plot(epoch, y1_psi_hjb, color='orange', lw=1, label='HJB PDE')\n",
    "line2, = ax.plot(epoch, y2_rho_plankpde, color='blue', lw=1, label='Controlled Fokker-Planck PDE')\n",
    "line3, = ax.plot(epoch, rho0_initial, color='red', lw=1, label='p0 boundary condition')\n",
    "line4, = ax.plot(epoch, rhoT_terminal, color='purple', lw=1, label='pT boundary condition')\n",
    "\n",
    "ax.grid()\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set_title('training error/residual plots: mu0=2 -> muT=0')\n",
    "\n",
    "plot_fname = \"%s/wass_loss.png\" % (os.path.abspath(\"./\"))\n",
    "plt.savefig(plot_fname, dpi=300)\n",
    "print(\"saved plot\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f953275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18 load test data\n",
    "\n",
    "test = np.genfromtxt('./test.dat')\n",
    "# test_timesorted = test[test[:, 3].argsort()]\n",
    "# sort AGAIN by output because a lot of samples @ t=0, t=5\n",
    "ind = np.lexsort((test[:,4],test[:,3])) # sorts by [3] (t) then by [4] (psi)\n",
    "test_timesorted = test[ind]\n",
    "source_t = test_timesorted[:, 3]\n",
    "\n",
    "print(test_timesorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65641d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35 plot rho at t=5, t=0\n",
    "\n",
    "target_t = 0.0\n",
    "\n",
    "N = 100\n",
    "\n",
    "test_timesorted = test[test[:, 3].argsort()]\n",
    "timesorted = test_timesorted[:, 3]\n",
    "test_ti = test_timesorted[np.where(np.abs(timesorted - target_t) < 1e-8), :][0] # 2k\n",
    "\n",
    "ti_rho_opt = test_ti[:, 5]\n",
    "\n",
    "ti_rho_opt = np.where(ti_rho_opt<0, 0, ti_rho_opt)\n",
    "\n",
    "ti_x1_x2_x3 = test_ti[:, 0:3]\n",
    "\n",
    "####################################################################\n",
    "\n",
    "d = 0.0\n",
    "x1 = np.linspace(state_min - d, state_max + d, N)\n",
    "x2 = np.linspace(state_min - d, state_max + d, N)\n",
    "x3 = np.linspace(state_min - d, state_max + d, N)\n",
    "X1, X2, X3 = np.meshgrid(x1,x2,x3,copy=False) # each is NxNxN\n",
    "\n",
    "rho_opt = np.zeros((N,N,N))\n",
    "\n",
    "closest_1 = [(np.abs(x1 - ti_x1_x2_x3[i, 0])).argmin() for i in range(ti_x1_x2_x3.shape[0])]\n",
    "closest_2 = [(np.abs(x2 - ti_x1_x2_x3[i, 1])).argmin() for i in range(ti_x1_x2_x3.shape[0])]\n",
    "closest_3 = [(np.abs(x3 - ti_x1_x2_x3[i, 2])).argmin() for i in range(ti_x1_x2_x3.shape[0])]\n",
    "\n",
    "# some transposing going on in some reshape\n",
    "# swapping closest_1/2 works well\n",
    "rho_opt[closest_1, closest_2, closest_3] = ti_rho_opt\n",
    "\n",
    "####################################################################\n",
    "\n",
    "# RHO_OPT = gd(\n",
    "#   (ti_x1_x2_x3[:, 0], ti_x1_x2_x3[:, 1], ti_x1_x2_x3[:, 2]),\n",
    "#   ti_rho_opt,\n",
    "#   (X1, X2, X3),\n",
    "#   method='linear')\n",
    "\n",
    "####################################################################\n",
    "\n",
    "x1_marginal = np.array([\n",
    "    np.trapz(\n",
    "        np.array([\n",
    "            np.trapz(rho_opt[j, i, :], x=x3) # x3 slices for one x2 => R\n",
    "            for i in range(len(x2))]) # x3 slices across all x2 => Rn\n",
    "        , x=x2) # x2 slice for one x1 => R\n",
    "for j in range(len(x1))])\n",
    "\n",
    "x2_marginal = np.array([\n",
    "    np.trapz(\n",
    "        np.array([\n",
    "            np.trapz(rho_opt[i, j, :], x=x3) # x3 slices for one x1 => R\n",
    "            for i in range(len(x1))]) # x3 slices across all x1 => Rn\n",
    "        , x=x1) # x1 slice for one x2 => R\n",
    "for j in range(len(x2))])\n",
    "\n",
    "x3_marginal = np.array([\n",
    "    np.trapz(\n",
    "        np.array([\n",
    "            np.trapz(rho_opt[i, :, j], x=x2) # x2 slices for one x1 => R\n",
    "            for i in range(len(x1))]) # x2 slices across all x1 => Rn\n",
    "        , x=x1) # x1 slice for one x3 => R\n",
    "for j in range(len(x3))])\n",
    "\n",
    "####################################################################\n",
    "\n",
    "# normalize all the pdfs so area under curve ~= 1.0\n",
    "x1_pdf_area = np.trapz(x1_marginal, x=x1)\n",
    "x2_pdf_area = np.trapz(x2_marginal, x=x2)\n",
    "x3_pdf_area = np.trapz(x3_marginal, x=x3)\n",
    "print(\"prior to normalization: %.2f, %.2f, %.2f\" % (\n",
    "    x1_pdf_area,\n",
    "    x2_pdf_area,\n",
    "    x3_pdf_area))\n",
    "\n",
    "# x1_marginal /= x1_pdf_area\n",
    "# x2_marginal /= x2_pdf_area\n",
    "# x3_marginal /= x3_pdf_area\n",
    "\n",
    "print(x1_marginal.shape)\n",
    "\n",
    "x1_pdf_area = np.trapz(x1_marginal, x=x1)\n",
    "x2_pdf_area = np.trapz(x2_marginal, x=x2)\n",
    "x3_pdf_area = np.trapz(x3_marginal, x=x3)\n",
    "print(\"after to normalization: %.2f, %.2f, %.2f\" % (\n",
    "    x1_pdf_area,\n",
    "    x2_pdf_area,\n",
    "    x3_pdf_area))\n",
    "\n",
    "fig = plt.figure(1)\n",
    "ax1 = plt.subplot(131, frameon=False)\n",
    "# ax1.set_aspect('equal')\n",
    "ax1.grid()\n",
    "ax1.set_title('x1 marginal')\n",
    "\n",
    "ax2 = plt.subplot(132, frameon=False)\n",
    "# ax2.set_aspect('equal')\n",
    "ax2.grid()\n",
    "ax2.set_title('x2 marginal')\n",
    "\n",
    "# ax3 = plt.subplot(133, frameon=False)\n",
    "\n",
    "ax3 = plt.subplot(133, frameon=False)\n",
    "# ax3.set_aspect('equal')\n",
    "ax3.grid()\n",
    "ax3.set_title('x3 marginal')\n",
    "\n",
    "colors=\"rgbymkc\"\n",
    "\n",
    "i = 0\n",
    "t_e = 0\n",
    "ax1.plot(x1,\n",
    "    x1_marginal,\n",
    "    colors[i % len(colors)],\n",
    "    linewidth=1,\n",
    "    label=t_e)\n",
    "ax1.legend(loc='lower right')\n",
    "\n",
    "ax2.plot(x2,\n",
    "    x2_marginal,\n",
    "    colors[i % len(colors)],\n",
    "    linewidth=1,\n",
    "    label=t_e)\n",
    "ax2.legend(loc='lower right')\n",
    "\n",
    "ax3.plot(x3,\n",
    "    x3_marginal,\n",
    "    colors[i % len(colors)],\n",
    "    linewidth=1,\n",
    "    label=t_e)\n",
    "ax3.legend(loc='lower right')\n",
    "\n",
    "fig.suptitle('t=%.2f' % (target_t), fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9060d5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
